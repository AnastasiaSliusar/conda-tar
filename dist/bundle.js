/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/b4a/browser.js":
/*!*************************************!*\
  !*** ./node_modules/b4a/browser.js ***!
  \*************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const ascii = __webpack_require__(/*! ./lib/ascii */ \"./node_modules/b4a/lib/ascii.js\")\nconst base64 = __webpack_require__(/*! ./lib/base64 */ \"./node_modules/b4a/lib/base64.js\")\nconst hex = __webpack_require__(/*! ./lib/hex */ \"./node_modules/b4a/lib/hex.js\")\nconst utf8 = __webpack_require__(/*! ./lib/utf8 */ \"./node_modules/b4a/lib/utf8.js\")\nconst utf16le = __webpack_require__(/*! ./lib/utf16le */ \"./node_modules/b4a/lib/utf16le.js\")\n\nconst LE = new Uint8Array(Uint16Array.of(0xff).buffer)[0] === 0xff\n\nfunction codecFor (encoding) {\n  switch (encoding) {\n    case 'ascii':\n      return ascii\n    case 'base64':\n      return base64\n    case 'hex':\n      return hex\n    case 'utf8':\n    case 'utf-8':\n    case undefined:\n    case null:\n      return utf8\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return utf16le\n    default:\n      throw new Error(`Unknown encoding: ${encoding}`)\n  }\n}\n\nfunction isBuffer (value) {\n  return value instanceof Uint8Array\n}\n\nfunction isEncoding (encoding) {\n  try {\n    codecFor(encoding)\n    return true\n  } catch {\n    return false\n  }\n}\n\nfunction alloc (size, fill, encoding) {\n  const buffer = new Uint8Array(size)\n  if (fill !== undefined) exports.fill(buffer, fill, 0, buffer.byteLength, encoding)\n  return buffer\n}\n\nfunction allocUnsafe (size) {\n  return new Uint8Array(size)\n}\n\nfunction allocUnsafeSlow (size) {\n  return new Uint8Array(size)\n}\n\nfunction byteLength (string, encoding) {\n  return codecFor(encoding).byteLength(string)\n}\n\nfunction compare (a, b) {\n  if (a === b) return 0\n\n  const len = Math.min(a.byteLength, b.byteLength)\n\n  a = new DataView(a.buffer, a.byteOffset, a.byteLength)\n  b = new DataView(b.buffer, b.byteOffset, b.byteLength)\n\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    const x = a.getUint32(i, LE)\n    const y = b.getUint32(i, LE)\n    if (x !== y) break\n  }\n\n  for (; i < len; i++) {\n    const x = a.getUint8(i)\n    const y = b.getUint8(i)\n    if (x < y) return -1\n    if (x > y) return 1\n  }\n\n  return a.byteLength > b.byteLength ? 1 : a.byteLength < b.byteLength ? -1 : 0\n}\n\nfunction concat (buffers, totalLength) {\n  if (totalLength === undefined) {\n    totalLength = buffers.reduce((len, buffer) => len + buffer.byteLength, 0)\n  }\n\n  const result = new Uint8Array(totalLength)\n\n  let offset = 0\n  for (const buffer of buffers) {\n    if (offset + buffer.byteLength > result.byteLength) {\n      const sub = buffer.subarray(0, result.byteLength - offset)\n      result.set(sub, offset)\n      return result\n    }\n    result.set(buffer, offset)\n    offset += buffer.byteLength\n  }\n\n  return result\n}\n\nfunction copy (source, target, targetStart = 0, start = 0, end = source.byteLength) {\n  if (end > 0 && end < start) return 0\n  if (end === start) return 0\n  if (source.byteLength === 0 || target.byteLength === 0) return 0\n\n  if (targetStart < 0) throw new RangeError('targetStart is out of range')\n  if (start < 0 || start >= source.byteLength) throw new RangeError('sourceStart is out of range')\n  if (end < 0) throw new RangeError('sourceEnd is out of range')\n\n  if (targetStart >= target.byteLength) targetStart = target.byteLength\n  if (end > source.byteLength) end = source.byteLength\n  if (target.byteLength - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  const len = end - start\n\n  if (source === target) {\n    target.copyWithin(targetStart, start, end)\n  } else {\n    target.set(source.subarray(start, end), targetStart)\n  }\n\n  return len\n}\n\nfunction equals (a, b) {\n  if (a === b) return true\n  if (a.byteLength !== b.byteLength) return false\n\n  const len = a.byteLength\n\n  a = new DataView(a.buffer, a.byteOffset, a.byteLength)\n  b = new DataView(b.buffer, b.byteOffset, b.byteLength)\n\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    if (a.getUint32(i, LE) !== b.getUint32(i, LE)) return false\n  }\n\n  for (; i < len; i++) {\n    if (a.getUint8(i) !== b.getUint8(i)) return false\n  }\n\n  return true\n}\n\nfunction fill (buffer, value, offset, end, encoding) {\n  if (typeof value === 'string') {\n    // fill(buffer, string, encoding)\n    if (typeof offset === 'string') {\n      encoding = offset\n      offset = 0\n      end = buffer.byteLength\n\n    // fill(buffer, string, offset, encoding)\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = buffer.byteLength\n    }\n  } else if (typeof value === 'number') {\n    value = value & 0xff\n  } else if (typeof value === 'boolean') {\n    value = +value\n  }\n\n  if (offset < 0 || buffer.byteLength < offset || buffer.byteLength < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (offset === undefined) offset = 0\n  if (end === undefined) end = buffer.byteLength\n\n  if (end <= offset) return buffer\n\n  if (!value) value = 0\n\n  if (typeof value === 'number') {\n    for (let i = offset; i < end; ++i) {\n      buffer[i] = value\n    }\n  } else {\n    value = isBuffer(value) ? value : from(value, encoding)\n\n    const len = value.byteLength\n\n    for (let i = 0; i < end - offset; ++i) {\n      buffer[i + offset] = value[i % len]\n    }\n  }\n\n  return buffer\n}\n\nfunction from (value, encodingOrOffset, length) {\n  // from(string, encoding)\n  if (typeof value === 'string') return fromString(value, encodingOrOffset)\n\n  // from(array)\n  if (Array.isArray(value)) return fromArray(value)\n\n  // from(buffer)\n  if (ArrayBuffer.isView(value)) return fromBuffer(value)\n\n  // from(arrayBuffer[, byteOffset[, length]])\n  return fromArrayBuffer(value, encodingOrOffset, length)\n}\n\nfunction fromString (string, encoding) {\n  const codec = codecFor(encoding)\n  const buffer = new Uint8Array(codec.byteLength(string))\n  codec.write(buffer, string, 0, buffer.byteLength)\n  return buffer\n}\n\nfunction fromArray (array) {\n  const buffer = new Uint8Array(array.length)\n  buffer.set(array)\n  return buffer\n}\n\nfunction fromBuffer (buffer) {\n  const copy = new Uint8Array(buffer.byteLength)\n  copy.set(buffer)\n  return copy\n}\n\nfunction fromArrayBuffer (arrayBuffer, byteOffset, length) {\n  return new Uint8Array(arrayBuffer, byteOffset, length)\n}\n\nfunction includes (buffer, value, byteOffset, encoding) {\n  return indexOf(buffer, value, byteOffset, encoding) !== -1\n}\n\nfunction bidirectionalIndexOf (buffer, value, byteOffset, encoding, first) {\n  if (buffer.byteLength === 0) return -1\n\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset === undefined) {\n    byteOffset = first ? 0 : (buffer.length - 1)\n  } else if (byteOffset < 0) {\n    byteOffset += buffer.byteLength\n  }\n\n  if (byteOffset >= buffer.byteLength) {\n    if (first) return -1\n    else byteOffset = buffer.byteLength - 1\n  } else if (byteOffset < 0) {\n    if (first) byteOffset = 0\n    else return -1\n  }\n\n  if (typeof value === 'string') {\n    value = from(value, encoding)\n  } else if (typeof value === 'number') {\n    value = value & 0xff\n\n    if (first) {\n      return buffer.indexOf(value, byteOffset)\n    } else {\n      return buffer.lastIndexOf(value, byteOffset)\n    }\n  }\n\n  if (value.byteLength === 0) return -1\n\n  if (first) {\n    let foundIndex = -1\n\n    for (let i = byteOffset; i < buffer.byteLength; i++) {\n      if (buffer[i] === value[foundIndex === -1 ? 0 : i - foundIndex]) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === value.byteLength) return foundIndex\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + value.byteLength > buffer.byteLength) {\n      byteOffset = buffer.byteLength - value.byteLength\n    }\n\n    for (let i = byteOffset; i >= 0; i--) {\n      let found = true\n\n      for (let j = 0; j < value.byteLength; j++) {\n        if (buffer[i + j] !== value[j]) {\n          found = false\n          break\n        }\n      }\n\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nfunction indexOf (buffer, value, byteOffset, encoding) {\n  return bidirectionalIndexOf(buffer, value, byteOffset, encoding, true /* first */)\n}\n\nfunction lastIndexOf (buffer, value, byteOffset, encoding) {\n  return bidirectionalIndexOf(buffer, value, byteOffset, encoding, false /* last */)\n}\n\nfunction swap (buffer, n, m) {\n  const i = buffer[n]\n  buffer[n] = buffer[m]\n  buffer[m] = i\n}\n\nfunction swap16 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 2 !== 0) throw new RangeError('Buffer size must be a multiple of 16-bits')\n\n  for (let i = 0; i < len; i += 2) swap(buffer, i, i + 1)\n\n  return buffer\n}\n\nfunction swap32 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 4 !== 0) throw new RangeError('Buffer size must be a multiple of 32-bits')\n\n  for (let i = 0; i < len; i += 4) {\n    swap(buffer, i, i + 3)\n    swap(buffer, i + 1, i + 2)\n  }\n\n  return buffer\n}\n\nfunction swap64 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 8 !== 0) throw new RangeError('Buffer size must be a multiple of 64-bits')\n\n  for (let i = 0; i < len; i += 8) {\n    swap(buffer, i, i + 7)\n    swap(buffer, i + 1, i + 6)\n    swap(buffer, i + 2, i + 5)\n    swap(buffer, i + 3, i + 4)\n  }\n\n  return buffer\n}\n\nfunction toBuffer (buffer) {\n  return buffer\n}\n\nfunction toString (buffer, encoding, start = 0, end = buffer.byteLength) {\n  const len = buffer.byteLength\n\n  if (start >= len) return ''\n  if (end <= start) return ''\n  if (start < 0) start = 0\n  if (end > len) end = len\n\n  if (start !== 0 || end < len) buffer = buffer.subarray(start, end)\n\n  return codecFor(encoding).toString(buffer)\n}\n\nfunction write (buffer, string, offset, length, encoding) {\n  // write(buffer, string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n\n  // write(buffer, string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    offset = undefined\n\n  // write(buffer, string, offset, encoding)\n  } else if (encoding === undefined && typeof length === 'string') {\n    encoding = length\n    length = undefined\n  }\n\n  return codecFor(encoding).write(buffer, string, offset, length)\n}\n\nfunction writeDoubleLE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat64(offset, value, true)\n\n  return offset + 8\n}\n\nfunction writeFloatLE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction writeUInt32LE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setUint32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction writeInt32LE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setInt32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction readDoubleLE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat64(offset, true)\n}\n\nfunction readFloatLE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat32(offset, true)\n}\n\nfunction readUInt32LE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getUint32(offset, true)\n}\n\nfunction readInt32LE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getInt32(offset, true)\n}\n\nfunction writeDoubleBE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat64(offset, value, false)\n\n  return offset + 8\n}\n\nfunction writeFloatBE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction writeUInt32BE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setUint32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction writeInt32BE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setInt32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction readDoubleBE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat64(offset, false)\n}\n\nfunction readFloatBE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat32(offset, false)\n}\n\nfunction readUInt32BE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getUint32(offset, false)\n}\n\nfunction readInt32BE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getInt32(offset, false)\n}\n\nmodule.exports = exports = {\n  isBuffer,\n  isEncoding,\n  alloc,\n  allocUnsafe,\n  allocUnsafeSlow,\n  byteLength,\n  compare,\n  concat,\n  copy,\n  equals,\n  fill,\n  from,\n  includes,\n  indexOf,\n  lastIndexOf,\n  swap16,\n  swap32,\n  swap64,\n  toBuffer,\n  toString,\n  write,\n  writeDoubleLE,\n  writeFloatLE,\n  writeUInt32LE,\n  writeInt32LE,\n  readDoubleLE,\n  readFloatLE,\n  readUInt32LE,\n  readInt32LE,\n  writeDoubleBE,\n  writeFloatBE,\n  writeUInt32BE,\n  writeInt32BE,\n  readDoubleBE,\n  readFloatBE,\n  readUInt32BE,\n  readInt32BE\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/browser.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/ascii.js":
/*!***************************************!*\
  !*** ./node_modules/b4a/lib/ascii.js ***!
  \***************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len; i++) {\n    result += String.fromCharCode(buffer[i])\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0; i < len; i++) {\n    buffer[offset + i] = string.charCodeAt(i)\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/lib/ascii.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/base64.js":
/*!****************************************!*\
  !*** ./node_modules/b4a/lib/base64.js ***!
  \****************************************/
/***/ ((module) => {

eval("const alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\n\nconst codes = new Uint8Array(256)\n\nfor (let i = 0; i < alphabet.length; i++) {\n  codes[alphabet.charCodeAt(i)] = i\n}\n\ncodes[/* - */ 0x2d] = 62\ncodes[/* _ */ 0x5f] = 63\n\nfunction byteLength (string) {\n  let len = string.length\n\n  if (string.charCodeAt(len - 1) === 0x3d) len--\n  if (len > 1 && string.charCodeAt(len - 1) === 0x3d) len--\n\n  return (len * 3) >>> 2\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len; i += 3) {\n    result += (\n      alphabet[buffer[i] >> 2] +\n      alphabet[((buffer[i] & 3) << 4) | (buffer[i + 1] >> 4)] +\n      alphabet[((buffer[i + 1] & 15) << 2) | (buffer[i + 2] >> 6)] +\n      alphabet[buffer[i + 2] & 63]\n    )\n  }\n\n  if (len % 3 === 2) {\n    result = result.substring(0, result.length - 1) + '='\n  } else if (len % 3 === 1) {\n    result = result.substring(0, result.length - 2) + '=='\n  }\n\n  return result\n};\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0, j = 0; j < len; i += 4) {\n    const a = codes[string.charCodeAt(i)]\n    const b = codes[string.charCodeAt(i + 1)]\n    const c = codes[string.charCodeAt(i + 2)]\n    const d = codes[string.charCodeAt(i + 3)]\n\n    buffer[j++] = (a << 2) | (b >> 4)\n    buffer[j++] = ((b & 15) << 4) | (c >> 2)\n    buffer[j++] = ((c & 3) << 6) | (d & 63)\n  }\n\n  return len\n};\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/lib/base64.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/hex.js":
/*!*************************************!*\
  !*** ./node_modules/b4a/lib/hex.js ***!
  \*************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length >>> 1\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  buffer = new DataView(buffer.buffer, buffer.byteOffset, len)\n\n  let result = ''\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    result += buffer.getUint32(i).toString(16).padStart(8, '0')\n  }\n\n  for (; i < len; i++) {\n    result += buffer.getUint8(i).toString(16).padStart(2, '0')\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0; i < len; i++) {\n    const a = hexValue(string.charCodeAt(i * 2))\n    const b = hexValue(string.charCodeAt(i * 2 + 1))\n\n    if (a === undefined || b === undefined) {\n      return buffer.subarray(0, i)\n    }\n\n    buffer[offset + i] = (a << 4) | b\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\nfunction hexValue (char) {\n  if (char >= 0x30 && char <= 0x39) return char - 0x30\n  if (char >= 0x41 && char <= 0x46) return char - 0x41 + 10\n  if (char >= 0x61 && char <= 0x66) return char - 0x61 + 10\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/lib/hex.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/utf16le.js":
/*!*****************************************!*\
  !*** ./node_modules/b4a/lib/utf16le.js ***!
  \*****************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length * 2\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len - 1; i += 2) {\n    result += String.fromCharCode(buffer[i] + (buffer[i + 1] * 256))\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  let units = len\n\n  for (let i = 0; i < string.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    const c = string.charCodeAt(i)\n    const hi = c >> 8\n    const lo = c % 256\n\n    buffer[offset + i * 2] = lo\n    buffer[offset + i * 2 + 1] = hi\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/lib/utf16le.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/utf8.js":
/*!**************************************!*\
  !*** ./node_modules/b4a/lib/utf8.js ***!
  \**************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  let length = 0\n\n  for (let i = 0, n = string.length; i < n; i++) {\n    const code = string.charCodeAt(i)\n\n    if (code >= 0xd800 && code <= 0xdbff && i + 1 < n) {\n      const code = string.charCodeAt(i + 1)\n\n      if (code >= 0xdc00 && code <= 0xdfff) {\n        length += 4\n        i++\n        continue\n      }\n    }\n\n    if (code <= 0x7f) length += 1\n    else if (code <= 0x7ff) length += 2\n    else length += 3\n  }\n\n  return length\n}\n\nlet toString\n\nif (typeof TextDecoder !== 'undefined') {\n  const decoder = new TextDecoder()\n\n  toString = function toString (buffer) {\n    return decoder.decode(buffer)\n  }\n} else {\n  toString = function toString (buffer) {\n    const len = buffer.byteLength\n\n    let output = ''\n    let i = 0\n\n    while (i < len) {\n      let byte = buffer[i]\n\n      if (byte <= 0x7f) {\n        output += String.fromCharCode(byte)\n        i++\n        continue\n      }\n\n      let bytesNeeded = 0\n      let codePoint = 0\n\n      if (byte <= 0xdf) {\n        bytesNeeded = 1\n        codePoint = byte & 0x1f\n      } else if (byte <= 0xef) {\n        bytesNeeded = 2\n        codePoint = byte & 0x0f\n      } else if (byte <= 0xf4) {\n        bytesNeeded = 3\n        codePoint = byte & 0x07\n      }\n\n      if (len - i - bytesNeeded > 0) {\n        let k = 0\n\n        while (k < bytesNeeded) {\n          byte = buffer[i + k + 1]\n          codePoint = (codePoint << 6) | (byte & 0x3f)\n          k += 1\n        }\n      } else {\n        codePoint = 0xfffd\n        bytesNeeded = len - i\n      }\n\n      output += String.fromCodePoint(codePoint)\n      i += bytesNeeded + 1\n    }\n\n    return output\n  }\n}\n\nlet write\n\nif (typeof TextEncoder !== 'undefined') {\n  const encoder = new TextEncoder()\n\n  write = function write (buffer, string, offset = 0, length = byteLength(string)) {\n    const len = Math.min(length, buffer.byteLength - offset)\n    encoder.encodeInto(string, buffer.subarray(offset, offset + len))\n    return len\n  }\n} else {\n  write = function write (buffer, string, offset = 0, length = byteLength(string)) {\n    const len = Math.min(length, buffer.byteLength - offset)\n\n    buffer = buffer.subarray(offset, offset + len)\n\n    let i = 0\n    let j = 0\n\n    while (i < string.length) {\n      const code = string.codePointAt(i)\n\n      if (code <= 0x7f) {\n        buffer[j++] = code\n        i++\n        continue\n      }\n\n      let count = 0\n      let bits = 0\n\n      if (code <= 0x7ff) {\n        count = 6\n        bits = 0xc0\n      } else if (code <= 0xffff) {\n        count = 12\n        bits = 0xe0\n      } else if (code <= 0x1fffff) {\n        count = 18\n        bits = 0xf0\n      }\n\n      buffer[j++] = bits | (code >> count)\n      count -= 6\n\n      while (count >= 0) {\n        buffer[j++] = 0x80 | ((code >> count) & 0x3f)\n        count -= 6\n      }\n\n      i += code >= 0x10000 ? 2 : 1\n    }\n\n    return len\n  }\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/b4a/lib/utf8.js?");

/***/ }),

/***/ "./lib/libarchive.js":
/*!***************************!*\
  !*** ./lib/libarchive.js ***!
  \***************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* module decorator */ module = __webpack_require__.nmd(module);\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;function _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nvar Module = function () {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  return function () {\n    var moduleArg = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    // include: shell.js\n    // The Module object: Our interface to the outside world. We import\n    // and export values on it. There are various ways Module can be used:\n    // 1. Not defined. We create it here\n    // 2. A function parameter, function(Module) { ..generated code.. }\n    // 3. pre-run appended it, var Module = {}; ..generated code..\n    // 4. External script tag defines var Module.\n    // We need to check if Module already exists (e.g. case 3 above).\n    // Substitution will be replaced with actual code on later stage of the build,\n    // this way Closure Compiler will not mangle it (e.g. case 4. above).\n    // Note that if you want to run closure, and also to use Module\n    // after the generated code, you will need to define   var Module = {};\n    // before the code. Then that object will be used in the code, and you\n    // can continue to use Module afterwards as well.\n    var Module = moduleArg;\n\n    // Set up the promise that indicates the Module is initialized\n    var readyPromiseResolve, readyPromiseReject;\n    Module['ready'] = new Promise(function (resolve, reject) {\n      readyPromiseResolve = resolve;\n      readyPromiseReject = reject;\n    });\n    [\"_malloc\", \"_free\", \"_archive_read_open\", \"_archive_read_next_header\", \"_archive_read_data\", \"_archive_read_free\", \"_archive_read_close\", \"_archive_read_open_memory\", \"_archive_entry_size\", \"_archive_entry_pathname\", \"_archive_read_new\", \"_memory\", \"_fflush\", \"___indirect_function_table\", \"onRuntimeInitialized\"].forEach(function (prop) {\n      if (!Object.getOwnPropertyDescriptor(Module['ready'], prop)) {\n        Object.defineProperty(Module['ready'], prop, {\n          get: function get() {\n            return abort('You are getting ' + prop + ' on the Promise object, instead of the instance. Use .then() to get called back with the instance, see the MODULARIZE docs in src/settings.js');\n          },\n          set: function set() {\n            return abort('You are setting ' + prop + ' on the Promise object, instead of the instance. Use .then() to get called back with the instance, see the MODULARIZE docs in src/settings.js');\n          }\n        });\n      }\n    });\n\n    // --pre-jses are emitted after the Module integration code, so that they can\n    // refer to Module (if they choose; they can also define Module)\n\n    // Sometimes an existing Module object exists with properties\n    // meant to overwrite the default module functionality. Here\n    // we collect those properties and reapply _after_ we configure\n    // the current environment's defaults to avoid having to be so\n    // defensive during initialization.\n    var moduleOverrides = Object.assign({}, Module);\n    var arguments_ = [];\n    var thisProgram = './this.program';\n    var quit_ = function quit_(status, toThrow) {\n      throw toThrow;\n    };\n\n    // Determine the runtime environment we are in. You can customize this by\n    // setting the ENVIRONMENT setting at compile time (see settings.js).\n\n    var ENVIRONMENT_IS_WEB = true;\n    var ENVIRONMENT_IS_WORKER = false;\n    var ENVIRONMENT_IS_NODE = false;\n    var ENVIRONMENT_IS_SHELL = false;\n    if (Module['ENVIRONMENT']) {\n      throw new Error('Module.ENVIRONMENT has been deprecated. To force the environment, use the ENVIRONMENT compile-time option (for example, -sENVIRONMENT=web or -sENVIRONMENT=node)');\n    }\n\n    // `/` should be present at the end if `scriptDirectory` is not empty\n    var scriptDirectory = '';\n    function locateFile(path) {\n      if (Module['locateFile']) {\n        return Module['locateFile'](path, scriptDirectory);\n      }\n      return scriptDirectory + path;\n    }\n\n    // Hooks that are implemented differently in different runtime environments.\n    var read_, readAsync, readBinary, setWindowTitle;\n    if (ENVIRONMENT_IS_SHELL) {\n      if ((typeof process === \"undefined\" ? \"undefined\" : _typeof(process)) == 'object' && \"function\" === 'function' || (typeof window === \"undefined\" ? \"undefined\" : _typeof(window)) == 'object' || typeof importScripts == 'function') throw new Error('not compiled for this environment (did you build to HTML and try to run it not on the web, or set ENVIRONMENT to something - like node - and run it someplace else - like on the web?)');\n      if (typeof read != 'undefined') {\n        read_ = read;\n      }\n      readBinary = function readBinary(f) {\n        if (typeof readbuffer == 'function') {\n          return new Uint8Array(readbuffer(f));\n        }\n        var data = read(f, 'binary');\n        assert(_typeof(data) == 'object');\n        return data;\n      };\n      readAsync = function readAsync(f, onload, onerror) {\n        setTimeout(function () {\n          return onload(readBinary(f));\n        });\n      };\n      if (typeof clearTimeout == 'undefined') {\n        globalThis.clearTimeout = function (id) {};\n      }\n      if (typeof setTimeout == 'undefined') {\n        // spidermonkey lacks setTimeout but we use it above in readAsync.\n        globalThis.setTimeout = function (f) {\n          return typeof f == 'function' ? f() : abort();\n        };\n      }\n      if (typeof scriptArgs != 'undefined') {\n        arguments_ = scriptArgs;\n      } else if (typeof arguments != 'undefined') {\n        arguments_ = arguments;\n      }\n      if (typeof quit == 'function') {\n        quit_ = function quit_(status, toThrow) {\n          // Unlike node which has process.exitCode, d8 has no such mechanism. So we\n          // have no way to set the exit code and then let the program exit with\n          // that code when it naturally stops running (say, when all setTimeouts\n          // have completed). For that reason, we must call `quit` - the only way to\n          // set the exit code - but quit also halts immediately.  To increase\n          // consistency with node (and the web) we schedule the actual quit call\n          // using a setTimeout to give the current stack and any exception handlers\n          // a chance to run.  This enables features such as addOnPostRun (which\n          // expected to be able to run code after main returns).\n          setTimeout(function () {\n            if (!(toThrow instanceof ExitStatus)) {\n              var toLog = toThrow;\n              if (toThrow && _typeof(toThrow) == 'object' && toThrow.stack) {\n                toLog = [toThrow, toThrow.stack];\n              }\n              err(\"exiting due to exception: \".concat(toLog));\n            }\n            quit(status);\n          });\n          throw toThrow;\n        };\n      }\n      if (typeof print != 'undefined') {\n        // Prefer to use print/printErr where they exist, as they usually work better.\n        if (typeof console == 'undefined') console = /** @type{!Console} */{};\n        console.log = /** @type{!function(this:Console, ...*): undefined} */print;\n        console.warn = console.error = /** @type{!function(this:Console, ...*): undefined} */typeof printErr != 'undefined' ? printErr : print;\n      }\n    } else\n      // Note that this includes Node.js workers when relevant (pthreads is enabled).\n      // Node.js workers are detected as a combination of ENVIRONMENT_IS_WORKER and\n      // ENVIRONMENT_IS_NODE.\n      if (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER) {\n        if (ENVIRONMENT_IS_WORKER) {\n          // Check worker, not web, since window could be polyfilled\n          scriptDirectory = self.location.href;\n        } else if (typeof document != 'undefined' && document.currentScript) {\n          // web\n          scriptDirectory = document.currentScript.src;\n        }\n        // When MODULARIZE, this JS may be executed later, after document.currentScript\n        // is gone, so we saved it, and we use it here instead of any other info.\n        if (_scriptDir) {\n          scriptDirectory = _scriptDir;\n        }\n        // blob urls look like blob:http://site.com/etc/etc and we cannot infer anything from them.\n        // otherwise, slice off the final part of the url to find the script directory.\n        // if scriptDirectory does not contain a slash, lastIndexOf will return -1,\n        // and scriptDirectory will correctly be replaced with an empty string.\n        // If scriptDirectory contains a query (starting with ?) or a fragment (starting with #),\n        // they are removed because they could contain a slash.\n        if (scriptDirectory.indexOf('blob:') !== 0) {\n          scriptDirectory = scriptDirectory.substr(0, scriptDirectory.replace(/[?#].*/, \"\").lastIndexOf('/') + 1);\n        } else {\n          scriptDirectory = '';\n        }\n        if (!((typeof window === \"undefined\" ? \"undefined\" : _typeof(window)) == 'object' || typeof importScripts == 'function')) throw new Error('not compiled for this environment (did you build to HTML and try to run it not on the web, or set ENVIRONMENT to something - like node - and run it someplace else - like on the web?)');\n\n        // Differentiate the Web Worker from the Node Worker case, as reading must\n        // be done differently.\n        {\n          // include: web_or_worker_shell_read.js\n          read_ = function read_(url) {\n            var xhr = new XMLHttpRequest();\n            xhr.open('GET', url, false);\n            xhr.send(null);\n            return xhr.responseText;\n          };\n          if (ENVIRONMENT_IS_WORKER) {\n            readBinary = function readBinary(url) {\n              var xhr = new XMLHttpRequest();\n              xhr.open('GET', url, false);\n              xhr.responseType = 'arraybuffer';\n              xhr.send(null);\n              return new Uint8Array(/** @type{!ArrayBuffer} */xhr.response);\n            };\n          }\n          readAsync = function readAsync(url, onload, onerror) {\n            var xhr = new XMLHttpRequest();\n            xhr.open('GET', url, true);\n            xhr.responseType = 'arraybuffer';\n            xhr.onload = function () {\n              if (xhr.status == 200 || xhr.status == 0 && xhr.response) {\n                // file URLs can return 0\n                onload(xhr.response);\n                return;\n              }\n              onerror();\n            };\n            xhr.onerror = onerror;\n            xhr.send(null);\n          };\n\n          // end include: web_or_worker_shell_read.js\n        }\n        setWindowTitle = function setWindowTitle(title) {\n          return document.title = title;\n        };\n      } else {\n        throw new Error('environment detection error');\n      }\n    var out = Module['print'] || console.log.bind(console);\n    var err = Module['printErr'] || console.error.bind(console);\n\n    // Merge back in the overrides\n    Object.assign(Module, moduleOverrides);\n    // Free the object hierarchy contained in the overrides, this lets the GC\n    // reclaim data used e.g. in memoryInitializerRequest, which is a large typed array.\n    moduleOverrides = null;\n    checkIncomingModuleAPI();\n\n    // Emit code to handle expected values on the Module object. This applies Module.x\n    // to the proper local x. This has two benefits: first, we only emit it if it is\n    // expected to arrive, and second, by using a local everywhere else that can be\n    // minified.\n\n    if (Module['arguments']) arguments_ = Module['arguments'];\n    legacyModuleProp('arguments', 'arguments_');\n    if (Module['thisProgram']) thisProgram = Module['thisProgram'];\n    legacyModuleProp('thisProgram', 'thisProgram');\n    if (Module['quit']) quit_ = Module['quit'];\n    legacyModuleProp('quit', 'quit_');\n\n    // perform assertions in shell.js after we set up out() and err(), as otherwise if an assertion fails it cannot print the message\n    // Assertions on removed incoming Module JS APIs.\n    assert(typeof Module['memoryInitializerPrefixURL'] == 'undefined', 'Module.memoryInitializerPrefixURL option was removed, use Module.locateFile instead');\n    assert(typeof Module['pthreadMainPrefixURL'] == 'undefined', 'Module.pthreadMainPrefixURL option was removed, use Module.locateFile instead');\n    assert(typeof Module['cdInitializerPrefixURL'] == 'undefined', 'Module.cdInitializerPrefixURL option was removed, use Module.locateFile instead');\n    assert(typeof Module['filePackagePrefixURL'] == 'undefined', 'Module.filePackagePrefixURL option was removed, use Module.locateFile instead');\n    assert(typeof Module['read'] == 'undefined', 'Module.read option was removed (modify read_ in JS)');\n    assert(typeof Module['readAsync'] == 'undefined', 'Module.readAsync option was removed (modify readAsync in JS)');\n    assert(typeof Module['readBinary'] == 'undefined', 'Module.readBinary option was removed (modify readBinary in JS)');\n    assert(typeof Module['setWindowTitle'] == 'undefined', 'Module.setWindowTitle option was removed (modify setWindowTitle in JS)');\n    assert(typeof Module['TOTAL_MEMORY'] == 'undefined', 'Module.TOTAL_MEMORY has been renamed Module.INITIAL_MEMORY');\n    legacyModuleProp('asm', 'wasmExports');\n    legacyModuleProp('read', 'read_');\n    legacyModuleProp('readAsync', 'readAsync');\n    legacyModuleProp('readBinary', 'readBinary');\n    legacyModuleProp('setWindowTitle', 'setWindowTitle');\n    var IDBFS = 'IDBFS is no longer included by default; build with -lidbfs.js';\n    var PROXYFS = 'PROXYFS is no longer included by default; build with -lproxyfs.js';\n    var WORKERFS = 'WORKERFS is no longer included by default; build with -lworkerfs.js';\n    var FETCHFS = 'FETCHFS is no longer included by default; build with -lfetchfs.js';\n    var ICASEFS = 'ICASEFS is no longer included by default; build with -licasefs.js';\n    var JSFILEFS = 'JSFILEFS is no longer included by default; build with -ljsfilefs.js';\n    var OPFS = 'OPFS is no longer included by default; build with -lopfs.js';\n    var NODEFS = 'NODEFS is no longer included by default; build with -lnodefs.js';\n    assert(!ENVIRONMENT_IS_WORKER, \"worker environment detected but not enabled at build time.  Add 'worker' to `-sENVIRONMENT` to enable.\");\n    assert(!ENVIRONMENT_IS_NODE, \"node environment detected but not enabled at build time.  Add 'node' to `-sENVIRONMENT` to enable.\");\n    assert(!ENVIRONMENT_IS_SHELL, \"shell environment detected but not enabled at build time.  Add 'shell' to `-sENVIRONMENT` to enable.\");\n\n    // end include: shell.js\n    // include: preamble.js\n    // === Preamble library stuff ===\n\n    // Documentation for the public APIs defined in this file must be updated in:\n    //    site/source/docs/api_reference/preamble.js.rst\n    // A prebuilt local version of the documentation is available at:\n    //    site/build/text/docs/api_reference/preamble.js.txt\n    // You can also build docs locally as HTML or other formats in site/\n    // An online HTML version (which may be of a different version of Emscripten)\n    //    is up at http://kripken.github.io/emscripten-site/docs/api_reference/preamble.js.html\n\n    var wasmBinary;\n    if (Module['wasmBinary']) wasmBinary = Module['wasmBinary'];\n    legacyModuleProp('wasmBinary', 'wasmBinary');\n    var noExitRuntime = Module['noExitRuntime'] || true;\n    legacyModuleProp('noExitRuntime', 'noExitRuntime');\n    if ((typeof WebAssembly === \"undefined\" ? \"undefined\" : _typeof(WebAssembly)) != 'object') {\n      abort('no native wasm support detected');\n    }\n\n    // Wasm globals\n\n    var wasmMemory;\n\n    //========================================\n    // Runtime essentials\n    //========================================\n\n    // whether we are quitting the application. no code should run after this.\n    // set in exit() and abort()\n    var ABORT = false;\n\n    // set by exit() and abort().  Passed to 'onExit' handler.\n    // NOTE: This is also used as the process return code code in shell environments\n    // but only when noExitRuntime is false.\n    var EXITSTATUS;\n\n    /** @type {function(*, string=)} */\n    function assert(condition, text) {\n      if (!condition) {\n        abort('Assertion failed' + (text ? ': ' + text : ''));\n      }\n    }\n\n    // We used to include malloc/free by default in the past. Show a helpful error in\n    // builds with assertions.\n\n    // Memory management\n\n    var HEAP, /** @type {!Int8Array} */\n      HEAP8, /** @type {!Uint8Array} */\n      HEAPU8, /** @type {!Int16Array} */\n      HEAP16, /** @type {!Uint16Array} */\n      HEAPU16, /** @type {!Int32Array} */\n      HEAP32, /** @type {!Uint32Array} */\n      HEAPU32, /** @type {!Float32Array} */\n      HEAPF32, /** @type {!Float64Array} */\n      HEAPF64;\n    function updateMemoryViews() {\n      var b = wasmMemory.buffer;\n      Module['HEAP8'] = HEAP8 = new Int8Array(b);\n      Module['HEAP16'] = HEAP16 = new Int16Array(b);\n      Module['HEAPU8'] = HEAPU8 = new Uint8Array(b);\n      Module['HEAPU16'] = HEAPU16 = new Uint16Array(b);\n      Module['HEAP32'] = HEAP32 = new Int32Array(b);\n      Module['HEAPU32'] = HEAPU32 = new Uint32Array(b);\n      Module['HEAPF32'] = HEAPF32 = new Float32Array(b);\n      Module['HEAPF64'] = HEAPF64 = new Float64Array(b);\n    }\n    assert(!Module['STACK_SIZE'], 'STACK_SIZE can no longer be set at runtime.  Use -sSTACK_SIZE at link time');\n    assert(typeof Int32Array != 'undefined' && typeof Float64Array !== 'undefined' && Int32Array.prototype.subarray != undefined && Int32Array.prototype.set != undefined, 'JS engine does not provide full typed array support');\n\n    // If memory is defined in wasm, the user can't provide it, or set INITIAL_MEMORY\n    assert(!Module['wasmMemory'], 'Use of `wasmMemory` detected.  Use -sIMPORTED_MEMORY to define wasmMemory externally');\n    assert(!Module['INITIAL_MEMORY'], 'Detected runtime INITIAL_MEMORY setting.  Use -sIMPORTED_MEMORY to define wasmMemory dynamically');\n\n    // include: runtime_init_table.js\n    // In regular non-RELOCATABLE mode the table is exported\n    // from the wasm module and this will be assigned once\n    // the exports are available.\n    var wasmTable;\n    // end include: runtime_init_table.js\n    // include: runtime_stack_check.js\n    // Initializes the stack cookie. Called at the startup of main and at the startup of each thread in pthreads mode.\n    function writeStackCookie() {\n      var max = _emscripten_stack_get_end2();\n      assert((max & 3) == 0);\n      // If the stack ends at address zero we write our cookies 4 bytes into the\n      // stack.  This prevents interference with SAFE_HEAP and ASAN which also\n      // monitor writes to address zero.\n      if (max == 0) {\n        max += 4;\n      }\n      // The stack grow downwards towards _emscripten_stack_get_end.\n      // We write cookies to the final two words in the stack and detect if they are\n      // ever overwritten.\n      HEAPU32[max >> 2] = 0x02135467;\n      HEAPU32[max + 4 >> 2] = 0x89BACDFE;\n      // Also test the global address 0 for integrity.\n      HEAPU32[0 >> 2] = 1668509029;\n    }\n    function checkStackCookie() {\n      if (ABORT) return;\n      var max = _emscripten_stack_get_end2();\n      // See writeStackCookie().\n      if (max == 0) {\n        max += 4;\n      }\n      var cookie1 = HEAPU32[max >> 2];\n      var cookie2 = HEAPU32[max + 4 >> 2];\n      if (cookie1 != 0x02135467 || cookie2 != 0x89BACDFE) {\n        abort(\"Stack overflow! Stack cookie has been overwritten at \".concat(ptrToString(max), \", expected hex dwords 0x89BACDFE and 0x2135467, but received \").concat(ptrToString(cookie2), \" \").concat(ptrToString(cookie1)));\n      }\n      // Also test the global address 0 for integrity.\n      if (HEAPU32[0 >> 2] != 0x63736d65 /* 'emsc' */) {\n        abort('Runtime error: The application has corrupted its heap memory area (address zero)!');\n      }\n    }\n    // end include: runtime_stack_check.js\n    // include: runtime_assertions.js\n    // Endianness check\n    (function () {\n      var h16 = new Int16Array(1);\n      var h8 = new Int8Array(h16.buffer);\n      h16[0] = 0x6373;\n      if (h8[0] !== 0x73 || h8[1] !== 0x63) throw 'Runtime error: expected the system to be little-endian! (Run with -sSUPPORT_BIG_ENDIAN to bypass)';\n    })();\n\n    // end include: runtime_assertions.js\n    var __ATPRERUN__ = []; // functions called before the runtime is initialized\n    var __ATINIT__ = []; // functions called during startup\n    var __ATEXIT__ = []; // functions called during shutdown\n    var __ATPOSTRUN__ = []; // functions called after the main() is called\n\n    var runtimeInitialized = false;\n    var runtimeKeepaliveCounter = 0;\n    function keepRuntimeAlive() {\n      return noExitRuntime || runtimeKeepaliveCounter > 0;\n    }\n    function preRun() {\n      if (Module['preRun']) {\n        if (typeof Module['preRun'] == 'function') Module['preRun'] = [Module['preRun']];\n        while (Module['preRun'].length) {\n          addOnPreRun(Module['preRun'].shift());\n        }\n      }\n      callRuntimeCallbacks(__ATPRERUN__);\n    }\n    function initRuntime() {\n      assert(!runtimeInitialized);\n      runtimeInitialized = true;\n      checkStackCookie();\n      if (!Module[\"noFSInit\"] && !FS.init.initialized) FS.init();\n      FS.ignorePermissions = false;\n      TTY.init();\n      callRuntimeCallbacks(__ATINIT__);\n    }\n    function postRun() {\n      checkStackCookie();\n      if (Module['postRun']) {\n        if (typeof Module['postRun'] == 'function') Module['postRun'] = [Module['postRun']];\n        while (Module['postRun'].length) {\n          addOnPostRun(Module['postRun'].shift());\n        }\n      }\n      callRuntimeCallbacks(__ATPOSTRUN__);\n    }\n    function addOnPreRun(cb) {\n      __ATPRERUN__.unshift(cb);\n    }\n    function addOnInit(cb) {\n      __ATINIT__.unshift(cb);\n    }\n    function addOnExit(cb) {}\n    function addOnPostRun(cb) {\n      __ATPOSTRUN__.unshift(cb);\n    }\n\n    // include: runtime_math.js\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/imul\n\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/fround\n\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/clz32\n\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc\n\n    assert(Math.imul, 'This browser does not support Math.imul(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill');\n    assert(Math.fround, 'This browser does not support Math.fround(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill');\n    assert(Math.clz32, 'This browser does not support Math.clz32(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill');\n    assert(Math.trunc, 'This browser does not support Math.trunc(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill');\n    // end include: runtime_math.js\n    // A counter of dependencies for calling run(). If we need to\n    // do asynchronous work before running, increment this and\n    // decrement it. Incrementing must happen in a place like\n    // Module.preRun (used by emcc to add file preloading).\n    // Note that you can add dependencies in preRun, even though\n    // it happens right before run - run will be postponed until\n    // the dependencies are met.\n    var runDependencies = 0;\n    var runDependencyWatcher = null;\n    var dependenciesFulfilled = null; // overridden to take different actions when all run dependencies are fulfilled\n    var runDependencyTracking = {};\n    function getUniqueRunDependency(id) {\n      var orig = id;\n      while (1) {\n        if (!runDependencyTracking[id]) return id;\n        id = orig + Math.random();\n      }\n    }\n    function addRunDependency(id) {\n      runDependencies++;\n      if (Module['monitorRunDependencies']) {\n        Module['monitorRunDependencies'](runDependencies);\n      }\n      if (id) {\n        assert(!runDependencyTracking[id]);\n        runDependencyTracking[id] = 1;\n        if (runDependencyWatcher === null && typeof setInterval != 'undefined') {\n          // Check for missing dependencies every few seconds\n          runDependencyWatcher = setInterval(function () {\n            if (ABORT) {\n              clearInterval(runDependencyWatcher);\n              runDependencyWatcher = null;\n              return;\n            }\n            var shown = false;\n            for (var dep in runDependencyTracking) {\n              if (!shown) {\n                shown = true;\n                err('still waiting on run dependencies:');\n              }\n              err(\"dependency: \".concat(dep));\n            }\n            if (shown) {\n              err('(end of list)');\n            }\n          }, 10000);\n        }\n      } else {\n        err('warning: run dependency added without ID');\n      }\n    }\n    function removeRunDependency(id) {\n      runDependencies--;\n      if (Module['monitorRunDependencies']) {\n        Module['monitorRunDependencies'](runDependencies);\n      }\n      if (id) {\n        assert(runDependencyTracking[id]);\n        delete runDependencyTracking[id];\n      } else {\n        err('warning: run dependency removed without ID');\n      }\n      if (runDependencies == 0) {\n        if (runDependencyWatcher !== null) {\n          clearInterval(runDependencyWatcher);\n          runDependencyWatcher = null;\n        }\n        if (dependenciesFulfilled) {\n          var callback = dependenciesFulfilled;\n          dependenciesFulfilled = null;\n          callback(); // can add another dependenciesFulfilled\n        }\n      }\n    }\n\n    /** @param {string|number=} what */\n    function abort(what) {\n      if (Module['onAbort']) {\n        Module['onAbort'](what);\n      }\n      what = 'Aborted(' + what + ')';\n      // TODO(sbc): Should we remove printing and leave it up to whoever\n      // catches the exception?\n      err(what);\n      ABORT = true;\n      EXITSTATUS = 1;\n\n      // Use a wasm runtime error, because a JS error might be seen as a foreign\n      // exception, which means we'd run destructors on it. We need the error to\n      // simply make the program stop.\n      // FIXME This approach does not work in Wasm EH because it currently does not assume\n      // all RuntimeErrors are from traps; it decides whether a RuntimeError is from\n      // a trap or not based on a hidden field within the object. So at the moment\n      // we don't have a way of throwing a wasm trap from JS. TODO Make a JS API that\n      // allows this in the wasm spec.\n\n      // Suppress closure compiler warning here. Closure compiler's builtin extern\n      // defintion for WebAssembly.RuntimeError claims it takes no arguments even\n      // though it can.\n      // TODO(https://github.com/google/closure-compiler/pull/3913): Remove if/when upstream closure gets fixed.\n      /** @suppress {checkTypes} */\n      var e = new WebAssembly.RuntimeError(what);\n      readyPromiseReject(e);\n      // Throw the error whether or not MODULARIZE is set because abort is used\n      // in code paths apart from instantiation where an exception is expected\n      // to be thrown when abort is called.\n      throw e;\n    }\n\n    // include: memoryprofiler.js\n    // end include: memoryprofiler.js\n    // include: URIUtils.js\n    // Prefix of data URIs emitted by SINGLE_FILE and related options.\n    var dataURIPrefix = 'data:application/octet-stream;base64,';\n\n    // Indicates whether filename is a base64 data URI.\n    function isDataURI(filename) {\n      // Prefix of data URIs emitted by SINGLE_FILE and related options.\n      return filename.startsWith(dataURIPrefix);\n    }\n\n    // Indicates whether filename is delivered via file protocol (as opposed to http/https)\n    function isFileURI(filename) {\n      return filename.startsWith('file://');\n    }\n    // end include: URIUtils.js\n    function createExportWrapper(name) {\n      return function () {\n        assert(runtimeInitialized, \"native function `\".concat(name, \"` called before runtime initialization\"));\n        var f = wasmExports[name];\n        assert(f, \"exported native function `\".concat(name, \"` not found\"));\n        return f.apply(null, arguments);\n      };\n    }\n\n    // include: runtime_exceptions.js\n    // end include: runtime_exceptions.js\n    var wasmBinaryFile;\n    wasmBinaryFile = 'libarchive.wasm';\n    if (!isDataURI(wasmBinaryFile)) {\n      wasmBinaryFile = locateFile(wasmBinaryFile);\n    }\n    function getBinarySync(file) {\n      if (file == wasmBinaryFile && wasmBinary) {\n        return new Uint8Array(wasmBinary);\n      }\n      if (readBinary) {\n        return readBinary(file);\n      }\n      throw \"both async and sync fetching of the wasm failed\";\n    }\n    function getBinaryPromise(binaryFile) {\n      // If we don't have the binary yet, try to load it asynchronously.\n      // Fetch has some additional restrictions over XHR, like it can't be used on a file:// url.\n      // See https://github.com/github/fetch/pull/92#issuecomment-140665932\n      // Cordova or Electron apps are typically loaded from a file:// url.\n      // So use fetch if it is available and the url is not a file, otherwise fall back to XHR.\n      if (!wasmBinary && (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER)) {\n        if (typeof fetch == 'function') {\n          return fetch(binaryFile, {\n            credentials: 'same-origin'\n          }).then(function (response) {\n            if (!response['ok']) {\n              throw \"failed to load wasm binary file at '\" + binaryFile + \"'\";\n            }\n            return response['arrayBuffer']();\n          })[\"catch\"](function () {\n            return getBinarySync(binaryFile);\n          });\n        }\n      }\n\n      // Otherwise, getBinarySync should be able to get it synchronously\n      return Promise.resolve().then(function () {\n        return getBinarySync(binaryFile);\n      });\n    }\n    function instantiateArrayBuffer(binaryFile, imports, receiver) {\n      return getBinaryPromise(binaryFile).then(function (binary) {\n        return WebAssembly.instantiate(binary, imports);\n      }).then(function (instance) {\n        return instance;\n      }).then(receiver, function (reason) {\n        err(\"failed to asynchronously prepare wasm: \".concat(reason));\n\n        // Warn on some common problems.\n        if (isFileURI(wasmBinaryFile)) {\n          err(\"warning: Loading from a file URI (\".concat(wasmBinaryFile, \") is not supported in most browsers. See https://emscripten.org/docs/getting_started/FAQ.html#how-do-i-run-a-local-webserver-for-testing-why-does-my-program-stall-in-downloading-or-preparing\"));\n        }\n        abort(reason);\n      });\n    }\n    function instantiateAsync(binary, binaryFile, imports, callback) {\n      if (!binary && typeof WebAssembly.instantiateStreaming == 'function' && !isDataURI(binaryFile) && typeof fetch == 'function') {\n        return fetch(binaryFile, {\n          credentials: 'same-origin'\n        }).then(function (response) {\n          // Suppress closure warning here since the upstream definition for\n          // instantiateStreaming only allows Promise<Repsponse> rather than\n          // an actual Response.\n          // TODO(https://github.com/google/closure-compiler/pull/3913): Remove if/when upstream closure is fixed.\n          /** @suppress {checkTypes} */\n          var result = WebAssembly.instantiateStreaming(response, imports);\n          return result.then(callback, function (reason) {\n            // We expect the most common failure cause to be a bad MIME type for the binary,\n            // in which case falling back to ArrayBuffer instantiation should work.\n            err(\"wasm streaming compile failed: \".concat(reason));\n            err('falling back to ArrayBuffer instantiation');\n            return instantiateArrayBuffer(binaryFile, imports, callback);\n          });\n        });\n      }\n      return instantiateArrayBuffer(binaryFile, imports, callback);\n    }\n\n    // Create the wasm instance.\n    // Receives the wasm imports, returns the exports.\n    function createWasm() {\n      // prepare imports\n      var info = {\n        'env': wasmImports,\n        'wasi_snapshot_preview1': wasmImports\n      };\n      // Load the wasm module and create an instance of using native support in the JS engine.\n      // handle a generated wasm instance, receiving its exports and\n      // performing other necessary setup\n      /** @param {WebAssembly.Module=} module*/\n      function receiveInstance(instance, module) {\n        var exports = instance.exports;\n        wasmExports = exports;\n        wasmMemory = wasmExports['memory'];\n        assert(wasmMemory, \"memory not found in wasm exports\");\n        // This assertion doesn't hold when emscripten is run in --post-link\n        // mode.\n        // TODO(sbc): Read INITIAL_MEMORY out of the wasm file in post-link mode.\n        //assert(wasmMemory.buffer.byteLength === 16777216);\n        updateMemoryViews();\n        wasmTable = wasmExports['__indirect_function_table'];\n        assert(wasmTable, \"table not found in wasm exports\");\n        addOnInit(wasmExports['__wasm_call_ctors']);\n        removeRunDependency('wasm-instantiate');\n        return exports;\n      }\n      // wait for the pthread pool (if any)\n      addRunDependency('wasm-instantiate');\n\n      // Prefer streaming instantiation if available.\n      // Async compilation can be confusing when an error on the page overwrites Module\n      // (for example, if the order of elements is wrong, and the one defining Module is\n      // later), so we save Module and check it later.\n      var trueModule = Module;\n      function receiveInstantiationResult(result) {\n        // 'result' is a ResultObject object which has both the module and instance.\n        // receiveInstance() will swap in the exports (to Module.asm) so they can be called\n        assert(Module === trueModule, 'the Module object should not be replaced during async compilation - perhaps the order of HTML elements is wrong?');\n        trueModule = null;\n        // TODO: Due to Closure regression https://github.com/google/closure-compiler/issues/3193, the above line no longer optimizes out down to the following line.\n        // When the regression is fixed, can restore the above PTHREADS-enabled path.\n        receiveInstance(result['instance']);\n      }\n\n      // User shell pages can write their own Module.instantiateWasm = function(imports, successCallback) callback\n      // to manually instantiate the Wasm module themselves. This allows pages to\n      // run the instantiation parallel to any other async startup actions they are\n      // performing.\n      // Also pthreads and wasm workers initialize the wasm instance through this\n      // path.\n      if (Module['instantiateWasm']) {\n        try {\n          return Module['instantiateWasm'](info, receiveInstance);\n        } catch (e) {\n          err(\"Module.instantiateWasm callback failed with error: \".concat(e));\n          // If instantiation fails, reject the module ready promise.\n          readyPromiseReject(e);\n        }\n      }\n\n      // If instantiation fails, reject the module ready promise.\n      instantiateAsync(wasmBinary, wasmBinaryFile, info, receiveInstantiationResult)[\"catch\"](readyPromiseReject);\n      return {}; // no exports yet; we'll fill them in later\n    }\n\n    // Globals used by JS i64 conversions (see makeSetValue)\n    var tempDouble;\n    var tempI64;\n\n    // include: runtime_debug.js\n    function legacyModuleProp(prop, newName) {\n      var incomming = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n      if (!Object.getOwnPropertyDescriptor(Module, prop)) {\n        Object.defineProperty(Module, prop, {\n          configurable: true,\n          get: function get() {\n            var extra = incomming ? ' (the initial value can be provided on Module, but after startup the value is only looked for on a local variable of that name)' : '';\n            abort(\"`Module.\".concat(prop, \"` has been replaced by `\").concat(newName, \"`\") + extra);\n          }\n        });\n      }\n    }\n    function ignoredModuleProp(prop) {\n      if (Object.getOwnPropertyDescriptor(Module, prop)) {\n        abort(\"`Module.\".concat(prop, \"` was supplied but `\").concat(prop, \"` not included in INCOMING_MODULE_JS_API\"));\n      }\n    }\n\n    // forcing the filesystem exports a few things by default\n    function isExportedByForceFilesystem(name) {\n      return name === 'FS_createPath' || name === 'FS_createDataFile' || name === 'FS_createPreloadedFile' || name === 'FS_unlink' || name === 'addRunDependency' ||\n      // The old FS has some functionality that WasmFS lacks.\n      name === 'FS_createLazyFile' || name === 'FS_createDevice' || name === 'removeRunDependency';\n    }\n    function missingGlobal(sym, msg) {\n      if (typeof globalThis !== 'undefined') {\n        Object.defineProperty(globalThis, sym, {\n          configurable: true,\n          get: function get() {\n            _warnOnce('`' + sym + '` is not longer defined by emscripten. ' + msg);\n            return undefined;\n          }\n        });\n      }\n    }\n    missingGlobal('buffer', 'Please use HEAP8.buffer or wasmMemory.buffer');\n    missingGlobal('asm', 'Please use wasmExports instead');\n    function missingLibrarySymbol(sym) {\n      if (typeof globalThis !== 'undefined' && !Object.getOwnPropertyDescriptor(globalThis, sym)) {\n        Object.defineProperty(globalThis, sym, {\n          configurable: true,\n          get: function get() {\n            // Can't `abort()` here because it would break code that does runtime\n            // checks.  e.g. `if (typeof SDL === 'undefined')`.\n            var msg = '`' + sym + '` is a library symbol and not included by default; add it to your library.js __deps or to DEFAULT_LIBRARY_FUNCS_TO_INCLUDE on the command line';\n            // DEFAULT_LIBRARY_FUNCS_TO_INCLUDE requires the name as it appears in\n            // library.js, which means $name for a JS name with no prefix, or name\n            // for a JS name like _name.\n            var librarySymbol = sym;\n            if (!librarySymbol.startsWith('_')) {\n              librarySymbol = '$' + sym;\n            }\n            msg += \" (e.g. -sDEFAULT_LIBRARY_FUNCS_TO_INCLUDE='\" + librarySymbol + \"')\";\n            if (isExportedByForceFilesystem(sym)) {\n              msg += '. Alternatively, forcing filesystem support (-sFORCE_FILESYSTEM) can export this for you';\n            }\n            _warnOnce(msg);\n            return undefined;\n          }\n        });\n      }\n      // Any symbol that is not included from the JS libary is also (by definition)\n      // not exported on the Module object.\n      unexportedRuntimeSymbol(sym);\n    }\n    function unexportedRuntimeSymbol(sym) {\n      if (!Object.getOwnPropertyDescriptor(Module, sym)) {\n        Object.defineProperty(Module, sym, {\n          configurable: true,\n          get: function get() {\n            var msg = \"'\" + sym + \"' was not exported. add it to EXPORTED_RUNTIME_METHODS (see the Emscripten FAQ)\";\n            if (isExportedByForceFilesystem(sym)) {\n              msg += '. Alternatively, forcing filesystem support (-sFORCE_FILESYSTEM) can export this for you';\n            }\n            abort(msg);\n          }\n        });\n      }\n    }\n\n    // Used by XXXXX_DEBUG settings to output debug messages.\n    function dbg(text) {\n      // TODO(sbc): Make this configurable somehow.  Its not always convenient for\n      // logging to show up as warnings.\n      console.warn.apply(console, arguments);\n    }\n    // end include: runtime_debug.js\n    // === Body ===\n\n    // end include: preamble.js\n\n    /** @constructor */\n    function ExitStatus(status) {\n      this.name = 'ExitStatus';\n      this.message = \"Program terminated with exit(\".concat(status, \")\");\n      this.status = status;\n    }\n    var callRuntimeCallbacks = function callRuntimeCallbacks(callbacks) {\n      while (callbacks.length > 0) {\n        // Pass the module as the first argument.\n        callbacks.shift()(Module);\n      }\n    };\n\n    /**\n     * @param {number} ptr\n     * @param {string} type\n     */\n    function getValue(ptr) {\n      var type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'i8';\n      if (type.endsWith('*')) type = '*';\n      switch (type) {\n        case 'i1':\n          return HEAP8[ptr >> 0];\n        case 'i8':\n          return HEAP8[ptr >> 0];\n        case 'i16':\n          return HEAP16[ptr >> 1];\n        case 'i32':\n          return HEAP32[ptr >> 2];\n        case 'i64':\n          abort('to do getValue(i64) use WASM_BIGINT');\n        case 'float':\n          return HEAPF32[ptr >> 2];\n        case 'double':\n          return HEAPF64[ptr >> 3];\n        case '*':\n          return HEAPU32[ptr >> 2];\n        default:\n          abort(\"invalid type for getValue: \".concat(type));\n      }\n    }\n    var ptrToString = function ptrToString(ptr) {\n      assert(typeof ptr === 'number');\n      // With CAN_ADDRESS_2GB or MEMORY64, pointers are already unsigned.\n      ptr >>>= 0;\n      return '0x' + ptr.toString(16).padStart(8, '0');\n    };\n\n    /**\n     * @param {number} ptr\n     * @param {number} value\n     * @param {string} type\n     */\n    function setValue(ptr, value) {\n      var type = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 'i8';\n      if (type.endsWith('*')) type = '*';\n      switch (type) {\n        case 'i1':\n          HEAP8[ptr >> 0] = value;\n          break;\n        case 'i8':\n          HEAP8[ptr >> 0] = value;\n          break;\n        case 'i16':\n          HEAP16[ptr >> 1] = value;\n          break;\n        case 'i32':\n          HEAP32[ptr >> 2] = value;\n          break;\n        case 'i64':\n          abort('to do setValue(i64) use WASM_BIGINT');\n        case 'float':\n          HEAPF32[ptr >> 2] = value;\n          break;\n        case 'double':\n          HEAPF64[ptr >> 3] = value;\n          break;\n        case '*':\n          HEAPU32[ptr >> 2] = value;\n          break;\n        default:\n          abort(\"invalid type for setValue: \".concat(type));\n      }\n    }\n    var _warnOnce = function warnOnce(text) {\n      if (!_warnOnce.shown) _warnOnce.shown = {};\n      if (!_warnOnce.shown[text]) {\n        _warnOnce.shown[text] = 1;\n        err(text);\n      }\n    };\n    var _abort = function _abort() {\n      abort('native code called abort()');\n    };\n    var _emscripten_memcpy_big = function _emscripten_memcpy_big(dest, src, num) {\n      return HEAPU8.copyWithin(dest, src, src + num);\n    };\n    var getHeapMax = function getHeapMax() {\n      return HEAPU8.length;\n    };\n    var abortOnCannotGrowMemory = function abortOnCannotGrowMemory(requestedSize) {\n      abort(\"Cannot enlarge memory arrays to size \".concat(requestedSize, \" bytes (OOM). Either (1) compile with -sINITIAL_MEMORY=X with X higher than the current value \").concat(HEAP8.length, \", (2) compile with -sALLOW_MEMORY_GROWTH which allows increasing the size at runtime, or (3) if you want malloc to return NULL (0) instead of this abort, compile with -sABORTING_MALLOC=0\"));\n    };\n    var _emscripten_resize_heap = function _emscripten_resize_heap(requestedSize) {\n      var oldSize = HEAPU8.length;\n      // With CAN_ADDRESS_2GB or MEMORY64, pointers are already unsigned.\n      requestedSize >>>= 0;\n      abortOnCannotGrowMemory(requestedSize);\n    };\n    var UTF8Decoder = typeof TextDecoder != 'undefined' ? new TextDecoder('utf8') : undefined;\n\n    /**\n     * Given a pointer 'idx' to a null-terminated UTF8-encoded string in the given\n     * array that contains uint8 values, returns a copy of that string as a\n     * Javascript String object.\n     * heapOrArray is either a regular array, or a JavaScript typed array view.\n     * @param {number} idx\n     * @param {number=} maxBytesToRead\n     * @return {string}\n     */\n    var UTF8ArrayToString = function UTF8ArrayToString(heapOrArray, idx, maxBytesToRead) {\n      var endIdx = idx + maxBytesToRead;\n      var endPtr = idx;\n      // TextDecoder needs to know the byte length in advance, it doesn't stop on\n      // null terminator by itself.  Also, use the length info to avoid running tiny\n      // strings through TextDecoder, since .subarray() allocates garbage.\n      // (As a tiny code save trick, compare endPtr against endIdx using a negation,\n      // so that undefined means Infinity)\n      while (heapOrArray[endPtr] && !(endPtr >= endIdx)) ++endPtr;\n      if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {\n        return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr));\n      }\n      var str = '';\n      // If building with TextDecoder, we have already computed the string length\n      // above, so test loop end condition against that\n      while (idx < endPtr) {\n        // For UTF8 byte structure, see:\n        // http://en.wikipedia.org/wiki/UTF-8#Description\n        // https://www.ietf.org/rfc/rfc2279.txt\n        // https://tools.ietf.org/html/rfc3629\n        var u0 = heapOrArray[idx++];\n        if (!(u0 & 0x80)) {\n          str += String.fromCharCode(u0);\n          continue;\n        }\n        var u1 = heapOrArray[idx++] & 63;\n        if ((u0 & 0xE0) == 0xC0) {\n          str += String.fromCharCode((u0 & 31) << 6 | u1);\n          continue;\n        }\n        var u2 = heapOrArray[idx++] & 63;\n        if ((u0 & 0xF0) == 0xE0) {\n          u0 = (u0 & 15) << 12 | u1 << 6 | u2;\n        } else {\n          if ((u0 & 0xF8) != 0xF0) _warnOnce('Invalid UTF-8 leading byte ' + ptrToString(u0) + ' encountered when deserializing a UTF-8 string in wasm memory to a JS string!');\n          u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heapOrArray[idx++] & 63;\n        }\n        if (u0 < 0x10000) {\n          str += String.fromCharCode(u0);\n        } else {\n          var ch = u0 - 0x10000;\n          str += String.fromCharCode(0xD800 | ch >> 10, 0xDC00 | ch & 0x3FF);\n        }\n      }\n      return str;\n    };\n\n    /**\n     * Given a pointer 'ptr' to a null-terminated UTF8-encoded string in the\n     * emscripten HEAP, returns a copy of that string as a Javascript String object.\n     *\n     * @param {number} ptr\n     * @param {number=} maxBytesToRead - An optional length that specifies the\n     *   maximum number of bytes to read. You can omit this parameter to scan the\n     *   string until the first 0 byte. If maxBytesToRead is passed, and the string\n     *   at [ptr, ptr+maxBytesToReadr[ contains a null byte in the middle, then the\n     *   string will cut short at that byte index (i.e. maxBytesToRead will not\n     *   produce a string of exact length [ptr, ptr+maxBytesToRead[) N.B. mixing\n     *   frequent uses of UTF8ToString() with and without maxBytesToRead may throw\n     *   JS JIT optimizations off, so it is worth to consider consistently using one\n     * @return {string}\n     */\n    var UTF8ToString = function UTF8ToString(ptr, maxBytesToRead) {\n      assert(typeof ptr == 'number');\n      return ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : '';\n    };\n    var SYSCALLS = {\n      varargs: undefined,\n      get: function get() {\n        assert(SYSCALLS.varargs != undefined);\n        var ret = HEAP32[SYSCALLS.varargs >> 2];\n        SYSCALLS.varargs += 4;\n        return ret;\n      },\n      getp: function getp() {\n        return SYSCALLS.get();\n      },\n      getStr: function getStr(ptr) {\n        var ret = UTF8ToString(ptr);\n        return ret;\n      }\n    };\n    var _proc_exit = function _proc_exit(code) {\n      EXITSTATUS = code;\n      if (!keepRuntimeAlive()) {\n        if (Module['onExit']) Module['onExit'](code);\n        ABORT = true;\n      }\n      quit_(code, new ExitStatus(code));\n    };\n    /** @suppress {duplicate } */\n    /** @param {boolean|number=} implicit */\n    var exitJS = function exitJS(status, implicit) {\n      EXITSTATUS = status;\n      checkUnflushedContent();\n\n      // if exit() was called explicitly, warn the user if the runtime isn't actually being shut down\n      if (keepRuntimeAlive() && !implicit) {\n        var msg = \"program exited (with status: \".concat(status, \"), but keepRuntimeAlive() is set (counter=\").concat(runtimeKeepaliveCounter, \") due to an async operation, so halting execution but not exiting the runtime or preventing further async execution (you can use emscripten_force_exit, if you want to force a true shutdown)\");\n        readyPromiseReject(msg);\n        err(msg);\n      }\n      _proc_exit(status);\n    };\n    var _exit = exitJS;\n    var printCharBuffers = [null, [], []];\n    var printChar = function printChar(stream, curr) {\n      var buffer = printCharBuffers[stream];\n      assert(buffer);\n      if (curr === 0 || curr === 10) {\n        (stream === 1 ? out : err)(UTF8ArrayToString(buffer, 0));\n        buffer.length = 0;\n      } else {\n        buffer.push(curr);\n      }\n    };\n    var flush_NO_FILESYSTEM = function flush_NO_FILESYSTEM() {\n      // flush anything remaining in the buffers during shutdown\n      _fflush(0);\n      if (printCharBuffers[1].length) printChar(1, 10);\n      if (printCharBuffers[2].length) printChar(2, 10);\n    };\n    var _fd_write = function _fd_write(fd, iov, iovcnt, pnum) {\n      // hack to support printf in SYSCALLS_REQUIRE_FILESYSTEM=0\n      var num = 0;\n      for (var i = 0; i < iovcnt; i++) {\n        var ptr = HEAPU32[iov >> 2];\n        var len = HEAPU32[iov + 4 >> 2];\n        iov += 8;\n        for (var j = 0; j < len; j++) {\n          printChar(fd, HEAPU8[ptr + j]);\n        }\n        num += len;\n      }\n      HEAPU32[pnum >> 2] = num;\n      return 0;\n    };\n    var getCFunc = function getCFunc(ident) {\n      var func = Module['_' + ident]; // closure exported function\n      assert(func, 'Cannot call unknown function ' + ident + ', make sure it is exported');\n      return func;\n    };\n    var writeArrayToMemory = function writeArrayToMemory(array, buffer) {\n      assert(array.length >= 0, 'writeArrayToMemory array must have a length (should be an array or typed array)');\n      HEAP8.set(array, buffer);\n    };\n    var lengthBytesUTF8 = function lengthBytesUTF8(str) {\n      var len = 0;\n      for (var i = 0; i < str.length; ++i) {\n        // Gotcha: charCodeAt returns a 16-bit word that is a UTF-16 encoded code\n        // unit, not a Unicode code point of the character! So decode\n        // UTF16->UTF32->UTF8.\n        // See http://unicode.org/faq/utf_bom.html#utf16-3\n        var c = str.charCodeAt(i); // possibly a lead surrogate\n        if (c <= 0x7F) {\n          len++;\n        } else if (c <= 0x7FF) {\n          len += 2;\n        } else if (c >= 0xD800 && c <= 0xDFFF) {\n          len += 4;\n          ++i;\n        } else {\n          len += 3;\n        }\n      }\n      return len;\n    };\n    var stringToUTF8Array = function stringToUTF8Array(str, heap, outIdx, maxBytesToWrite) {\n      assert(typeof str === 'string');\n      // Parameter maxBytesToWrite is not optional. Negative values, 0, null,\n      // undefined and false each don't write out any bytes.\n      if (!(maxBytesToWrite > 0)) return 0;\n      var startIdx = outIdx;\n      var endIdx = outIdx + maxBytesToWrite - 1; // -1 for string null terminator.\n      for (var i = 0; i < str.length; ++i) {\n        // Gotcha: charCodeAt returns a 16-bit word that is a UTF-16 encoded code\n        // unit, not a Unicode code point of the character! So decode\n        // UTF16->UTF32->UTF8.\n        // See http://unicode.org/faq/utf_bom.html#utf16-3\n        // For UTF8 byte structure, see http://en.wikipedia.org/wiki/UTF-8#Description\n        // and https://www.ietf.org/rfc/rfc2279.txt\n        // and https://tools.ietf.org/html/rfc3629\n        var u = str.charCodeAt(i); // possibly a lead surrogate\n        if (u >= 0xD800 && u <= 0xDFFF) {\n          var u1 = str.charCodeAt(++i);\n          u = 0x10000 + ((u & 0x3FF) << 10) | u1 & 0x3FF;\n        }\n        if (u <= 0x7F) {\n          if (outIdx >= endIdx) break;\n          heap[outIdx++] = u;\n        } else if (u <= 0x7FF) {\n          if (outIdx + 1 >= endIdx) break;\n          heap[outIdx++] = 0xC0 | u >> 6;\n          heap[outIdx++] = 0x80 | u & 63;\n        } else if (u <= 0xFFFF) {\n          if (outIdx + 2 >= endIdx) break;\n          heap[outIdx++] = 0xE0 | u >> 12;\n          heap[outIdx++] = 0x80 | u >> 6 & 63;\n          heap[outIdx++] = 0x80 | u & 63;\n        } else {\n          if (outIdx + 3 >= endIdx) break;\n          if (u > 0x10FFFF) _warnOnce('Invalid Unicode code point ' + ptrToString(u) + ' encountered when serializing a JS string to a UTF-8 string in wasm memory! (Valid unicode code points should be in range 0-0x10FFFF).');\n          heap[outIdx++] = 0xF0 | u >> 18;\n          heap[outIdx++] = 0x80 | u >> 12 & 63;\n          heap[outIdx++] = 0x80 | u >> 6 & 63;\n          heap[outIdx++] = 0x80 | u & 63;\n        }\n      }\n      // Null-terminate the pointer to the buffer.\n      heap[outIdx] = 0;\n      return outIdx - startIdx;\n    };\n    var stringToUTF8 = function stringToUTF8(str, outPtr, maxBytesToWrite) {\n      assert(typeof maxBytesToWrite == 'number', 'stringToUTF8(str, outPtr, maxBytesToWrite) is missing the third parameter that specifies the length of the output buffer!');\n      return stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);\n    };\n    var stringToUTF8OnStack = function stringToUTF8OnStack(str) {\n      var size = lengthBytesUTF8(str) + 1;\n      var ret = stackAlloc(size);\n      stringToUTF8(str, ret, size);\n      return ret;\n    };\n\n    /**\n     * @param {string|null=} returnType\n     * @param {Array=} argTypes\n     * @param {Arguments|Array=} args\n     * @param {Object=} opts\n     */\n    var ccall = function ccall(ident, returnType, argTypes, args, opts) {\n      // For fast lookup of conversion functions\n      var toC = {\n        'string': function string(str) {\n          var ret = 0;\n          if (str !== null && str !== undefined && str !== 0) {\n            // null string\n            // at most 4 bytes per UTF-8 code point, +1 for the trailing '\\0'\n            ret = stringToUTF8OnStack(str);\n          }\n          return ret;\n        },\n        'array': function array(arr) {\n          var ret = stackAlloc(arr.length);\n          writeArrayToMemory(arr, ret);\n          return ret;\n        }\n      };\n      function convertReturnValue(ret) {\n        if (returnType === 'string') {\n          return UTF8ToString(ret);\n        }\n        if (returnType === 'boolean') return Boolean(ret);\n        return ret;\n      }\n      var func = getCFunc(ident);\n      var cArgs = [];\n      var stack = 0;\n      assert(returnType !== 'array', 'Return type should not be \"array\".');\n      if (args) {\n        for (var i = 0; i < args.length; i++) {\n          var converter = toC[argTypes[i]];\n          if (converter) {\n            if (stack === 0) stack = stackSave();\n            cArgs[i] = converter(args[i]);\n          } else {\n            cArgs[i] = args[i];\n          }\n        }\n      }\n      var ret = func.apply(null, cArgs);\n      function onDone(ret) {\n        if (stack !== 0) stackRestore(stack);\n        return convertReturnValue(ret);\n      }\n      ret = onDone(ret);\n      return ret;\n    };\n\n    /**\n     * @param {string=} returnType\n     * @param {Array=} argTypes\n     * @param {Object=} opts\n     */\n    var cwrap = function cwrap(ident, returnType, argTypes, opts) {\n      return function () {\n        return ccall(ident, returnType, argTypes, arguments, opts);\n      };\n    };\n    var ERRNO_CODES = {};\n    var initRandomFill = function initRandomFill() {\n      if ((typeof crypto === \"undefined\" ? \"undefined\" : _typeof(crypto)) == 'object' && typeof crypto['getRandomValues'] == 'function') {\n        // for modern web browsers\n        return function (view) {\n          return crypto.getRandomValues(view);\n        };\n      } else\n        // we couldn't find a proper implementation, as Math.random() is not suitable for /dev/random, see emscripten-core/emscripten/pull/7096\n        abort(\"no cryptographic support found for randomDevice. consider polyfilling it if you want to use something insecure like Math.random(), e.g. put this in a --pre-js: var crypto = { getRandomValues: (array) => { for (var i = 0; i < array.length; i++) array[i] = (Math.random()*256)|0 } };\");\n    };\n    var _randomFill = function randomFill(view) {\n      // Lazily init on the first invocation.\n      return (_randomFill = initRandomFill())(view);\n    };\n    var PATH = {\n      isAbs: function isAbs(path) {\n        return path.charAt(0) === '/';\n      },\n      splitPath: function splitPath(filename) {\n        var splitPathRe = /^(\\/?|)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?|)(\\.[^.\\/]*|))(?:[\\/]*)$/;\n        return splitPathRe.exec(filename).slice(1);\n      },\n      normalizeArray: function normalizeArray(parts, allowAboveRoot) {\n        // if the path tries to go above the root, `up` ends up > 0\n        var up = 0;\n        for (var i = parts.length - 1; i >= 0; i--) {\n          var last = parts[i];\n          if (last === '.') {\n            parts.splice(i, 1);\n          } else if (last === '..') {\n            parts.splice(i, 1);\n            up++;\n          } else if (up) {\n            parts.splice(i, 1);\n            up--;\n          }\n        }\n        // if the path is allowed to go above the root, restore leading ..s\n        if (allowAboveRoot) {\n          for (; up; up--) {\n            parts.unshift('..');\n          }\n        }\n        return parts;\n      },\n      normalize: function normalize(path) {\n        var isAbsolute = PATH.isAbs(path),\n          trailingSlash = path.substr(-1) === '/';\n        // Normalize the path\n        path = PATH.normalizeArray(path.split('/').filter(function (p) {\n          return !!p;\n        }), !isAbsolute).join('/');\n        if (!path && !isAbsolute) {\n          path = '.';\n        }\n        if (path && trailingSlash) {\n          path += '/';\n        }\n        return (isAbsolute ? '/' : '') + path;\n      },\n      dirname: function dirname(path) {\n        var result = PATH.splitPath(path),\n          root = result[0],\n          dir = result[1];\n        if (!root && !dir) {\n          // No dirname whatsoever\n          return '.';\n        }\n        if (dir) {\n          // It has a dirname, strip trailing slash\n          dir = dir.substr(0, dir.length - 1);\n        }\n        return root + dir;\n      },\n      basename: function basename(path) {\n        // EMSCRIPTEN return '/'' for '/', not an empty string\n        if (path === '/') return '/';\n        path = PATH.normalize(path);\n        path = path.replace(/\\/$/, \"\");\n        var lastSlash = path.lastIndexOf('/');\n        if (lastSlash === -1) return path;\n        return path.substr(lastSlash + 1);\n      },\n      join: function join() {\n        var paths = Array.prototype.slice.call(arguments);\n        return PATH.normalize(paths.join('/'));\n      },\n      join2: function join2(l, r) {\n        return PATH.normalize(l + '/' + r);\n      }\n    };\n    var PATH_FS = {\n      resolve: function resolve() {\n        var resolvedPath = '',\n          resolvedAbsolute = false;\n        for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n          var path = i >= 0 ? arguments[i] : FS.cwd();\n          // Skip empty and invalid entries\n          if (typeof path != 'string') {\n            throw new TypeError('Arguments to path.resolve must be strings');\n          } else if (!path) {\n            return ''; // an invalid portion invalidates the whole thing\n          }\n          resolvedPath = path + '/' + resolvedPath;\n          resolvedAbsolute = PATH.isAbs(path);\n        }\n        // At this point the path should be resolved to a full absolute path, but\n        // handle relative paths to be safe (might happen when process.cwd() fails)\n        resolvedPath = PATH.normalizeArray(resolvedPath.split('/').filter(function (p) {\n          return !!p;\n        }), !resolvedAbsolute).join('/');\n        return (resolvedAbsolute ? '/' : '') + resolvedPath || '.';\n      },\n      relative: function relative(from, to) {\n        from = PATH_FS.resolve(from).substr(1);\n        to = PATH_FS.resolve(to).substr(1);\n        function trim(arr) {\n          var start = 0;\n          for (; start < arr.length; start++) {\n            if (arr[start] !== '') break;\n          }\n          var end = arr.length - 1;\n          for (; end >= 0; end--) {\n            if (arr[end] !== '') break;\n          }\n          if (start > end) return [];\n          return arr.slice(start, end - start + 1);\n        }\n        var fromParts = trim(from.split('/'));\n        var toParts = trim(to.split('/'));\n        var length = Math.min(fromParts.length, toParts.length);\n        var samePartsLength = length;\n        for (var i = 0; i < length; i++) {\n          if (fromParts[i] !== toParts[i]) {\n            samePartsLength = i;\n            break;\n          }\n        }\n        var outputParts = [];\n        for (var i = samePartsLength; i < fromParts.length; i++) {\n          outputParts.push('..');\n        }\n        outputParts = outputParts.concat(toParts.slice(samePartsLength));\n        return outputParts.join('/');\n      }\n    };\n    var FS_stdin_getChar_buffer = [];\n\n    /** @type {function(string, boolean=, number=)} */\n    function intArrayFromString(stringy, dontAddNull, length) {\n      var len = length > 0 ? length : lengthBytesUTF8(stringy) + 1;\n      var u8array = new Array(len);\n      var numBytesWritten = stringToUTF8Array(stringy, u8array, 0, u8array.length);\n      if (dontAddNull) u8array.length = numBytesWritten;\n      return u8array;\n    }\n    var FS_stdin_getChar = function FS_stdin_getChar() {\n      if (!FS_stdin_getChar_buffer.length) {\n        var result = null;\n        if (typeof window != 'undefined' && typeof window.prompt == 'function') {\n          // Browser.\n          result = window.prompt('Input: '); // returns null on cancel\n          if (result !== null) {\n            result += '\\n';\n          }\n        } else if (typeof readline == 'function') {\n          // Command line.\n          result = readline();\n          if (result !== null) {\n            result += '\\n';\n          }\n        }\n        if (!result) {\n          return null;\n        }\n        FS_stdin_getChar_buffer = intArrayFromString(result, true);\n      }\n      return FS_stdin_getChar_buffer.shift();\n    };\n    var TTY = {\n      ttys: [],\n      init: function init() {\n        // https://github.com/emscripten-core/emscripten/pull/1555\n        // if (ENVIRONMENT_IS_NODE) {\n        //   // currently, FS.init does not distinguish if process.stdin is a file or TTY\n        //   // device, it always assumes it's a TTY device. because of this, we're forcing\n        //   // process.stdin to UTF8 encoding to at least make stdin reading compatible\n        //   // with text files until FS.init can be refactored.\n        //   process.stdin.setEncoding('utf8');\n        // }\n      },\n      shutdown: function shutdown() {\n        // https://github.com/emscripten-core/emscripten/pull/1555\n        // if (ENVIRONMENT_IS_NODE) {\n        //   // inolen: any idea as to why node -e 'process.stdin.read()' wouldn't exit immediately (with process.stdin being a tty)?\n        //   // isaacs: because now it's reading from the stream, you've expressed interest in it, so that read() kicks off a _read() which creates a ReadReq operation\n        //   // inolen: I thought read() in that case was a synchronous operation that just grabbed some amount of buffered data if it exists?\n        //   // isaacs: it is. but it also triggers a _read() call, which calls readStart() on the handle\n        //   // isaacs: do process.stdin.pause() and i'd think it'd probably close the pending call\n        //   process.stdin.pause();\n        // }\n      },\n      register: function register(dev, ops) {\n        TTY.ttys[dev] = {\n          input: [],\n          output: [],\n          ops: ops\n        };\n        FS.registerDevice(dev, TTY.stream_ops);\n      },\n      stream_ops: {\n        open: function open(stream) {\n          var tty = TTY.ttys[stream.node.rdev];\n          if (!tty) {\n            throw new FS.ErrnoError(43);\n          }\n          stream.tty = tty;\n          stream.seekable = false;\n        },\n        close: function close(stream) {\n          // flush any pending line data\n          stream.tty.ops.fsync(stream.tty);\n        },\n        fsync: function fsync(stream) {\n          stream.tty.ops.fsync(stream.tty);\n        },\n        read: function read(stream, buffer, offset, length, pos /* ignored */) {\n          if (!stream.tty || !stream.tty.ops.get_char) {\n            throw new FS.ErrnoError(60);\n          }\n          var bytesRead = 0;\n          for (var i = 0; i < length; i++) {\n            var result;\n            try {\n              result = stream.tty.ops.get_char(stream.tty);\n            } catch (e) {\n              throw new FS.ErrnoError(29);\n            }\n            if (result === undefined && bytesRead === 0) {\n              throw new FS.ErrnoError(6);\n            }\n            if (result === null || result === undefined) break;\n            bytesRead++;\n            buffer[offset + i] = result;\n          }\n          if (bytesRead) {\n            stream.node.timestamp = Date.now();\n          }\n          return bytesRead;\n        },\n        write: function write(stream, buffer, offset, length, pos) {\n          if (!stream.tty || !stream.tty.ops.put_char) {\n            throw new FS.ErrnoError(60);\n          }\n          try {\n            for (var i = 0; i < length; i++) {\n              stream.tty.ops.put_char(stream.tty, buffer[offset + i]);\n            }\n          } catch (e) {\n            throw new FS.ErrnoError(29);\n          }\n          if (length) {\n            stream.node.timestamp = Date.now();\n          }\n          return i;\n        }\n      },\n      default_tty_ops: {\n        get_char: function get_char(tty) {\n          return FS_stdin_getChar();\n        },\n        put_char: function put_char(tty, val) {\n          if (val === null || val === 10) {\n            out(UTF8ArrayToString(tty.output, 0));\n            tty.output = [];\n          } else {\n            if (val != 0) tty.output.push(val); // val == 0 would cut text output off in the middle.\n          }\n        },\n        fsync: function fsync(tty) {\n          if (tty.output && tty.output.length > 0) {\n            out(UTF8ArrayToString(tty.output, 0));\n            tty.output = [];\n          }\n        },\n        ioctl_tcgets: function ioctl_tcgets(tty) {\n          // typical setting\n          return {\n            c_iflag: 25856,\n            c_oflag: 5,\n            c_cflag: 191,\n            c_lflag: 35387,\n            c_cc: [0x03, 0x1c, 0x7f, 0x15, 0x04, 0x00, 0x01, 0x00, 0x11, 0x13, 0x1a, 0x00, 0x12, 0x0f, 0x17, 0x16, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]\n          };\n        },\n        ioctl_tcsets: function ioctl_tcsets(tty, optional_actions, data) {\n          // currently just ignore\n          return 0;\n        },\n        ioctl_tiocgwinsz: function ioctl_tiocgwinsz(tty) {\n          return [24, 80];\n        }\n      },\n      default_tty1_ops: {\n        put_char: function put_char(tty, val) {\n          if (val === null || val === 10) {\n            err(UTF8ArrayToString(tty.output, 0));\n            tty.output = [];\n          } else {\n            if (val != 0) tty.output.push(val);\n          }\n        },\n        fsync: function fsync(tty) {\n          if (tty.output && tty.output.length > 0) {\n            err(UTF8ArrayToString(tty.output, 0));\n            tty.output = [];\n          }\n        }\n      }\n    };\n    var zeroMemory = function zeroMemory(address, size) {\n      HEAPU8.fill(0, address, address + size);\n      return address;\n    };\n    var alignMemory = function alignMemory(size, alignment) {\n      assert(alignment, \"alignment argument is required\");\n      return Math.ceil(size / alignment) * alignment;\n    };\n    var mmapAlloc = function mmapAlloc(size) {\n      abort('internal error: mmapAlloc called but `emscripten_builtin_memalign` native symbol not exported');\n    };\n    var MEMFS = {\n      ops_table: null,\n      mount: function mount(_mount) {\n        return MEMFS.createNode(null, '/', 16384 | 511 /* 0777 */, 0);\n      },\n      createNode: function createNode(parent, name, mode, dev) {\n        if (FS.isBlkdev(mode) || FS.isFIFO(mode)) {\n          // no supported\n          throw new FS.ErrnoError(63);\n        }\n        if (!MEMFS.ops_table) {\n          MEMFS.ops_table = {\n            dir: {\n              node: {\n                getattr: MEMFS.node_ops.getattr,\n                setattr: MEMFS.node_ops.setattr,\n                lookup: MEMFS.node_ops.lookup,\n                mknod: MEMFS.node_ops.mknod,\n                rename: MEMFS.node_ops.rename,\n                unlink: MEMFS.node_ops.unlink,\n                rmdir: MEMFS.node_ops.rmdir,\n                readdir: MEMFS.node_ops.readdir,\n                symlink: MEMFS.node_ops.symlink\n              },\n              stream: {\n                llseek: MEMFS.stream_ops.llseek\n              }\n            },\n            file: {\n              node: {\n                getattr: MEMFS.node_ops.getattr,\n                setattr: MEMFS.node_ops.setattr\n              },\n              stream: {\n                llseek: MEMFS.stream_ops.llseek,\n                read: MEMFS.stream_ops.read,\n                write: MEMFS.stream_ops.write,\n                allocate: MEMFS.stream_ops.allocate,\n                mmap: MEMFS.stream_ops.mmap,\n                msync: MEMFS.stream_ops.msync\n              }\n            },\n            link: {\n              node: {\n                getattr: MEMFS.node_ops.getattr,\n                setattr: MEMFS.node_ops.setattr,\n                readlink: MEMFS.node_ops.readlink\n              },\n              stream: {}\n            },\n            chrdev: {\n              node: {\n                getattr: MEMFS.node_ops.getattr,\n                setattr: MEMFS.node_ops.setattr\n              },\n              stream: FS.chrdev_stream_ops\n            }\n          };\n        }\n        var node = FS.createNode(parent, name, mode, dev);\n        if (FS.isDir(node.mode)) {\n          node.node_ops = MEMFS.ops_table.dir.node;\n          node.stream_ops = MEMFS.ops_table.dir.stream;\n          node.contents = {};\n        } else if (FS.isFile(node.mode)) {\n          node.node_ops = MEMFS.ops_table.file.node;\n          node.stream_ops = MEMFS.ops_table.file.stream;\n          node.usedBytes = 0; // The actual number of bytes used in the typed array, as opposed to contents.length which gives the whole capacity.\n          // When the byte data of the file is populated, this will point to either a typed array, or a normal JS array. Typed arrays are preferred\n          // for performance, and used by default. However, typed arrays are not resizable like normal JS arrays are, so there is a small disk size\n          // penalty involved for appending file writes that continuously grow a file similar to std::vector capacity vs used -scheme.\n          node.contents = null;\n        } else if (FS.isLink(node.mode)) {\n          node.node_ops = MEMFS.ops_table.link.node;\n          node.stream_ops = MEMFS.ops_table.link.stream;\n        } else if (FS.isChrdev(node.mode)) {\n          node.node_ops = MEMFS.ops_table.chrdev.node;\n          node.stream_ops = MEMFS.ops_table.chrdev.stream;\n        }\n        node.timestamp = Date.now();\n        // add the new node to the parent\n        if (parent) {\n          parent.contents[name] = node;\n          parent.timestamp = node.timestamp;\n        }\n        return node;\n      },\n      getFileDataAsTypedArray: function getFileDataAsTypedArray(node) {\n        if (!node.contents) return new Uint8Array(0);\n        if (node.contents.subarray) return node.contents.subarray(0, node.usedBytes); // Make sure to not return excess unused bytes.\n        return new Uint8Array(node.contents);\n      },\n      expandFileStorage: function expandFileStorage(node, newCapacity) {\n        var prevCapacity = node.contents ? node.contents.length : 0;\n        if (prevCapacity >= newCapacity) return; // No need to expand, the storage was already large enough.\n        // Don't expand strictly to the given requested limit if it's only a very small increase, but instead geometrically grow capacity.\n        // For small filesizes (<1MB), perform size*2 geometric increase, but for large sizes, do a much more conservative size*1.125 increase to\n        // avoid overshooting the allocation cap by a very large margin.\n        var CAPACITY_DOUBLING_MAX = 1024 * 1024;\n        newCapacity = Math.max(newCapacity, prevCapacity * (prevCapacity < CAPACITY_DOUBLING_MAX ? 2.0 : 1.125) >>> 0);\n        if (prevCapacity != 0) newCapacity = Math.max(newCapacity, 256); // At minimum allocate 256b for each file when expanding.\n        var oldContents = node.contents;\n        node.contents = new Uint8Array(newCapacity); // Allocate new storage.\n        if (node.usedBytes > 0) node.contents.set(oldContents.subarray(0, node.usedBytes), 0); // Copy old data over to the new storage.\n      },\n      resizeFileStorage: function resizeFileStorage(node, newSize) {\n        if (node.usedBytes == newSize) return;\n        if (newSize == 0) {\n          node.contents = null; // Fully decommit when requesting a resize to zero.\n          node.usedBytes = 0;\n        } else {\n          var oldContents = node.contents;\n          node.contents = new Uint8Array(newSize); // Allocate new storage.\n          if (oldContents) {\n            node.contents.set(oldContents.subarray(0, Math.min(newSize, node.usedBytes))); // Copy old data over to the new storage.\n          }\n          node.usedBytes = newSize;\n        }\n      },\n      node_ops: {\n        getattr: function getattr(node) {\n          var attr = {};\n          // device numbers reuse inode numbers.\n          attr.dev = FS.isChrdev(node.mode) ? node.id : 1;\n          attr.ino = node.id;\n          attr.mode = node.mode;\n          attr.nlink = 1;\n          attr.uid = 0;\n          attr.gid = 0;\n          attr.rdev = node.rdev;\n          if (FS.isDir(node.mode)) {\n            attr.size = 4096;\n          } else if (FS.isFile(node.mode)) {\n            attr.size = node.usedBytes;\n          } else if (FS.isLink(node.mode)) {\n            attr.size = node.link.length;\n          } else {\n            attr.size = 0;\n          }\n          attr.atime = new Date(node.timestamp);\n          attr.mtime = new Date(node.timestamp);\n          attr.ctime = new Date(node.timestamp);\n          // NOTE: In our implementation, st_blocks = Math.ceil(st_size/st_blksize),\n          //       but this is not required by the standard.\n          attr.blksize = 4096;\n          attr.blocks = Math.ceil(attr.size / attr.blksize);\n          return attr;\n        },\n        setattr: function setattr(node, attr) {\n          if (attr.mode !== undefined) {\n            node.mode = attr.mode;\n          }\n          if (attr.timestamp !== undefined) {\n            node.timestamp = attr.timestamp;\n          }\n          if (attr.size !== undefined) {\n            MEMFS.resizeFileStorage(node, attr.size);\n          }\n        },\n        lookup: function lookup(parent, name) {\n          throw FS.genericErrors[44];\n        },\n        mknod: function mknod(parent, name, mode, dev) {\n          return MEMFS.createNode(parent, name, mode, dev);\n        },\n        rename: function rename(old_node, new_dir, new_name) {\n          // if we're overwriting a directory at new_name, make sure it's empty.\n          if (FS.isDir(old_node.mode)) {\n            var new_node;\n            try {\n              new_node = FS.lookupNode(new_dir, new_name);\n            } catch (e) {}\n            if (new_node) {\n              for (var i in new_node.contents) {\n                throw new FS.ErrnoError(55);\n              }\n            }\n          }\n          // do the internal rewiring\n          delete old_node.parent.contents[old_node.name];\n          old_node.parent.timestamp = Date.now();\n          old_node.name = new_name;\n          new_dir.contents[new_name] = old_node;\n          new_dir.timestamp = old_node.parent.timestamp;\n          old_node.parent = new_dir;\n        },\n        unlink: function unlink(parent, name) {\n          delete parent.contents[name];\n          parent.timestamp = Date.now();\n        },\n        rmdir: function rmdir(parent, name) {\n          var node = FS.lookupNode(parent, name);\n          for (var i in node.contents) {\n            throw new FS.ErrnoError(55);\n          }\n          delete parent.contents[name];\n          parent.timestamp = Date.now();\n        },\n        readdir: function readdir(node) {\n          var entries = ['.', '..'];\n          for (var key in node.contents) {\n            if (!node.contents.hasOwnProperty(key)) {\n              continue;\n            }\n            entries.push(key);\n          }\n          return entries;\n        },\n        symlink: function symlink(parent, newname, oldpath) {\n          var node = MEMFS.createNode(parent, newname, 511 /* 0777 */ | 40960, 0);\n          node.link = oldpath;\n          return node;\n        },\n        readlink: function readlink(node) {\n          if (!FS.isLink(node.mode)) {\n            throw new FS.ErrnoError(28);\n          }\n          return node.link;\n        }\n      },\n      stream_ops: {\n        read: function read(stream, buffer, offset, length, position) {\n          var contents = stream.node.contents;\n          if (position >= stream.node.usedBytes) return 0;\n          var size = Math.min(stream.node.usedBytes - position, length);\n          assert(size >= 0);\n          if (size > 8 && contents.subarray) {\n            // non-trivial, and typed array\n            buffer.set(contents.subarray(position, position + size), offset);\n          } else {\n            for (var i = 0; i < size; i++) buffer[offset + i] = contents[position + i];\n          }\n          return size;\n        },\n        write: function write(stream, buffer, offset, length, position, canOwn) {\n          // The data buffer should be a typed array view\n          assert(!(buffer instanceof ArrayBuffer));\n          if (!length) return 0;\n          var node = stream.node;\n          node.timestamp = Date.now();\n          if (buffer.subarray && (!node.contents || node.contents.subarray)) {\n            // This write is from a typed array to a typed array?\n            if (canOwn) {\n              assert(position === 0, 'canOwn must imply no weird position inside the file');\n              node.contents = buffer.subarray(offset, offset + length);\n              node.usedBytes = length;\n              return length;\n            } else if (node.usedBytes === 0 && position === 0) {\n              // If this is a simple first write to an empty file, do a fast set since we don't need to care about old data.\n              node.contents = buffer.slice(offset, offset + length);\n              node.usedBytes = length;\n              return length;\n            } else if (position + length <= node.usedBytes) {\n              // Writing to an already allocated and used subrange of the file?\n              node.contents.set(buffer.subarray(offset, offset + length), position);\n              return length;\n            }\n          }\n\n          // Appending to an existing file and we need to reallocate, or source data did not come as a typed array.\n          MEMFS.expandFileStorage(node, position + length);\n          if (node.contents.subarray && buffer.subarray) {\n            // Use typed array write which is available.\n            node.contents.set(buffer.subarray(offset, offset + length), position);\n          } else {\n            for (var i = 0; i < length; i++) {\n              node.contents[position + i] = buffer[offset + i]; // Or fall back to manual write if not.\n            }\n          }\n          node.usedBytes = Math.max(node.usedBytes, position + length);\n          return length;\n        },\n        llseek: function llseek(stream, offset, whence) {\n          var position = offset;\n          if (whence === 1) {\n            position += stream.position;\n          } else if (whence === 2) {\n            if (FS.isFile(stream.node.mode)) {\n              position += stream.node.usedBytes;\n            }\n          }\n          if (position < 0) {\n            throw new FS.ErrnoError(28);\n          }\n          return position;\n        },\n        allocate: function allocate(stream, offset, length) {\n          MEMFS.expandFileStorage(stream.node, offset + length);\n          stream.node.usedBytes = Math.max(stream.node.usedBytes, offset + length);\n        },\n        mmap: function mmap(stream, length, position, prot, flags) {\n          if (!FS.isFile(stream.node.mode)) {\n            throw new FS.ErrnoError(43);\n          }\n          var ptr;\n          var allocated;\n          var contents = stream.node.contents;\n          // Only make a new copy when MAP_PRIVATE is specified.\n          if (!(flags & 2) && contents.buffer === HEAP8.buffer) {\n            // We can't emulate MAP_SHARED when the file is not backed by the\n            // buffer we're mapping to (e.g. the HEAP buffer).\n            allocated = false;\n            ptr = contents.byteOffset;\n          } else {\n            // Try to avoid unnecessary slices.\n            if (position > 0 || position + length < contents.length) {\n              if (contents.subarray) {\n                contents = contents.subarray(position, position + length);\n              } else {\n                contents = Array.prototype.slice.call(contents, position, position + length);\n              }\n            }\n            allocated = true;\n            ptr = mmapAlloc(length);\n            if (!ptr) {\n              throw new FS.ErrnoError(48);\n            }\n            HEAP8.set(contents, ptr);\n          }\n          return {\n            ptr: ptr,\n            allocated: allocated\n          };\n        },\n        msync: function msync(stream, buffer, offset, length, mmapFlags) {\n          MEMFS.stream_ops.write(stream, buffer, 0, length, offset, false);\n          // should we check if bytesWritten and length are the same?\n          return 0;\n        }\n      }\n    };\n\n    /** @param {boolean=} noRunDep */\n    var asyncLoad = function asyncLoad(url, onload, onerror, noRunDep) {\n      var dep = !noRunDep ? getUniqueRunDependency(\"al \".concat(url)) : '';\n      readAsync(url, function (arrayBuffer) {\n        assert(arrayBuffer, \"Loading data file \\\"\".concat(url, \"\\\" failed (no arrayBuffer).\"));\n        onload(new Uint8Array(arrayBuffer));\n        if (dep) removeRunDependency(dep);\n      }, function (event) {\n        if (onerror) {\n          onerror();\n        } else {\n          throw \"Loading data file \\\"\".concat(url, \"\\\" failed.\");\n        }\n      });\n      if (dep) addRunDependency(dep);\n    };\n    var preloadPlugins = Module['preloadPlugins'] || [];\n    var FS_handledByPreloadPlugin = function FS_handledByPreloadPlugin(byteArray, fullname, finish, onerror) {\n      // Ensure plugins are ready.\n      if (typeof Browser != 'undefined') Browser.init();\n      var handled = false;\n      preloadPlugins.forEach(function (plugin) {\n        if (handled) return;\n        if (plugin['canHandle'](fullname)) {\n          plugin['handle'](byteArray, fullname, finish, onerror);\n          handled = true;\n        }\n      });\n      return handled;\n    };\n    var FS_createPreloadedFile = function FS_createPreloadedFile(parent, name, url, canRead, canWrite, onload, onerror, dontCreateFile, canOwn, preFinish) {\n      // TODO we should allow people to just pass in a complete filename instead\n      // of parent and name being that we just join them anyways\n      var fullname = name ? PATH_FS.resolve(PATH.join2(parent, name)) : parent;\n      var dep = getUniqueRunDependency(\"cp \".concat(fullname)); // might have several active requests for the same fullname\n      function processData(byteArray) {\n        function finish(byteArray) {\n          if (preFinish) preFinish();\n          if (!dontCreateFile) {\n            FS.createDataFile(parent, name, byteArray, canRead, canWrite, canOwn);\n          }\n          if (onload) onload();\n          removeRunDependency(dep);\n        }\n        if (FS_handledByPreloadPlugin(byteArray, fullname, finish, function () {\n          if (onerror) onerror();\n          removeRunDependency(dep);\n        })) {\n          return;\n        }\n        finish(byteArray);\n      }\n      addRunDependency(dep);\n      if (typeof url == 'string') {\n        asyncLoad(url, function (byteArray) {\n          return processData(byteArray);\n        }, onerror);\n      } else {\n        processData(url);\n      }\n    };\n    var FS_modeStringToFlags = function FS_modeStringToFlags(str) {\n      var flagModes = {\n        'r': 0,\n        'r+': 2,\n        'w': 512 | 64 | 1,\n        'w+': 512 | 64 | 2,\n        'a': 1024 | 64 | 1,\n        'a+': 1024 | 64 | 2\n      };\n      var flags = flagModes[str];\n      if (typeof flags == 'undefined') {\n        throw new Error(\"Unknown file open mode: \".concat(str));\n      }\n      return flags;\n    };\n    var FS_getMode = function FS_getMode(canRead, canWrite) {\n      var mode = 0;\n      if (canRead) mode |= 292 | 73;\n      if (canWrite) mode |= 146;\n      return mode;\n    };\n    var ERRNO_MESSAGES = {\n      0: \"Success\",\n      1: \"Arg list too long\",\n      2: \"Permission denied\",\n      3: \"Address already in use\",\n      4: \"Address not available\",\n      5: \"Address family not supported by protocol family\",\n      6: \"No more processes\",\n      7: \"Socket already connected\",\n      8: \"Bad file number\",\n      9: \"Trying to read unreadable message\",\n      10: \"Mount device busy\",\n      11: \"Operation canceled\",\n      12: \"No children\",\n      13: \"Connection aborted\",\n      14: \"Connection refused\",\n      15: \"Connection reset by peer\",\n      16: \"File locking deadlock error\",\n      17: \"Destination address required\",\n      18: \"Math arg out of domain of func\",\n      19: \"Quota exceeded\",\n      20: \"File exists\",\n      21: \"Bad address\",\n      22: \"File too large\",\n      23: \"Host is unreachable\",\n      24: \"Identifier removed\",\n      25: \"Illegal byte sequence\",\n      26: \"Connection already in progress\",\n      27: \"Interrupted system call\",\n      28: \"Invalid argument\",\n      29: \"I/O error\",\n      30: \"Socket is already connected\",\n      31: \"Is a directory\",\n      32: \"Too many symbolic links\",\n      33: \"Too many open files\",\n      34: \"Too many links\",\n      35: \"Message too long\",\n      36: \"Multihop attempted\",\n      37: \"File or path name too long\",\n      38: \"Network interface is not configured\",\n      39: \"Connection reset by network\",\n      40: \"Network is unreachable\",\n      41: \"Too many open files in system\",\n      42: \"No buffer space available\",\n      43: \"No such device\",\n      44: \"No such file or directory\",\n      45: \"Exec format error\",\n      46: \"No record locks available\",\n      47: \"The link has been severed\",\n      48: \"Not enough core\",\n      49: \"No message of desired type\",\n      50: \"Protocol not available\",\n      51: \"No space left on device\",\n      52: \"Function not implemented\",\n      53: \"Socket is not connected\",\n      54: \"Not a directory\",\n      55: \"Directory not empty\",\n      56: \"State not recoverable\",\n      57: \"Socket operation on non-socket\",\n      59: \"Not a typewriter\",\n      60: \"No such device or address\",\n      61: \"Value too large for defined data type\",\n      62: \"Previous owner died\",\n      63: \"Not super-user\",\n      64: \"Broken pipe\",\n      65: \"Protocol error\",\n      66: \"Unknown protocol\",\n      67: \"Protocol wrong type for socket\",\n      68: \"Math result not representable\",\n      69: \"Read only file system\",\n      70: \"Illegal seek\",\n      71: \"No such process\",\n      72: \"Stale file handle\",\n      73: \"Connection timed out\",\n      74: \"Text file busy\",\n      75: \"Cross-device link\",\n      100: \"Device not a stream\",\n      101: \"Bad font file fmt\",\n      102: \"Invalid slot\",\n      103: \"Invalid request code\",\n      104: \"No anode\",\n      105: \"Block device required\",\n      106: \"Channel number out of range\",\n      107: \"Level 3 halted\",\n      108: \"Level 3 reset\",\n      109: \"Link number out of range\",\n      110: \"Protocol driver not attached\",\n      111: \"No CSI structure available\",\n      112: \"Level 2 halted\",\n      113: \"Invalid exchange\",\n      114: \"Invalid request descriptor\",\n      115: \"Exchange full\",\n      116: \"No data (for no delay io)\",\n      117: \"Timer expired\",\n      118: \"Out of streams resources\",\n      119: \"Machine is not on the network\",\n      120: \"Package not installed\",\n      121: \"The object is remote\",\n      122: \"Advertise error\",\n      123: \"Srmount error\",\n      124: \"Communication error on send\",\n      125: \"Cross mount point (not really error)\",\n      126: \"Given log. name not unique\",\n      127: \"f.d. invalid for this operation\",\n      128: \"Remote address changed\",\n      129: \"Can   access a needed shared lib\",\n      130: \"Accessing a corrupted shared lib\",\n      131: \".lib section in a.out corrupted\",\n      132: \"Attempting to link in too many libs\",\n      133: \"Attempting to exec a shared library\",\n      135: \"Streams pipe error\",\n      136: \"Too many users\",\n      137: \"Socket type not supported\",\n      138: \"Not supported\",\n      139: \"Protocol family not supported\",\n      140: \"Can't send after socket shutdown\",\n      141: \"Too many references\",\n      142: \"Host is down\",\n      148: \"No medium (in tape drive)\",\n      156: \"Level 2 not synchronized\"\n    };\n    var demangle = function demangle(func) {\n      _warnOnce('warning: build with -sDEMANGLE_SUPPORT to link in libcxxabi demangling');\n      return func;\n    };\n    var demangleAll = function demangleAll(text) {\n      var regex = /\\b_Z[\\w\\d_]+/g;\n      return text.replace(regex, function (x) {\n        var y = demangle(x);\n        return x === y ? x : y + ' [' + x + ']';\n      });\n    };\n    var FS = {\n      root: null,\n      mounts: [],\n      devices: {},\n      streams: [],\n      nextInode: 1,\n      nameTable: null,\n      currentPath: \"/\",\n      initialized: false,\n      ignorePermissions: true,\n      ErrnoError: null,\n      genericErrors: {},\n      filesystems: null,\n      syncFSRequests: 0,\n      lookupPath: function lookupPath(path) {\n        var opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n        path = PATH_FS.resolve(path);\n        if (!path) return {\n          path: '',\n          node: null\n        };\n        var defaults = {\n          follow_mount: true,\n          recurse_count: 0\n        };\n        opts = Object.assign(defaults, opts);\n        if (opts.recurse_count > 8) {\n          // max recursive lookup of 8\n          throw new FS.ErrnoError(32);\n        }\n\n        // split the absolute path\n        var parts = path.split('/').filter(function (p) {\n          return !!p;\n        });\n\n        // start at the root\n        var current = FS.root;\n        var current_path = '/';\n        for (var i = 0; i < parts.length; i++) {\n          var islast = i === parts.length - 1;\n          if (islast && opts.parent) {\n            // stop resolving\n            break;\n          }\n          current = FS.lookupNode(current, parts[i]);\n          current_path = PATH.join2(current_path, parts[i]);\n\n          // jump to the mount's root node if this is a mountpoint\n          if (FS.isMountpoint(current)) {\n            if (!islast || islast && opts.follow_mount) {\n              current = current.mounted.root;\n            }\n          }\n\n          // by default, lookupPath will not follow a symlink if it is the final path component.\n          // setting opts.follow = true will override this behavior.\n          if (!islast || opts.follow) {\n            var count = 0;\n            while (FS.isLink(current.mode)) {\n              var link = FS.readlink(current_path);\n              current_path = PATH_FS.resolve(PATH.dirname(current_path), link);\n              var lookup = FS.lookupPath(current_path, {\n                recurse_count: opts.recurse_count + 1\n              });\n              current = lookup.node;\n              if (count++ > 40) {\n                // limit max consecutive symlinks to 40 (SYMLOOP_MAX).\n                throw new FS.ErrnoError(32);\n              }\n            }\n          }\n        }\n        return {\n          path: current_path,\n          node: current\n        };\n      },\n      getPath: function getPath(node) {\n        var path;\n        while (true) {\n          if (FS.isRoot(node)) {\n            var mount = node.mount.mountpoint;\n            if (!path) return mount;\n            return mount[mount.length - 1] !== '/' ? \"\".concat(mount, \"/\").concat(path) : mount + path;\n          }\n          path = path ? \"\".concat(node.name, \"/\").concat(path) : node.name;\n          node = node.parent;\n        }\n      },\n      hashName: function hashName(parentid, name) {\n        var hash = 0;\n        for (var i = 0; i < name.length; i++) {\n          hash = (hash << 5) - hash + name.charCodeAt(i) | 0;\n        }\n        return (parentid + hash >>> 0) % FS.nameTable.length;\n      },\n      hashAddNode: function hashAddNode(node) {\n        var hash = FS.hashName(node.parent.id, node.name);\n        node.name_next = FS.nameTable[hash];\n        FS.nameTable[hash] = node;\n      },\n      hashRemoveNode: function hashRemoveNode(node) {\n        var hash = FS.hashName(node.parent.id, node.name);\n        if (FS.nameTable[hash] === node) {\n          FS.nameTable[hash] = node.name_next;\n        } else {\n          var current = FS.nameTable[hash];\n          while (current) {\n            if (current.name_next === node) {\n              current.name_next = node.name_next;\n              break;\n            }\n            current = current.name_next;\n          }\n        }\n      },\n      lookupNode: function lookupNode(parent, name) {\n        var errCode = FS.mayLookup(parent);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode, parent);\n        }\n        var hash = FS.hashName(parent.id, name);\n        for (var node = FS.nameTable[hash]; node; node = node.name_next) {\n          var nodeName = node.name;\n          if (node.parent.id === parent.id && nodeName === name) {\n            return node;\n          }\n        }\n        // if we failed to find it in the cache, call into the VFS\n        return FS.lookup(parent, name);\n      },\n      createNode: function createNode(parent, name, mode, rdev) {\n        assert(_typeof(parent) == 'object');\n        var node = new FS.FSNode(parent, name, mode, rdev);\n        FS.hashAddNode(node);\n        return node;\n      },\n      destroyNode: function destroyNode(node) {\n        FS.hashRemoveNode(node);\n      },\n      isRoot: function isRoot(node) {\n        return node === node.parent;\n      },\n      isMountpoint: function isMountpoint(node) {\n        return !!node.mounted;\n      },\n      isFile: function isFile(mode) {\n        return (mode & 61440) === 32768;\n      },\n      isDir: function isDir(mode) {\n        return (mode & 61440) === 16384;\n      },\n      isLink: function isLink(mode) {\n        return (mode & 61440) === 40960;\n      },\n      isChrdev: function isChrdev(mode) {\n        return (mode & 61440) === 8192;\n      },\n      isBlkdev: function isBlkdev(mode) {\n        return (mode & 61440) === 24576;\n      },\n      isFIFO: function isFIFO(mode) {\n        return (mode & 61440) === 4096;\n      },\n      isSocket: function isSocket(mode) {\n        return (mode & 49152) === 49152;\n      },\n      flagsToPermissionString: function flagsToPermissionString(flag) {\n        var perms = ['r', 'w', 'rw'][flag & 3];\n        if (flag & 512) {\n          perms += 'w';\n        }\n        return perms;\n      },\n      nodePermissions: function nodePermissions(node, perms) {\n        if (FS.ignorePermissions) {\n          return 0;\n        }\n        // return 0 if any user, group or owner bits are set.\n        if (perms.includes('r') && !(node.mode & 292)) {\n          return 2;\n        } else if (perms.includes('w') && !(node.mode & 146)) {\n          return 2;\n        } else if (perms.includes('x') && !(node.mode & 73)) {\n          return 2;\n        }\n        return 0;\n      },\n      mayLookup: function mayLookup(dir) {\n        var errCode = FS.nodePermissions(dir, 'x');\n        if (errCode) return errCode;\n        if (!dir.node_ops.lookup) return 2;\n        return 0;\n      },\n      mayCreate: function mayCreate(dir, name) {\n        try {\n          var node = FS.lookupNode(dir, name);\n          return 20;\n        } catch (e) {}\n        return FS.nodePermissions(dir, 'wx');\n      },\n      mayDelete: function mayDelete(dir, name, isdir) {\n        var node;\n        try {\n          node = FS.lookupNode(dir, name);\n        } catch (e) {\n          return e.errno;\n        }\n        var errCode = FS.nodePermissions(dir, 'wx');\n        if (errCode) {\n          return errCode;\n        }\n        if (isdir) {\n          if (!FS.isDir(node.mode)) {\n            return 54;\n          }\n          if (FS.isRoot(node) || FS.getPath(node) === FS.cwd()) {\n            return 10;\n          }\n        } else {\n          if (FS.isDir(node.mode)) {\n            return 31;\n          }\n        }\n        return 0;\n      },\n      mayOpen: function mayOpen(node, flags) {\n        if (!node) {\n          return 44;\n        }\n        if (FS.isLink(node.mode)) {\n          return 32;\n        } else if (FS.isDir(node.mode)) {\n          if (FS.flagsToPermissionString(flags) !== 'r' ||\n          // opening for write\n          flags & 512) {\n            // TODO: check for O_SEARCH? (== search for dir only)\n            return 31;\n          }\n        }\n        return FS.nodePermissions(node, FS.flagsToPermissionString(flags));\n      },\n      MAX_OPEN_FDS: 4096,\n      nextfd: function nextfd() {\n        for (var fd = 0; fd <= FS.MAX_OPEN_FDS; fd++) {\n          if (!FS.streams[fd]) {\n            return fd;\n          }\n        }\n        throw new FS.ErrnoError(33);\n      },\n      getStreamChecked: function getStreamChecked(fd) {\n        var stream = FS.getStream(fd);\n        if (!stream) {\n          throw new FS.ErrnoError(8);\n        }\n        return stream;\n      },\n      getStream: function getStream(fd) {\n        return FS.streams[fd];\n      },\n      createStream: function createStream(stream) {\n        var fd = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n        if (!FS.FSStream) {\n          FS.FSStream = /** @constructor */function () {\n            this.shared = {};\n          };\n          FS.FSStream.prototype = {};\n          Object.defineProperties(FS.FSStream.prototype, {\n            object: {\n              /** @this {FS.FSStream} */get: function get() {\n                return this.node;\n              },\n              /** @this {FS.FSStream} */set: function set(val) {\n                this.node = val;\n              }\n            },\n            isRead: {\n              /** @this {FS.FSStream} */get: function get() {\n                return (this.flags & 2097155) !== 1;\n              }\n            },\n            isWrite: {\n              /** @this {FS.FSStream} */get: function get() {\n                return (this.flags & 2097155) !== 0;\n              }\n            },\n            isAppend: {\n              /** @this {FS.FSStream} */get: function get() {\n                return this.flags & 1024;\n              }\n            },\n            flags: {\n              /** @this {FS.FSStream} */get: function get() {\n                return this.shared.flags;\n              },\n              /** @this {FS.FSStream} */set: function set(val) {\n                this.shared.flags = val;\n              }\n            },\n            position: {\n              /** @this {FS.FSStream} */get: function get() {\n                return this.shared.position;\n              },\n              /** @this {FS.FSStream} */set: function set(val) {\n                this.shared.position = val;\n              }\n            }\n          });\n        }\n        // clone it, so we can return an instance of FSStream\n        stream = Object.assign(new FS.FSStream(), stream);\n        if (fd == -1) {\n          fd = FS.nextfd();\n        }\n        stream.fd = fd;\n        FS.streams[fd] = stream;\n        return stream;\n      },\n      closeStream: function closeStream(fd) {\n        FS.streams[fd] = null;\n      },\n      chrdev_stream_ops: {\n        open: function open(stream) {\n          var device = FS.getDevice(stream.node.rdev);\n          // override node's stream ops with the device's\n          stream.stream_ops = device.stream_ops;\n          // forward the open call\n          if (stream.stream_ops.open) {\n            stream.stream_ops.open(stream);\n          }\n        },\n        llseek: function llseek() {\n          throw new FS.ErrnoError(70);\n        }\n      },\n      major: function major(dev) {\n        return dev >> 8;\n      },\n      minor: function minor(dev) {\n        return dev & 0xff;\n      },\n      makedev: function makedev(ma, mi) {\n        return ma << 8 | mi;\n      },\n      registerDevice: function registerDevice(dev, ops) {\n        FS.devices[dev] = {\n          stream_ops: ops\n        };\n      },\n      getDevice: function getDevice(dev) {\n        return FS.devices[dev];\n      },\n      getMounts: function getMounts(mount) {\n        var mounts = [];\n        var check = [mount];\n        while (check.length) {\n          var m = check.pop();\n          mounts.push(m);\n          check.push.apply(check, m.mounts);\n        }\n        return mounts;\n      },\n      syncfs: function syncfs(populate, callback) {\n        if (typeof populate == 'function') {\n          callback = populate;\n          populate = false;\n        }\n        FS.syncFSRequests++;\n        if (FS.syncFSRequests > 1) {\n          err(\"warning: \".concat(FS.syncFSRequests, \" FS.syncfs operations in flight at once, probably just doing extra work\"));\n        }\n        var mounts = FS.getMounts(FS.root.mount);\n        var completed = 0;\n        function doCallback(errCode) {\n          assert(FS.syncFSRequests > 0);\n          FS.syncFSRequests--;\n          return callback(errCode);\n        }\n        function done(errCode) {\n          if (errCode) {\n            if (!done.errored) {\n              done.errored = true;\n              return doCallback(errCode);\n            }\n            return;\n          }\n          if (++completed >= mounts.length) {\n            doCallback(null);\n          }\n        }\n        ;\n\n        // sync all mounts\n        mounts.forEach(function (mount) {\n          if (!mount.type.syncfs) {\n            return done(null);\n          }\n          mount.type.syncfs(mount, populate, done);\n        });\n      },\n      mount: function mount(type, opts, mountpoint) {\n        if (typeof type == 'string') {\n          // The filesystem was not included, and instead we have an error\n          // message stored in the variable.\n          throw type;\n        }\n        var root = mountpoint === '/';\n        var pseudo = !mountpoint;\n        var node;\n        if (root && FS.root) {\n          throw new FS.ErrnoError(10);\n        } else if (!root && !pseudo) {\n          var lookup = FS.lookupPath(mountpoint, {\n            follow_mount: false\n          });\n          mountpoint = lookup.path; // use the absolute path\n          node = lookup.node;\n          if (FS.isMountpoint(node)) {\n            throw new FS.ErrnoError(10);\n          }\n          if (!FS.isDir(node.mode)) {\n            throw new FS.ErrnoError(54);\n          }\n        }\n        var mount = {\n          type: type,\n          opts: opts,\n          mountpoint: mountpoint,\n          mounts: []\n        };\n\n        // create a root node for the fs\n        var mountRoot = type.mount(mount);\n        mountRoot.mount = mount;\n        mount.root = mountRoot;\n        if (root) {\n          FS.root = mountRoot;\n        } else if (node) {\n          // set as a mountpoint\n          node.mounted = mount;\n\n          // add the new mount to the current mount's children\n          if (node.mount) {\n            node.mount.mounts.push(mount);\n          }\n        }\n        return mountRoot;\n      },\n      unmount: function unmount(mountpoint) {\n        var lookup = FS.lookupPath(mountpoint, {\n          follow_mount: false\n        });\n        if (!FS.isMountpoint(lookup.node)) {\n          throw new FS.ErrnoError(28);\n        }\n\n        // destroy the nodes for this mount, and all its child mounts\n        var node = lookup.node;\n        var mount = node.mounted;\n        var mounts = FS.getMounts(mount);\n        Object.keys(FS.nameTable).forEach(function (hash) {\n          var current = FS.nameTable[hash];\n          while (current) {\n            var next = current.name_next;\n            if (mounts.includes(current.mount)) {\n              FS.destroyNode(current);\n            }\n            current = next;\n          }\n        });\n\n        // no longer a mountpoint\n        node.mounted = null;\n\n        // remove this mount from the child mounts\n        var idx = node.mount.mounts.indexOf(mount);\n        assert(idx !== -1);\n        node.mount.mounts.splice(idx, 1);\n      },\n      lookup: function lookup(parent, name) {\n        return parent.node_ops.lookup(parent, name);\n      },\n      mknod: function mknod(path, mode, dev) {\n        var lookup = FS.lookupPath(path, {\n          parent: true\n        });\n        var parent = lookup.node;\n        var name = PATH.basename(path);\n        if (!name || name === '.' || name === '..') {\n          throw new FS.ErrnoError(28);\n        }\n        var errCode = FS.mayCreate(parent, name);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        if (!parent.node_ops.mknod) {\n          throw new FS.ErrnoError(63);\n        }\n        return parent.node_ops.mknod(parent, name, mode, dev);\n      },\n      create: function create(path, mode) {\n        mode = mode !== undefined ? mode : 438 /* 0666 */;\n        mode &= 4095;\n        mode |= 32768;\n        return FS.mknod(path, mode, 0);\n      },\n      mkdir: function mkdir(path, mode) {\n        mode = mode !== undefined ? mode : 511 /* 0777 */;\n        mode &= 511 | 512;\n        mode |= 16384;\n        return FS.mknod(path, mode, 0);\n      },\n      mkdirTree: function mkdirTree(path, mode) {\n        var dirs = path.split('/');\n        var d = '';\n        for (var i = 0; i < dirs.length; ++i) {\n          if (!dirs[i]) continue;\n          d += '/' + dirs[i];\n          try {\n            FS.mkdir(d, mode);\n          } catch (e) {\n            if (e.errno != 20) throw e;\n          }\n        }\n      },\n      mkdev: function mkdev(path, mode, dev) {\n        if (typeof dev == 'undefined') {\n          dev = mode;\n          mode = 438 /* 0666 */;\n        }\n        mode |= 8192;\n        return FS.mknod(path, mode, dev);\n      },\n      symlink: function symlink(oldpath, newpath) {\n        if (!PATH_FS.resolve(oldpath)) {\n          throw new FS.ErrnoError(44);\n        }\n        var lookup = FS.lookupPath(newpath, {\n          parent: true\n        });\n        var parent = lookup.node;\n        if (!parent) {\n          throw new FS.ErrnoError(44);\n        }\n        var newname = PATH.basename(newpath);\n        var errCode = FS.mayCreate(parent, newname);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        if (!parent.node_ops.symlink) {\n          throw new FS.ErrnoError(63);\n        }\n        return parent.node_ops.symlink(parent, newname, oldpath);\n      },\n      rename: function rename(old_path, new_path) {\n        var old_dirname = PATH.dirname(old_path);\n        var new_dirname = PATH.dirname(new_path);\n        var old_name = PATH.basename(old_path);\n        var new_name = PATH.basename(new_path);\n        // parents must exist\n        var lookup, old_dir, new_dir;\n\n        // let the errors from non existant directories percolate up\n        lookup = FS.lookupPath(old_path, {\n          parent: true\n        });\n        old_dir = lookup.node;\n        lookup = FS.lookupPath(new_path, {\n          parent: true\n        });\n        new_dir = lookup.node;\n        if (!old_dir || !new_dir) throw new FS.ErrnoError(44);\n        // need to be part of the same mount\n        if (old_dir.mount !== new_dir.mount) {\n          throw new FS.ErrnoError(75);\n        }\n        // source must exist\n        var old_node = FS.lookupNode(old_dir, old_name);\n        // old path should not be an ancestor of the new path\n        var relative = PATH_FS.relative(old_path, new_dirname);\n        if (relative.charAt(0) !== '.') {\n          throw new FS.ErrnoError(28);\n        }\n        // new path should not be an ancestor of the old path\n        relative = PATH_FS.relative(new_path, old_dirname);\n        if (relative.charAt(0) !== '.') {\n          throw new FS.ErrnoError(55);\n        }\n        // see if the new path already exists\n        var new_node;\n        try {\n          new_node = FS.lookupNode(new_dir, new_name);\n        } catch (e) {\n          // not fatal\n        }\n        // early out if nothing needs to change\n        if (old_node === new_node) {\n          return;\n        }\n        // we'll need to delete the old entry\n        var isdir = FS.isDir(old_node.mode);\n        var errCode = FS.mayDelete(old_dir, old_name, isdir);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        // need delete permissions if we'll be overwriting.\n        // need create permissions if new doesn't already exist.\n        errCode = new_node ? FS.mayDelete(new_dir, new_name, isdir) : FS.mayCreate(new_dir, new_name);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        if (!old_dir.node_ops.rename) {\n          throw new FS.ErrnoError(63);\n        }\n        if (FS.isMountpoint(old_node) || new_node && FS.isMountpoint(new_node)) {\n          throw new FS.ErrnoError(10);\n        }\n        // if we are going to change the parent, check write permissions\n        if (new_dir !== old_dir) {\n          errCode = FS.nodePermissions(old_dir, 'w');\n          if (errCode) {\n            throw new FS.ErrnoError(errCode);\n          }\n        }\n        // remove the node from the lookup hash\n        FS.hashRemoveNode(old_node);\n        // do the underlying fs rename\n        try {\n          old_dir.node_ops.rename(old_node, new_dir, new_name);\n        } catch (e) {\n          throw e;\n        } finally {\n          // add the node back to the hash (in case node_ops.rename\n          // changed its name)\n          FS.hashAddNode(old_node);\n        }\n      },\n      rmdir: function rmdir(path) {\n        var lookup = FS.lookupPath(path, {\n          parent: true\n        });\n        var parent = lookup.node;\n        var name = PATH.basename(path);\n        var node = FS.lookupNode(parent, name);\n        var errCode = FS.mayDelete(parent, name, true);\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        if (!parent.node_ops.rmdir) {\n          throw new FS.ErrnoError(63);\n        }\n        if (FS.isMountpoint(node)) {\n          throw new FS.ErrnoError(10);\n        }\n        parent.node_ops.rmdir(parent, name);\n        FS.destroyNode(node);\n      },\n      readdir: function readdir(path) {\n        var lookup = FS.lookupPath(path, {\n          follow: true\n        });\n        var node = lookup.node;\n        if (!node.node_ops.readdir) {\n          throw new FS.ErrnoError(54);\n        }\n        return node.node_ops.readdir(node);\n      },\n      unlink: function unlink(path) {\n        var lookup = FS.lookupPath(path, {\n          parent: true\n        });\n        var parent = lookup.node;\n        if (!parent) {\n          throw new FS.ErrnoError(44);\n        }\n        var name = PATH.basename(path);\n        var node = FS.lookupNode(parent, name);\n        var errCode = FS.mayDelete(parent, name, false);\n        if (errCode) {\n          // According to POSIX, we should map EISDIR to EPERM, but\n          // we instead do what Linux does (and we must, as we use\n          // the musl linux libc).\n          throw new FS.ErrnoError(errCode);\n        }\n        if (!parent.node_ops.unlink) {\n          throw new FS.ErrnoError(63);\n        }\n        if (FS.isMountpoint(node)) {\n          throw new FS.ErrnoError(10);\n        }\n        parent.node_ops.unlink(parent, name);\n        FS.destroyNode(node);\n      },\n      readlink: function readlink(path) {\n        var lookup = FS.lookupPath(path);\n        var link = lookup.node;\n        if (!link) {\n          throw new FS.ErrnoError(44);\n        }\n        if (!link.node_ops.readlink) {\n          throw new FS.ErrnoError(28);\n        }\n        return PATH_FS.resolve(FS.getPath(link.parent), link.node_ops.readlink(link));\n      },\n      stat: function stat(path, dontFollow) {\n        var lookup = FS.lookupPath(path, {\n          follow: !dontFollow\n        });\n        var node = lookup.node;\n        if (!node) {\n          throw new FS.ErrnoError(44);\n        }\n        if (!node.node_ops.getattr) {\n          throw new FS.ErrnoError(63);\n        }\n        return node.node_ops.getattr(node);\n      },\n      lstat: function lstat(path) {\n        return FS.stat(path, true);\n      },\n      chmod: function chmod(path, mode, dontFollow) {\n        var node;\n        if (typeof path == 'string') {\n          var lookup = FS.lookupPath(path, {\n            follow: !dontFollow\n          });\n          node = lookup.node;\n        } else {\n          node = path;\n        }\n        if (!node.node_ops.setattr) {\n          throw new FS.ErrnoError(63);\n        }\n        node.node_ops.setattr(node, {\n          mode: mode & 4095 | node.mode & ~4095,\n          timestamp: Date.now()\n        });\n      },\n      lchmod: function lchmod(path, mode) {\n        FS.chmod(path, mode, true);\n      },\n      fchmod: function fchmod(fd, mode) {\n        var stream = FS.getStreamChecked(fd);\n        FS.chmod(stream.node, mode);\n      },\n      chown: function chown(path, uid, gid, dontFollow) {\n        var node;\n        if (typeof path == 'string') {\n          var lookup = FS.lookupPath(path, {\n            follow: !dontFollow\n          });\n          node = lookup.node;\n        } else {\n          node = path;\n        }\n        if (!node.node_ops.setattr) {\n          throw new FS.ErrnoError(63);\n        }\n        node.node_ops.setattr(node, {\n          timestamp: Date.now()\n          // we ignore the uid / gid for now\n        });\n      },\n      lchown: function lchown(path, uid, gid) {\n        FS.chown(path, uid, gid, true);\n      },\n      fchown: function fchown(fd, uid, gid) {\n        var stream = FS.getStreamChecked(fd);\n        FS.chown(stream.node, uid, gid);\n      },\n      truncate: function truncate(path, len) {\n        if (len < 0) {\n          throw new FS.ErrnoError(28);\n        }\n        var node;\n        if (typeof path == 'string') {\n          var lookup = FS.lookupPath(path, {\n            follow: true\n          });\n          node = lookup.node;\n        } else {\n          node = path;\n        }\n        if (!node.node_ops.setattr) {\n          throw new FS.ErrnoError(63);\n        }\n        if (FS.isDir(node.mode)) {\n          throw new FS.ErrnoError(31);\n        }\n        if (!FS.isFile(node.mode)) {\n          throw new FS.ErrnoError(28);\n        }\n        var errCode = FS.nodePermissions(node, 'w');\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        node.node_ops.setattr(node, {\n          size: len,\n          timestamp: Date.now()\n        });\n      },\n      ftruncate: function ftruncate(fd, len) {\n        var stream = FS.getStreamChecked(fd);\n        if ((stream.flags & 2097155) === 0) {\n          throw new FS.ErrnoError(28);\n        }\n        FS.truncate(stream.node, len);\n      },\n      utime: function utime(path, atime, mtime) {\n        var lookup = FS.lookupPath(path, {\n          follow: true\n        });\n        var node = lookup.node;\n        node.node_ops.setattr(node, {\n          timestamp: Math.max(atime, mtime)\n        });\n      },\n      open: function open(path, flags, mode) {\n        if (path === \"\") {\n          throw new FS.ErrnoError(44);\n        }\n        flags = typeof flags == 'string' ? FS_modeStringToFlags(flags) : flags;\n        mode = typeof mode == 'undefined' ? 438 /* 0666 */ : mode;\n        if (flags & 64) {\n          mode = mode & 4095 | 32768;\n        } else {\n          mode = 0;\n        }\n        var node;\n        if (_typeof(path) == 'object') {\n          node = path;\n        } else {\n          path = PATH.normalize(path);\n          try {\n            var lookup = FS.lookupPath(path, {\n              follow: !(flags & 131072)\n            });\n            node = lookup.node;\n          } catch (e) {\n            // ignore\n          }\n        }\n        // perhaps we need to create the node\n        var created = false;\n        if (flags & 64) {\n          if (node) {\n            // if O_CREAT and O_EXCL are set, error out if the node already exists\n            if (flags & 128) {\n              throw new FS.ErrnoError(20);\n            }\n          } else {\n            // node doesn't exist, try to create it\n            node = FS.mknod(path, mode, 0);\n            created = true;\n          }\n        }\n        if (!node) {\n          throw new FS.ErrnoError(44);\n        }\n        // can't truncate a device\n        if (FS.isChrdev(node.mode)) {\n          flags &= ~512;\n        }\n        // if asked only for a directory, then this must be one\n        if (flags & 65536 && !FS.isDir(node.mode)) {\n          throw new FS.ErrnoError(54);\n        }\n        // check permissions, if this is not a file we just created now (it is ok to\n        // create and write to a file with read-only permissions; it is read-only\n        // for later use)\n        if (!created) {\n          var errCode = FS.mayOpen(node, flags);\n          if (errCode) {\n            throw new FS.ErrnoError(errCode);\n          }\n        }\n        // do truncation if necessary\n        if (flags & 512 && !created) {\n          FS.truncate(node, 0);\n        }\n        // we've already handled these, don't pass down to the underlying vfs\n        flags &= ~(128 | 512 | 131072);\n\n        // register the stream with the filesystem\n        var stream = FS.createStream({\n          node: node,\n          path: FS.getPath(node),\n          // we want the absolute path to the node\n          flags: flags,\n          seekable: true,\n          position: 0,\n          stream_ops: node.stream_ops,\n          // used by the file family libc calls (fopen, fwrite, ferror, etc.)\n          ungotten: [],\n          error: false\n        });\n        // call the new stream's open function\n        if (stream.stream_ops.open) {\n          stream.stream_ops.open(stream);\n        }\n        if (Module['logReadFiles'] && !(flags & 1)) {\n          if (!FS.readFiles) FS.readFiles = {};\n          if (!(path in FS.readFiles)) {\n            FS.readFiles[path] = 1;\n          }\n        }\n        return stream;\n      },\n      close: function close(stream) {\n        if (FS.isClosed(stream)) {\n          throw new FS.ErrnoError(8);\n        }\n        if (stream.getdents) stream.getdents = null; // free readdir state\n        try {\n          if (stream.stream_ops.close) {\n            stream.stream_ops.close(stream);\n          }\n        } catch (e) {\n          throw e;\n        } finally {\n          FS.closeStream(stream.fd);\n        }\n        stream.fd = null;\n      },\n      isClosed: function isClosed(stream) {\n        return stream.fd === null;\n      },\n      llseek: function llseek(stream, offset, whence) {\n        if (FS.isClosed(stream)) {\n          throw new FS.ErrnoError(8);\n        }\n        if (!stream.seekable || !stream.stream_ops.llseek) {\n          throw new FS.ErrnoError(70);\n        }\n        if (whence != 0 && whence != 1 && whence != 2) {\n          throw new FS.ErrnoError(28);\n        }\n        stream.position = stream.stream_ops.llseek(stream, offset, whence);\n        stream.ungotten = [];\n        return stream.position;\n      },\n      read: function read(stream, buffer, offset, length, position) {\n        assert(offset >= 0);\n        if (length < 0 || position < 0) {\n          throw new FS.ErrnoError(28);\n        }\n        if (FS.isClosed(stream)) {\n          throw new FS.ErrnoError(8);\n        }\n        if ((stream.flags & 2097155) === 1) {\n          throw new FS.ErrnoError(8);\n        }\n        if (FS.isDir(stream.node.mode)) {\n          throw new FS.ErrnoError(31);\n        }\n        if (!stream.stream_ops.read) {\n          throw new FS.ErrnoError(28);\n        }\n        var seeking = typeof position != 'undefined';\n        if (!seeking) {\n          position = stream.position;\n        } else if (!stream.seekable) {\n          throw new FS.ErrnoError(70);\n        }\n        var bytesRead = stream.stream_ops.read(stream, buffer, offset, length, position);\n        if (!seeking) stream.position += bytesRead;\n        return bytesRead;\n      },\n      write: function write(stream, buffer, offset, length, position, canOwn) {\n        assert(offset >= 0);\n        if (length < 0 || position < 0) {\n          throw new FS.ErrnoError(28);\n        }\n        if (FS.isClosed(stream)) {\n          throw new FS.ErrnoError(8);\n        }\n        if ((stream.flags & 2097155) === 0) {\n          throw new FS.ErrnoError(8);\n        }\n        if (FS.isDir(stream.node.mode)) {\n          throw new FS.ErrnoError(31);\n        }\n        if (!stream.stream_ops.write) {\n          throw new FS.ErrnoError(28);\n        }\n        if (stream.seekable && stream.flags & 1024) {\n          // seek to the end before writing in append mode\n          FS.llseek(stream, 0, 2);\n        }\n        var seeking = typeof position != 'undefined';\n        if (!seeking) {\n          position = stream.position;\n        } else if (!stream.seekable) {\n          throw new FS.ErrnoError(70);\n        }\n        var bytesWritten = stream.stream_ops.write(stream, buffer, offset, length, position, canOwn);\n        if (!seeking) stream.position += bytesWritten;\n        return bytesWritten;\n      },\n      allocate: function allocate(stream, offset, length) {\n        if (FS.isClosed(stream)) {\n          throw new FS.ErrnoError(8);\n        }\n        if (offset < 0 || length <= 0) {\n          throw new FS.ErrnoError(28);\n        }\n        if ((stream.flags & 2097155) === 0) {\n          throw new FS.ErrnoError(8);\n        }\n        if (!FS.isFile(stream.node.mode) && !FS.isDir(stream.node.mode)) {\n          throw new FS.ErrnoError(43);\n        }\n        if (!stream.stream_ops.allocate) {\n          throw new FS.ErrnoError(138);\n        }\n        stream.stream_ops.allocate(stream, offset, length);\n      },\n      mmap: function mmap(stream, length, position, prot, flags) {\n        // User requests writing to file (prot & PROT_WRITE != 0).\n        // Checking if we have permissions to write to the file unless\n        // MAP_PRIVATE flag is set. According to POSIX spec it is possible\n        // to write to file opened in read-only mode with MAP_PRIVATE flag,\n        // as all modifications will be visible only in the memory of\n        // the current process.\n        if ((prot & 2) !== 0 && (flags & 2) === 0 && (stream.flags & 2097155) !== 2) {\n          throw new FS.ErrnoError(2);\n        }\n        if ((stream.flags & 2097155) === 1) {\n          throw new FS.ErrnoError(2);\n        }\n        if (!stream.stream_ops.mmap) {\n          throw new FS.ErrnoError(43);\n        }\n        return stream.stream_ops.mmap(stream, length, position, prot, flags);\n      },\n      msync: function msync(stream, buffer, offset, length, mmapFlags) {\n        assert(offset >= 0);\n        if (!stream.stream_ops.msync) {\n          return 0;\n        }\n        return stream.stream_ops.msync(stream, buffer, offset, length, mmapFlags);\n      },\n      munmap: function munmap(stream) {\n        return 0;\n      },\n      ioctl: function ioctl(stream, cmd, arg) {\n        if (!stream.stream_ops.ioctl) {\n          throw new FS.ErrnoError(59);\n        }\n        return stream.stream_ops.ioctl(stream, cmd, arg);\n      },\n      readFile: function readFile(path) {\n        var opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n        opts.flags = opts.flags || 0;\n        opts.encoding = opts.encoding || 'binary';\n        if (opts.encoding !== 'utf8' && opts.encoding !== 'binary') {\n          throw new Error(\"Invalid encoding type \\\"\".concat(opts.encoding, \"\\\"\"));\n        }\n        var ret;\n        var stream = FS.open(path, opts.flags);\n        var stat = FS.stat(path);\n        var length = stat.size;\n        var buf = new Uint8Array(length);\n        FS.read(stream, buf, 0, length, 0);\n        if (opts.encoding === 'utf8') {\n          ret = UTF8ArrayToString(buf, 0);\n        } else if (opts.encoding === 'binary') {\n          ret = buf;\n        }\n        FS.close(stream);\n        return ret;\n      },\n      writeFile: function writeFile(path, data) {\n        var opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n        opts.flags = opts.flags || 577;\n        var stream = FS.open(path, opts.flags, opts.mode);\n        if (typeof data == 'string') {\n          var buf = new Uint8Array(lengthBytesUTF8(data) + 1);\n          var actualNumBytes = stringToUTF8Array(data, buf, 0, buf.length);\n          FS.write(stream, buf, 0, actualNumBytes, undefined, opts.canOwn);\n        } else if (ArrayBuffer.isView(data)) {\n          FS.write(stream, data, 0, data.byteLength, undefined, opts.canOwn);\n        } else {\n          throw new Error('Unsupported data type');\n        }\n        FS.close(stream);\n      },\n      cwd: function cwd() {\n        return FS.currentPath;\n      },\n      chdir: function chdir(path) {\n        var lookup = FS.lookupPath(path, {\n          follow: true\n        });\n        if (lookup.node === null) {\n          throw new FS.ErrnoError(44);\n        }\n        if (!FS.isDir(lookup.node.mode)) {\n          throw new FS.ErrnoError(54);\n        }\n        var errCode = FS.nodePermissions(lookup.node, 'x');\n        if (errCode) {\n          throw new FS.ErrnoError(errCode);\n        }\n        FS.currentPath = lookup.path;\n      },\n      createDefaultDirectories: function createDefaultDirectories() {\n        FS.mkdir('/tmp');\n        FS.mkdir('/home');\n        FS.mkdir('/home/web_user');\n      },\n      createDefaultDevices: function createDefaultDevices() {\n        // create /dev\n        FS.mkdir('/dev');\n        // setup /dev/null\n        FS.registerDevice(FS.makedev(1, 3), {\n          read: function read() {\n            return 0;\n          },\n          write: function write(stream, buffer, offset, length, pos) {\n            return length;\n          }\n        });\n        FS.mkdev('/dev/null', FS.makedev(1, 3));\n        // setup /dev/tty and /dev/tty1\n        // stderr needs to print output using err() rather than out()\n        // so we register a second tty just for it.\n        TTY.register(FS.makedev(5, 0), TTY.default_tty_ops);\n        TTY.register(FS.makedev(6, 0), TTY.default_tty1_ops);\n        FS.mkdev('/dev/tty', FS.makedev(5, 0));\n        FS.mkdev('/dev/tty1', FS.makedev(6, 0));\n        // setup /dev/[u]random\n        // use a buffer to avoid overhead of individual crypto calls per byte\n        var randomBuffer = new Uint8Array(1024),\n          randomLeft = 0;\n        var randomByte = function randomByte() {\n          if (randomLeft === 0) {\n            randomLeft = _randomFill(randomBuffer).byteLength;\n          }\n          return randomBuffer[--randomLeft];\n        };\n        FS.createDevice('/dev', 'random', randomByte);\n        FS.createDevice('/dev', 'urandom', randomByte);\n        // we're not going to emulate the actual shm device,\n        // just create the tmp dirs that reside in it commonly\n        FS.mkdir('/dev/shm');\n        FS.mkdir('/dev/shm/tmp');\n      },\n      createSpecialDirectories: function createSpecialDirectories() {\n        // create /proc/self/fd which allows /proc/self/fd/6 => readlink gives the\n        // name of the stream for fd 6 (see test_unistd_ttyname)\n        FS.mkdir('/proc');\n        var proc_self = FS.mkdir('/proc/self');\n        FS.mkdir('/proc/self/fd');\n        FS.mount({\n          mount: function mount() {\n            var node = FS.createNode(proc_self, 'fd', 16384 | 511 /* 0777 */, 73);\n            node.node_ops = {\n              lookup: function lookup(parent, name) {\n                var fd = +name;\n                var stream = FS.getStreamChecked(fd);\n                var ret = {\n                  parent: null,\n                  mount: {\n                    mountpoint: 'fake'\n                  },\n                  node_ops: {\n                    readlink: function readlink() {\n                      return stream.path;\n                    }\n                  }\n                };\n                ret.parent = ret; // make it look like a simple root node\n                return ret;\n              }\n            };\n            return node;\n          }\n        }, {}, '/proc/self/fd');\n      },\n      createStandardStreams: function createStandardStreams() {\n        // TODO deprecate the old functionality of a single\n        // input / output callback and that utilizes FS.createDevice\n        // and instead require a unique set of stream ops\n\n        // by default, we symlink the standard streams to the\n        // default tty devices. however, if the standard streams\n        // have been overwritten we create a unique device for\n        // them instead.\n        if (Module['stdin']) {\n          FS.createDevice('/dev', 'stdin', Module['stdin']);\n        } else {\n          FS.symlink('/dev/tty', '/dev/stdin');\n        }\n        if (Module['stdout']) {\n          FS.createDevice('/dev', 'stdout', null, Module['stdout']);\n        } else {\n          FS.symlink('/dev/tty', '/dev/stdout');\n        }\n        if (Module['stderr']) {\n          FS.createDevice('/dev', 'stderr', null, Module['stderr']);\n        } else {\n          FS.symlink('/dev/tty1', '/dev/stderr');\n        }\n\n        // open default streams for the stdin, stdout and stderr devices\n        var stdin = FS.open('/dev/stdin', 0);\n        var stdout = FS.open('/dev/stdout', 1);\n        var stderr = FS.open('/dev/stderr', 1);\n        assert(stdin.fd === 0, \"invalid handle for stdin (\".concat(stdin.fd, \")\"));\n        assert(stdout.fd === 1, \"invalid handle for stdout (\".concat(stdout.fd, \")\"));\n        assert(stderr.fd === 2, \"invalid handle for stderr (\".concat(stderr.fd, \")\"));\n      },\n      ensureErrnoError: function ensureErrnoError() {\n        if (FS.ErrnoError) return;\n        FS.ErrnoError = /** @this{Object} */function ErrnoError(errno, node) {\n          // We set the `name` property to be able to identify `FS.ErrnoError`\n          // - the `name` is a standard ECMA-262 property of error objects. Kind of good to have it anyway.\n          // - when using PROXYFS, an error can come from an underlying FS\n          // as different FS objects have their own FS.ErrnoError each,\n          // the test `err instanceof FS.ErrnoError` won't detect an error coming from another filesystem, causing bugs.\n          // we'll use the reliable test `err.name == \"ErrnoError\"` instead\n          this.name = 'ErrnoError';\n          this.node = node;\n          this.setErrno = /** @this{Object} */function (errno) {\n            this.errno = errno;\n            for (var key in ERRNO_CODES) {\n              if (ERRNO_CODES[key] === errno) {\n                this.code = key;\n                break;\n              }\n            }\n          };\n          this.setErrno(errno);\n          this.message = ERRNO_MESSAGES[errno];\n\n          // Try to get a maximally helpful stack trace. On Node.js, getting Error.stack\n          // now ensures it shows what we want.\n          if (this.stack) {\n            // Define the stack property for Node.js 4, which otherwise errors on the next line.\n            Object.defineProperty(this, \"stack\", {\n              value: new Error().stack,\n              writable: true\n            });\n            this.stack = demangleAll(this.stack);\n          }\n        };\n        FS.ErrnoError.prototype = new Error();\n        FS.ErrnoError.prototype.constructor = FS.ErrnoError;\n        // Some errors may happen quite a bit, to avoid overhead we reuse them (and suffer a lack of stack info)\n        [44].forEach(function (code) {\n          FS.genericErrors[code] = new FS.ErrnoError(code);\n          FS.genericErrors[code].stack = '<generic error, no stack>';\n        });\n      },\n      staticInit: function staticInit() {\n        FS.ensureErrnoError();\n        FS.nameTable = new Array(4096);\n        FS.mount(MEMFS, {}, '/');\n        FS.createDefaultDirectories();\n        FS.createDefaultDevices();\n        FS.createSpecialDirectories();\n        FS.filesystems = {\n          'MEMFS': MEMFS\n        };\n      },\n      init: function init(input, output, error) {\n        assert(!FS.init.initialized, 'FS.init was previously called. If you want to initialize later with custom parameters, remove any earlier calls (note that one is automatically added to the generated code)');\n        FS.init.initialized = true;\n        FS.ensureErrnoError();\n\n        // Allow Module.stdin etc. to provide defaults, if none explicitly passed to us here\n        Module['stdin'] = input || Module['stdin'];\n        Module['stdout'] = output || Module['stdout'];\n        Module['stderr'] = error || Module['stderr'];\n        FS.createStandardStreams();\n      },\n      quit: function quit() {\n        FS.init.initialized = false;\n        // force-flush all streams, so we get musl std streams printed out\n        _fflush(0);\n        // close all of our streams\n        for (var i = 0; i < FS.streams.length; i++) {\n          var stream = FS.streams[i];\n          if (!stream) {\n            continue;\n          }\n          FS.close(stream);\n        }\n      },\n      findObject: function findObject(path, dontResolveLastLink) {\n        var ret = FS.analyzePath(path, dontResolveLastLink);\n        if (!ret.exists) {\n          return null;\n        }\n        return ret.object;\n      },\n      analyzePath: function analyzePath(path, dontResolveLastLink) {\n        // operate from within the context of the symlink's target\n        try {\n          var lookup = FS.lookupPath(path, {\n            follow: !dontResolveLastLink\n          });\n          path = lookup.path;\n        } catch (e) {}\n        var ret = {\n          isRoot: false,\n          exists: false,\n          error: 0,\n          name: null,\n          path: null,\n          object: null,\n          parentExists: false,\n          parentPath: null,\n          parentObject: null\n        };\n        try {\n          var lookup = FS.lookupPath(path, {\n            parent: true\n          });\n          ret.parentExists = true;\n          ret.parentPath = lookup.path;\n          ret.parentObject = lookup.node;\n          ret.name = PATH.basename(path);\n          lookup = FS.lookupPath(path, {\n            follow: !dontResolveLastLink\n          });\n          ret.exists = true;\n          ret.path = lookup.path;\n          ret.object = lookup.node;\n          ret.name = lookup.node.name;\n          ret.isRoot = lookup.path === '/';\n        } catch (e) {\n          ret.error = e.errno;\n        }\n        ;\n        return ret;\n      },\n      createPath: function createPath(parent, path, canRead, canWrite) {\n        parent = typeof parent == 'string' ? parent : FS.getPath(parent);\n        var parts = path.split('/').reverse();\n        while (parts.length) {\n          var part = parts.pop();\n          if (!part) continue;\n          var current = PATH.join2(parent, part);\n          try {\n            FS.mkdir(current);\n          } catch (e) {\n            // ignore EEXIST\n          }\n          parent = current;\n        }\n        return current;\n      },\n      createFile: function createFile(parent, name, properties, canRead, canWrite) {\n        var path = PATH.join2(typeof parent == 'string' ? parent : FS.getPath(parent), name);\n        var mode = FS_getMode(canRead, canWrite);\n        return FS.create(path, mode);\n      },\n      createDataFile: function createDataFile(parent, name, data, canRead, canWrite, canOwn) {\n        var path = name;\n        if (parent) {\n          parent = typeof parent == 'string' ? parent : FS.getPath(parent);\n          path = name ? PATH.join2(parent, name) : parent;\n        }\n        var mode = FS_getMode(canRead, canWrite);\n        var node = FS.create(path, mode);\n        if (data) {\n          if (typeof data == 'string') {\n            var arr = new Array(data.length);\n            for (var i = 0, len = data.length; i < len; ++i) arr[i] = data.charCodeAt(i);\n            data = arr;\n          }\n          // make sure we can write to the file\n          FS.chmod(node, mode | 146);\n          var stream = FS.open(node, 577);\n          FS.write(stream, data, 0, data.length, 0, canOwn);\n          FS.close(stream);\n          FS.chmod(node, mode);\n        }\n        return node;\n      },\n      createDevice: function createDevice(parent, name, input, output) {\n        var path = PATH.join2(typeof parent == 'string' ? parent : FS.getPath(parent), name);\n        var mode = FS_getMode(!!input, !!output);\n        if (!FS.createDevice.major) FS.createDevice.major = 64;\n        var dev = FS.makedev(FS.createDevice.major++, 0);\n        // Create a fake device that a set of stream ops to emulate\n        // the old behavior.\n        FS.registerDevice(dev, {\n          open: function open(stream) {\n            stream.seekable = false;\n          },\n          close: function close(stream) {\n            // flush any pending line data\n            if (output && output.buffer && output.buffer.length) {\n              output(10);\n            }\n          },\n          read: function read(stream, buffer, offset, length, pos /* ignored */) {\n            var bytesRead = 0;\n            for (var i = 0; i < length; i++) {\n              var result;\n              try {\n                result = input();\n              } catch (e) {\n                throw new FS.ErrnoError(29);\n              }\n              if (result === undefined && bytesRead === 0) {\n                throw new FS.ErrnoError(6);\n              }\n              if (result === null || result === undefined) break;\n              bytesRead++;\n              buffer[offset + i] = result;\n            }\n            if (bytesRead) {\n              stream.node.timestamp = Date.now();\n            }\n            return bytesRead;\n          },\n          write: function write(stream, buffer, offset, length, pos) {\n            for (var i = 0; i < length; i++) {\n              try {\n                output(buffer[offset + i]);\n              } catch (e) {\n                throw new FS.ErrnoError(29);\n              }\n            }\n            if (length) {\n              stream.node.timestamp = Date.now();\n            }\n            return i;\n          }\n        });\n        return FS.mkdev(path, mode, dev);\n      },\n      forceLoadFile: function forceLoadFile(obj) {\n        if (obj.isDevice || obj.isFolder || obj.link || obj.contents) return true;\n        if (typeof XMLHttpRequest != 'undefined') {\n          throw new Error(\"Lazy loading should have been performed (contents set) in createLazyFile, but it was not. Lazy loading only works in web workers. Use --embed-file or --preload-file in emcc on the main thread.\");\n        } else if (read_) {\n          // Command-line.\n          try {\n            // WARNING: Can't read binary files in V8's d8 or tracemonkey's js, as\n            //          read() will try to parse UTF8.\n            obj.contents = intArrayFromString(read_(obj.url), true);\n            obj.usedBytes = obj.contents.length;\n          } catch (e) {\n            throw new FS.ErrnoError(29);\n          }\n        } else {\n          throw new Error('Cannot load without read() or XMLHttpRequest.');\n        }\n      },\n      createLazyFile: function createLazyFile(parent, name, url, canRead, canWrite) {\n        // Lazy chunked Uint8Array (implements get and length from Uint8Array). Actual getting is abstracted away for eventual reuse.\n        /** @constructor */\n        function LazyUint8Array() {\n          this.lengthKnown = false;\n          this.chunks = []; // Loaded chunks. Index is the chunk number\n        }\n        LazyUint8Array.prototype.get = /** @this{Object} */function LazyUint8Array_get(idx) {\n          if (idx > this.length - 1 || idx < 0) {\n            return undefined;\n          }\n          var chunkOffset = idx % this.chunkSize;\n          var chunkNum = idx / this.chunkSize | 0;\n          return this.getter(chunkNum)[chunkOffset];\n        };\n        LazyUint8Array.prototype.setDataGetter = function LazyUint8Array_setDataGetter(getter) {\n          this.getter = getter;\n        };\n        LazyUint8Array.prototype.cacheLength = function LazyUint8Array_cacheLength() {\n          // Find length\n          var xhr = new XMLHttpRequest();\n          xhr.open('HEAD', url, false);\n          xhr.send(null);\n          if (!(xhr.status >= 200 && xhr.status < 300 || xhr.status === 304)) throw new Error(\"Couldn't load \" + url + \". Status: \" + xhr.status);\n          var datalength = Number(xhr.getResponseHeader(\"Content-length\"));\n          var header;\n          var hasByteServing = (header = xhr.getResponseHeader(\"Accept-Ranges\")) && header === \"bytes\";\n          var usesGzip = (header = xhr.getResponseHeader(\"Content-Encoding\")) && header === \"gzip\";\n          var chunkSize = 1024 * 1024; // Chunk size in bytes\n\n          if (!hasByteServing) chunkSize = datalength;\n\n          // Function to get a range from the remote URL.\n          var doXHR = function doXHR(from, to) {\n            if (from > to) throw new Error(\"invalid range (\" + from + \", \" + to + \") or no bytes requested!\");\n            if (to > datalength - 1) throw new Error(\"only \" + datalength + \" bytes available! programmer error!\");\n\n            // TODO: Use mozResponseArrayBuffer, responseStream, etc. if available.\n            var xhr = new XMLHttpRequest();\n            xhr.open('GET', url, false);\n            if (datalength !== chunkSize) xhr.setRequestHeader(\"Range\", \"bytes=\" + from + \"-\" + to);\n\n            // Some hints to the browser that we want binary data.\n            xhr.responseType = 'arraybuffer';\n            if (xhr.overrideMimeType) {\n              xhr.overrideMimeType('text/plain; charset=x-user-defined');\n            }\n            xhr.send(null);\n            if (!(xhr.status >= 200 && xhr.status < 300 || xhr.status === 304)) throw new Error(\"Couldn't load \" + url + \". Status: \" + xhr.status);\n            if (xhr.response !== undefined) {\n              return new Uint8Array(/** @type{Array<number>} */xhr.response || []);\n            }\n            return intArrayFromString(xhr.responseText || '', true);\n          };\n          var lazyArray = this;\n          lazyArray.setDataGetter(function (chunkNum) {\n            var start = chunkNum * chunkSize;\n            var end = (chunkNum + 1) * chunkSize - 1; // including this byte\n            end = Math.min(end, datalength - 1); // if datalength-1 is selected, this is the last block\n            if (typeof lazyArray.chunks[chunkNum] == 'undefined') {\n              lazyArray.chunks[chunkNum] = doXHR(start, end);\n            }\n            if (typeof lazyArray.chunks[chunkNum] == 'undefined') throw new Error('doXHR failed!');\n            return lazyArray.chunks[chunkNum];\n          });\n          if (usesGzip || !datalength) {\n            // if the server uses gzip or doesn't supply the length, we have to download the whole file to get the (uncompressed) length\n            chunkSize = datalength = 1; // this will force getter(0)/doXHR do download the whole file\n            datalength = this.getter(0).length;\n            chunkSize = datalength;\n            out(\"LazyFiles on gzip forces download of the whole file when length is accessed\");\n          }\n          this._length = datalength;\n          this._chunkSize = chunkSize;\n          this.lengthKnown = true;\n        };\n        if (typeof XMLHttpRequest != 'undefined') {\n          if (!ENVIRONMENT_IS_WORKER) throw 'Cannot do synchronous binary XHRs outside webworkers in modern browsers. Use --embed-file or --preload-file in emcc';\n          var lazyArray = new LazyUint8Array();\n          Object.defineProperties(lazyArray, {\n            length: {\n              get: /** @this{Object} */function get() {\n                if (!this.lengthKnown) {\n                  this.cacheLength();\n                }\n                return this._length;\n              }\n            },\n            chunkSize: {\n              get: /** @this{Object} */function get() {\n                if (!this.lengthKnown) {\n                  this.cacheLength();\n                }\n                return this._chunkSize;\n              }\n            }\n          });\n          var properties = {\n            isDevice: false,\n            contents: lazyArray\n          };\n        } else {\n          var properties = {\n            isDevice: false,\n            url: url\n          };\n        }\n        var node = FS.createFile(parent, name, properties, canRead, canWrite);\n        // This is a total hack, but I want to get this lazy file code out of the\n        // core of MEMFS. If we want to keep this lazy file concept I feel it should\n        // be its own thin LAZYFS proxying calls to MEMFS.\n        if (properties.contents) {\n          node.contents = properties.contents;\n        } else if (properties.url) {\n          node.contents = null;\n          node.url = properties.url;\n        }\n        // Add a function that defers querying the file size until it is asked the first time.\n        Object.defineProperties(node, {\n          usedBytes: {\n            get: /** @this {FSNode} */function get() {\n              return this.contents.length;\n            }\n          }\n        });\n        // override each stream op with one that tries to force load the lazy file first\n        var stream_ops = {};\n        var keys = Object.keys(node.stream_ops);\n        keys.forEach(function (key) {\n          var fn = node.stream_ops[key];\n          stream_ops[key] = function forceLoadLazyFile() {\n            FS.forceLoadFile(node);\n            return fn.apply(null, arguments);\n          };\n        });\n        function writeChunks(stream, buffer, offset, length, position) {\n          var contents = stream.node.contents;\n          if (position >= contents.length) return 0;\n          var size = Math.min(contents.length - position, length);\n          assert(size >= 0);\n          if (contents.slice) {\n            // normal array\n            for (var i = 0; i < size; i++) {\n              buffer[offset + i] = contents[position + i];\n            }\n          } else {\n            for (var i = 0; i < size; i++) {\n              // LazyUint8Array from sync binary XHR\n              buffer[offset + i] = contents.get(position + i);\n            }\n          }\n          return size;\n        }\n        // use a custom read function\n        stream_ops.read = function (stream, buffer, offset, length, position) {\n          FS.forceLoadFile(node);\n          return writeChunks(stream, buffer, offset, length, position);\n        };\n        // use a custom mmap function\n        stream_ops.mmap = function (stream, length, position, prot, flags) {\n          FS.forceLoadFile(node);\n          var ptr = mmapAlloc(length);\n          if (!ptr) {\n            throw new FS.ErrnoError(48);\n          }\n          writeChunks(stream, HEAP8, ptr, length, position);\n          return {\n            ptr: ptr,\n            allocated: true\n          };\n        };\n        node.stream_ops = stream_ops;\n        return node;\n      },\n      absolutePath: function absolutePath() {\n        abort('FS.absolutePath has been removed; use PATH_FS.resolve instead');\n      },\n      createFolder: function createFolder() {\n        abort('FS.createFolder has been removed; use FS.mkdir instead');\n      },\n      createLink: function createLink() {\n        abort('FS.createLink has been removed; use FS.symlink instead');\n      },\n      joinPath: function joinPath() {\n        abort('FS.joinPath has been removed; use PATH.join instead');\n      },\n      mmapAlloc: function mmapAlloc() {\n        abort('FS.mmapAlloc has been replaced by the top level function mmapAlloc');\n      },\n      standardizePath: function standardizePath() {\n        abort('FS.standardizePath has been removed; use PATH.normalize instead');\n      }\n    };\n    ERRNO_CODES = {\n      'EPERM': 63,\n      'ENOENT': 44,\n      'ESRCH': 71,\n      'EINTR': 27,\n      'EIO': 29,\n      'ENXIO': 60,\n      'E2BIG': 1,\n      'ENOEXEC': 45,\n      'EBADF': 8,\n      'ECHILD': 12,\n      'EAGAIN': 6,\n      'EWOULDBLOCK': 6,\n      'ENOMEM': 48,\n      'EACCES': 2,\n      'EFAULT': 21,\n      'ENOTBLK': 105,\n      'EBUSY': 10,\n      'EEXIST': 20,\n      'EXDEV': 75,\n      'ENODEV': 43,\n      'ENOTDIR': 54,\n      'EISDIR': 31,\n      'EINVAL': 28,\n      'ENFILE': 41,\n      'EMFILE': 33,\n      'ENOTTY': 59,\n      'ETXTBSY': 74,\n      'EFBIG': 22,\n      'ENOSPC': 51,\n      'ESPIPE': 70,\n      'EROFS': 69,\n      'EMLINK': 34,\n      'EPIPE': 64,\n      'EDOM': 18,\n      'ERANGE': 68,\n      'ENOMSG': 49,\n      'EIDRM': 24,\n      'ECHRNG': 106,\n      'EL2NSYNC': 156,\n      'EL3HLT': 107,\n      'EL3RST': 108,\n      'ELNRNG': 109,\n      'EUNATCH': 110,\n      'ENOCSI': 111,\n      'EL2HLT': 112,\n      'EDEADLK': 16,\n      'ENOLCK': 46,\n      'EBADE': 113,\n      'EBADR': 114,\n      'EXFULL': 115,\n      'ENOANO': 104,\n      'EBADRQC': 103,\n      'EBADSLT': 102,\n      'EDEADLOCK': 16,\n      'EBFONT': 101,\n      'ENOSTR': 100,\n      'ENODATA': 116,\n      'ETIME': 117,\n      'ENOSR': 118,\n      'ENONET': 119,\n      'ENOPKG': 120,\n      'EREMOTE': 121,\n      'ENOLINK': 47,\n      'EADV': 122,\n      'ESRMNT': 123,\n      'ECOMM': 124,\n      'EPROTO': 65,\n      'EMULTIHOP': 36,\n      'EDOTDOT': 125,\n      'EBADMSG': 9,\n      'ENOTUNIQ': 126,\n      'EBADFD': 127,\n      'EREMCHG': 128,\n      'ELIBACC': 129,\n      'ELIBBAD': 130,\n      'ELIBSCN': 131,\n      'ELIBMAX': 132,\n      'ELIBEXEC': 133,\n      'ENOSYS': 52,\n      'ENOTEMPTY': 55,\n      'ENAMETOOLONG': 37,\n      'ELOOP': 32,\n      'EOPNOTSUPP': 138,\n      'EPFNOSUPPORT': 139,\n      'ECONNRESET': 15,\n      'ENOBUFS': 42,\n      'EAFNOSUPPORT': 5,\n      'EPROTOTYPE': 67,\n      'ENOTSOCK': 57,\n      'ENOPROTOOPT': 50,\n      'ESHUTDOWN': 140,\n      'ECONNREFUSED': 14,\n      'EADDRINUSE': 3,\n      'ECONNABORTED': 13,\n      'ENETUNREACH': 40,\n      'ENETDOWN': 38,\n      'ETIMEDOUT': 73,\n      'EHOSTDOWN': 142,\n      'EHOSTUNREACH': 23,\n      'EINPROGRESS': 26,\n      'EALREADY': 7,\n      'EDESTADDRREQ': 17,\n      'EMSGSIZE': 35,\n      'EPROTONOSUPPORT': 66,\n      'ESOCKTNOSUPPORT': 137,\n      'EADDRNOTAVAIL': 4,\n      'ENETRESET': 39,\n      'EISCONN': 30,\n      'ENOTCONN': 53,\n      'ETOOMANYREFS': 141,\n      'EUSERS': 136,\n      'EDQUOT': 19,\n      'ESTALE': 72,\n      'ENOTSUP': 138,\n      'ENOMEDIUM': 148,\n      'EILSEQ': 25,\n      'EOVERFLOW': 61,\n      'ECANCELED': 11,\n      'ENOTRECOVERABLE': 56,\n      'EOWNERDEAD': 62,\n      'ESTRPIPE': 135\n    };\n    ;\n    var FSNode = /** @constructor */function FSNode(parent, name, mode, rdev) {\n      if (!parent) {\n        parent = this; // root node sets parent to itself\n      }\n      this.parent = parent;\n      this.mount = parent.mount;\n      this.mounted = null;\n      this.id = FS.nextInode++;\n      this.name = name;\n      this.mode = mode;\n      this.node_ops = {};\n      this.stream_ops = {};\n      this.rdev = rdev;\n    };\n    var readMode = 292 /*292*/ | 73 /*73*/;\n    var writeMode = 146 /*146*/;\n    Object.defineProperties(FSNode.prototype, {\n      read: {\n        get: /** @this{FSNode} */function get() {\n          return (this.mode & readMode) === readMode;\n        },\n        set: /** @this{FSNode} */function set(val) {\n          val ? this.mode |= readMode : this.mode &= ~readMode;\n        }\n      },\n      write: {\n        get: /** @this{FSNode} */function get() {\n          return (this.mode & writeMode) === writeMode;\n        },\n        set: /** @this{FSNode} */function set(val) {\n          val ? this.mode |= writeMode : this.mode &= ~writeMode;\n        }\n      },\n      isFolder: {\n        get: /** @this{FSNode} */function get() {\n          return FS.isDir(this.mode);\n        }\n      },\n      isDevice: {\n        get: /** @this{FSNode} */function get() {\n          return FS.isChrdev(this.mode);\n        }\n      }\n    });\n    FS.FSNode = FSNode;\n    FS.createPreloadedFile = FS_createPreloadedFile;\n    FS.staticInit();\n    ;\n    function checkIncomingModuleAPI() {\n      ignoredModuleProp('fetchSettings');\n    }\n    var wasmImports = {\n      abort: _abort,\n      emscripten_memcpy_big: _emscripten_memcpy_big,\n      emscripten_resize_heap: _emscripten_resize_heap,\n      exit: _exit,\n      fd_write: _fd_write\n    };\n    var wasmExports = createWasm();\n    var ___wasm_call_ctors = createExportWrapper('__wasm_call_ctors');\n    var _archive_entry_pathname = Module['_archive_entry_pathname'] = createExportWrapper('archive_entry_pathname');\n    var _archive_entry_size = Module['_archive_entry_size'] = createExportWrapper('archive_entry_size');\n    var _archive_read_new = Module['_archive_read_new'] = createExportWrapper('archive_read_new');\n    var _archive_read_open = Module['_archive_read_open'] = createExportWrapper('archive_read_open');\n    var _archive_read_data = Module['_archive_read_data'] = createExportWrapper('archive_read_data');\n    var _archive_read_open_memory = Module['_archive_read_open_memory'] = createExportWrapper('archive_read_open_memory');\n    var _archive_read_close = Module['_archive_read_close'] = createExportWrapper('archive_read_close');\n    var _archive_read_free = Module['_archive_read_free'] = createExportWrapper('archive_read_free');\n    var _archive_read_next_header = Module['_archive_read_next_header'] = createExportWrapper('archive_read_next_header');\n    var ___errno_location = createExportWrapper('__errno_location');\n    var _fflush = Module['_fflush'] = createExportWrapper('fflush');\n    var _malloc = Module['_malloc'] = createExportWrapper('malloc');\n    var _free = Module['_free'] = createExportWrapper('free');\n    var _emscripten_stack_init2 = function _emscripten_stack_init() {\n      return (_emscripten_stack_init2 = wasmExports['emscripten_stack_init'])();\n    };\n    var _emscripten_stack_get_free2 = function _emscripten_stack_get_free() {\n      return (_emscripten_stack_get_free2 = wasmExports['emscripten_stack_get_free'])();\n    };\n    var _emscripten_stack_get_base2 = function _emscripten_stack_get_base() {\n      return (_emscripten_stack_get_base2 = wasmExports['emscripten_stack_get_base'])();\n    };\n    var _emscripten_stack_get_end2 = function _emscripten_stack_get_end() {\n      return (_emscripten_stack_get_end2 = wasmExports['emscripten_stack_get_end'])();\n    };\n    var stackSave = createExportWrapper('stackSave');\n    var stackRestore = createExportWrapper('stackRestore');\n    var stackAlloc = createExportWrapper('stackAlloc');\n    var _emscripten_stack_get_current2 = function _emscripten_stack_get_current() {\n      return (_emscripten_stack_get_current2 = wasmExports['emscripten_stack_get_current'])();\n    };\n    var dynCall_jii = Module['dynCall_jii'] = createExportWrapper('dynCall_jii');\n    var dynCall_jiiji = Module['dynCall_jiiji'] = createExportWrapper('dynCall_jiiji');\n    var dynCall_jiij = Module['dynCall_jiij'] = createExportWrapper('dynCall_jiij');\n\n    // include: postamble.js\n    // === Auto-generated postamble setup entry stuff ===\n\n    Module['ERRNO_CODES'] = ERRNO_CODES;\n    Module['ccall'] = ccall;\n    Module['cwrap'] = cwrap;\n    Module['setValue'] = setValue;\n    Module['getValue'] = getValue;\n    Module['PATH'] = PATH;\n    Module['FS'] = FS;\n    var missingLibrarySymbols = ['writeI53ToI64', 'writeI53ToI64Clamped', 'writeI53ToI64Signaling', 'writeI53ToU64Clamped', 'writeI53ToU64Signaling', 'readI53FromI64', 'readI53FromU64', 'convertI32PairToI53', 'convertI32PairToI53Checked', 'convertU32PairToI53', 'growMemory', 'isLeapYear', 'ydayFromDate', 'arraySum', 'addDays', 'setErrNo', 'inetPton4', 'inetNtop4', 'inetPton6', 'inetNtop6', 'readSockaddr', 'writeSockaddr', 'getHostByName', 'getCallstack', 'emscriptenLog', 'convertPCtoSourceLocation', 'readEmAsmArgs', 'jstoi_q', 'jstoi_s', 'getExecutableName', 'listenOnce', 'autoResumeAudioContext', 'dynCallLegacy', 'getDynCaller', 'dynCall', 'handleException', 'runtimeKeepalivePush', 'runtimeKeepalivePop', 'callUserCallback', 'maybeExit', 'safeSetTimeout', 'asmjsMangle', 'handleAllocatorInit', 'HandleAllocator', 'getNativeTypeSize', 'STACK_SIZE', 'STACK_ALIGN', 'POINTER_SIZE', 'ASSERTIONS', 'uleb128Encode', 'sigToWasmTypes', 'generateFuncType', 'convertJsFunctionToWasm', 'getEmptyTableSlot', 'updateTableMap', 'getFunctionAddress', 'addFunction', 'removeFunction', 'reallyNegative', 'unSign', 'strLen', 'reSign', 'formatString', 'intArrayToString', 'AsciiToString', 'stringToAscii', 'UTF16ToString', 'stringToUTF16', 'lengthBytesUTF16', 'UTF32ToString', 'stringToUTF32', 'lengthBytesUTF32', 'stringToNewUTF8', 'registerKeyEventCallback', 'maybeCStringToJsString', 'findEventTarget', 'findCanvasEventTarget', 'getBoundingClientRect', 'fillMouseEventData', 'registerMouseEventCallback', 'registerWheelEventCallback', 'registerUiEventCallback', 'registerFocusEventCallback', 'fillDeviceOrientationEventData', 'registerDeviceOrientationEventCallback', 'fillDeviceMotionEventData', 'registerDeviceMotionEventCallback', 'screenOrientation', 'fillOrientationChangeEventData', 'registerOrientationChangeEventCallback', 'fillFullscreenChangeEventData', 'registerFullscreenChangeEventCallback', 'JSEvents_requestFullscreen', 'JSEvents_resizeCanvasForFullscreen', 'registerRestoreOldStyle', 'hideEverythingExceptGivenElement', 'restoreHiddenElements', 'setLetterbox', 'softFullscreenResizeWebGLRenderTarget', 'doRequestFullscreen', 'fillPointerlockChangeEventData', 'registerPointerlockChangeEventCallback', 'registerPointerlockErrorEventCallback', 'requestPointerLock', 'fillVisibilityChangeEventData', 'registerVisibilityChangeEventCallback', 'registerTouchEventCallback', 'fillGamepadEventData', 'registerGamepadEventCallback', 'registerBeforeUnloadEventCallback', 'fillBatteryEventData', 'battery', 'registerBatteryEventCallback', 'setCanvasElementSize', 'getCanvasElementSize', 'jsStackTrace', 'stackTrace', 'getEnvStrings', 'checkWasiClock', 'wasiRightsToMuslOFlags', 'wasiOFlagsToMuslOFlags', 'createDyncallWrapper', 'setImmediateWrapped', 'clearImmediateWrapped', 'polyfillSetImmediate', 'getPromise', 'makePromise', 'idsToPromises', 'makePromiseCallback', 'ExceptionInfo', 'findMatchingCatch', 'setMainLoop', 'getSocketFromFD', 'getSocketAddress', '_setNetworkCallback', 'heapObjectForWebGLType', 'heapAccessShiftForWebGLHeap', 'webgl_enable_ANGLE_instanced_arrays', 'webgl_enable_OES_vertex_array_object', 'webgl_enable_WEBGL_draw_buffers', 'webgl_enable_WEBGL_multi_draw', 'emscriptenWebGLGet', 'computeUnpackAlignedImageSize', 'colorChannelsInGlTextureFormat', 'emscriptenWebGLGetTexPixelData', '__glGenObject', 'emscriptenWebGLGetUniform', 'webglGetUniformLocation', 'webglPrepareUniformLocationsBeforeFirstUse', 'webglGetLeftBracePos', 'emscriptenWebGLGetVertexAttrib', '__glGetActiveAttribOrUniform', 'writeGLArray', 'registerWebGlEventCallback', 'runAndAbortIfError', 'SDL_unicode', 'SDL_ttfContext', 'SDL_audio', 'GLFW_Window', 'ALLOC_NORMAL', 'ALLOC_STACK', 'allocate', 'writeStringToMemory', 'writeAsciiToMemory'];\n    missingLibrarySymbols.forEach(missingLibrarySymbol);\n    var unexportedSymbols = ['run', 'addOnPreRun', 'addOnInit', 'addOnPreMain', 'addOnExit', 'addOnPostRun', 'addRunDependency', 'removeRunDependency', 'FS_createFolder', 'FS_createPath', 'FS_createDataFile', 'FS_createLazyFile', 'FS_createLink', 'FS_createDevice', 'FS_readFile', 'FS_unlink', 'out', 'err', 'callMain', 'abort', 'keepRuntimeAlive', 'wasmMemory', 'wasmTable', 'wasmExports', 'stackAlloc', 'stackSave', 'stackRestore', 'getTempRet0', 'setTempRet0', 'writeStackCookie', 'checkStackCookie', 'ptrToString', 'zeroMemory', 'exitJS', 'getHeapMax', 'abortOnCannotGrowMemory', 'ENV', 'MONTH_DAYS_REGULAR', 'MONTH_DAYS_LEAP', 'MONTH_DAYS_REGULAR_CUMULATIVE', 'MONTH_DAYS_LEAP_CUMULATIVE', 'ERRNO_MESSAGES', 'DNS', 'Protocols', 'Sockets', 'initRandomFill', 'randomFill', 'timers', 'warnOnce', 'UNWIND_CACHE', 'readEmAsmArgsArray', 'asyncLoad', 'alignMemory', 'mmapAlloc', 'getCFunc', 'freeTableIndexes', 'functionsInTableMap', 'PATH_FS', 'UTF8Decoder', 'UTF8ArrayToString', 'UTF8ToString', 'stringToUTF8Array', 'stringToUTF8', 'lengthBytesUTF8', 'intArrayFromString', 'UTF16Decoder', 'stringToUTF8OnStack', 'writeArrayToMemory', 'JSEvents', 'specialHTMLTargets', 'currentFullscreenStrategy', 'restoreOldWindowedStyle', 'demangle', 'demangleAll', 'ExitStatus', 'flush_NO_FILESYSTEM', 'promiseMap', 'uncaughtExceptionCount', 'exceptionLast', 'exceptionCaught', 'Browser', 'wget', 'SYSCALLS', 'preloadPlugins', 'FS_createPreloadedFile', 'FS_modeStringToFlags', 'FS_getMode', 'FS_stdin_getChar_buffer', 'FS_stdin_getChar', 'MEMFS', 'TTY', 'PIPEFS', 'SOCKFS', 'tempFixedLengthArray', 'miniTempWebGLFloatBuffers', 'miniTempWebGLIntBuffers', 'GL', 'emscripten_webgl_power_preferences', 'AL', 'GLUT', 'EGL', 'GLEW', 'IDBStore', 'SDL', 'SDL_gfx', 'GLFW', 'allocateUTF8', 'allocateUTF8OnStack'];\n    unexportedSymbols.forEach(unexportedRuntimeSymbol);\n    var calledRun;\n    dependenciesFulfilled = function runCaller() {\n      // If run has never been called, and we should call run (INVOKE_RUN is true, and Module.noInitialRun is not false)\n      if (!calledRun) run();\n      if (!calledRun) dependenciesFulfilled = runCaller; // try this again later, after new deps are fulfilled\n    };\n    function stackCheckInit() {\n      // This is normally called automatically during __wasm_call_ctors but need to\n      // get these values before even running any of the ctors so we call it redundantly\n      // here.\n      _emscripten_stack_init2();\n      // TODO(sbc): Move writeStackCookie to native to to avoid this.\n      writeStackCookie();\n    }\n    function run() {\n      if (runDependencies > 0) {\n        return;\n      }\n      stackCheckInit();\n      preRun();\n\n      // a preRun added a dependency, run will be called later\n      if (runDependencies > 0) {\n        return;\n      }\n      function doRun() {\n        // run may have just been called through dependencies being fulfilled just in this very frame,\n        // or while the async setStatus time below was happening\n        if (calledRun) return;\n        calledRun = true;\n        Module['calledRun'] = true;\n        if (ABORT) return;\n        initRuntime();\n        readyPromiseResolve(Module);\n        if (Module['onRuntimeInitialized']) Module['onRuntimeInitialized']();\n        assert(!Module['_main'], 'compiled without a main, but one is present. if you added it from JS, use Module[\"onRuntimeInitialized\"]');\n        postRun();\n      }\n      if (Module['setStatus']) {\n        Module['setStatus']('Running...');\n        setTimeout(function () {\n          setTimeout(function () {\n            Module['setStatus']('');\n          }, 1);\n          doRun();\n        }, 1);\n      } else {\n        doRun();\n      }\n      checkStackCookie();\n    }\n    function checkUnflushedContent() {\n      // Compiler settings do not allow exiting the runtime, so flushing\n      // the streams is not possible. but in ASSERTIONS mode we check\n      // if there was something to flush, and if so tell the user they\n      // should request that the runtime be exitable.\n      // Normally we would not even include flush() at all, but in ASSERTIONS\n      // builds we do so just for this check, and here we see if there is any\n      // content to flush, that is, we check if there would have been\n      // something a non-ASSERTIONS build would have not seen.\n      // How we flush the streams depends on whether we are in SYSCALLS_REQUIRE_FILESYSTEM=0\n      // mode (which has its own special function for this; otherwise, all\n      // the code is inside libc)\n      var oldOut = out;\n      var oldErr = err;\n      var has = false;\n      out = err = function err(x) {\n        has = true;\n      };\n      try {\n        // it doesn't matter if it fails\n        flush_NO_FILESYSTEM();\n        // also flush in the JS FS layer\n        ['stdout', 'stderr'].forEach(function (name) {\n          var info = FS.analyzePath('/dev/' + name);\n          if (!info) return;\n          var stream = info.object;\n          var rdev = stream.rdev;\n          var tty = TTY.ttys[rdev];\n          if (tty && tty.output && tty.output.length) {\n            has = true;\n          }\n        });\n      } catch (e) {}\n      out = oldOut;\n      err = oldErr;\n      if (has) {\n        _warnOnce('stdio streams had content in them that was not flushed. you should set EXIT_RUNTIME to 1 (see the Emscripten FAQ), or make sure to emit a newline when you printf etc.');\n        _warnOnce('(this may also be due to not including full filesystem support - try building with -sFORCE_FILESYSTEM)');\n      }\n    }\n    if (Module['preInit']) {\n      if (typeof Module['preInit'] == 'function') Module['preInit'] = [Module['preInit']];\n      while (Module['preInit'].length > 0) {\n        Module['preInit'].pop()();\n      }\n    }\n    run();\n\n    // end include: postamble.js\n    // include: /home/anastasiia/projects/custom_loading_packages/fetch_untar_solution/libarchive-wasm-9-10/test-lib/libarchive-3.7.6/post.js\n\n    // Emscripten doesn't make UTF8ToString or wasmTable available on Module by default...\n    Module.UTF8ToString = UTF8ToString;\n    Module.wasmTable = wasmTable;\n    // Emscripten has a bug where it accidentally exposes an empty object as Module.ERRNO_CODES\n    Module.ERRNO_CODES = ERRNO_CODES;\n    if (!('wasmTable' in Module)) {\n      Module['wasmTable'] = wasmTable;\n    }\n    Module['FS'] = FS;\n    Module['PATH'] = PATH;\n\n    // end include: /home/anastasiia/projects/custom_loading_packages/fetch_untar_solution/libarchive-wasm-9-10/test-lib/libarchive-3.7.6/post.js\n\n    return moduleArg.ready;\n  };\n}();\nif (( false ? 0 : _typeof(exports)) === 'object' && ( false ? 0 : _typeof(module)) === 'object') module.exports = Module;else if (true) !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function () {\n  return Module;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n//# sourceURL=webpack://untar-example/./lib/libarchive.js?");

/***/ }),

/***/ "./src/bz2.js":
/*!********************!*\
  !*** ./src/bz2.js ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decompress: () => (/* binding */ decompress)\n/* harmony export */ });\n/**\n * This file is modified from the original `index.js` in the `SheetJS/bz2` repository,\n * available at https://github.com/sheetjs/bz2.\n * \n * Changes made: [\n * - change from CommonJs export to ES6 Modules Export\n * - removing definition of the anonymous function bz2\n * ]\n */\n\n\n// https://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/lxr/source/src/util/compress/bzip2/crctable.c\nvar crc32Table = [0x00000000, 0x04c11db7, 0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b, 0x1a864db2, 0x1e475005, 0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61, 0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd, 0x4c11db70, 0x48d0c6c7, 0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b, 0x569796c2, 0x52568b75, 0x6a1936c8, 0x6ed82b7f, 0x639b0da6, 0x675a1011, 0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd, 0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039, 0x8b27c03c, 0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5, 0xbe2b5b58, 0xbaea46ef, 0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea, 0xa06c0b5d, 0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49, 0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95, 0xf23a8028, 0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1, 0xe13ef6f4, 0xe5ffeb43, 0xe8bccd9a, 0xec7dd02d, 0x34867077, 0x30476dc0, 0x3d044b19, 0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072, 0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13, 0x054bf6a4, 0x0808d07d, 0x0cc9cdca, 0x7897ab07, 0x7c56b6b0, 0x71159069, 0x75d48dde, 0x6b93dddb, 0x6f52c06c, 0x6211e6b5, 0x66d0fb02, 0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066, 0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba, 0xaca5c697, 0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc, 0xb6238b25, 0xb2e29692, 0x8aad2b2f, 0x8e6c3698, 0x832f1041, 0x87ee0df6, 0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a, 0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e, 0xf3b06b3b, 0xf771768c, 0xfa325055, 0xfef34de2, 0xc6bcf05f, 0xc27dede8, 0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34, 0xdc3abded, 0xd8fba05a, 0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637, 0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb, 0x4f040d56, 0x4bc510e1, 0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d, 0x558240e4, 0x51435d53, 0x251d3b9e, 0x21dc2629, 0x2c9f00f0, 0x285e1d47, 0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b, 0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff, 0x1011a0fa, 0x14d0bd4d, 0x19939b94, 0x1d528623, 0xf12f560e, 0xf5ee4bb9, 0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc, 0xef68060b, 0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f, 0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3, 0xbd3e8d7e, 0xb9ff90c9, 0xb4bcb610, 0xb07daba7, 0xae3afba2, 0xaafbe615, 0xa7b8c0cc, 0xa379dd7b, 0x9b3660c6, 0x9ff77d71, 0x92b45ba8, 0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3, 0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645, 0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c, 0x7b827d21, 0x7f436096, 0x7200464f, 0x76c15bf8, 0x68860bfd, 0x6c47164a, 0x61043093, 0x65c52d24, 0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30, 0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec, 0x3793a651, 0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a, 0x2d15ebe3, 0x29d4f654, 0xc5a92679, 0xc1683bce, 0xcc2b1d17, 0xc8ea00a0, 0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c, 0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18, 0xf0a5bd1d, 0xf464a0aa, 0xf9278673, 0xfde69bc4, 0x89b8fd09, 0x8d79e0be, 0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662, 0x933eb0bb, 0x97ffad0c, 0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668, 0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4];\n\n// generated from 1 << i, except for 32\nvar masks = [0x00000000, 0x00000001, 0x00000003, 0x00000007, 0x0000000f, 0x0000001f, 0x0000003f, 0x0000007f, 0x000000ff, 0x000001ff, 0x000003ff, 0x000007ff, 0x00000fff, 0x00001fff, 0x00003fff, 0x00007fff, 0x0000ffff, 0x0001ffff, 0x0003ffff, 0x0007ffff, 0x000fffff, 0x001fffff, 0x003fffff, 0x007fffff, 0x00ffffff, 0x01ffffff, 0x03ffffff, 0x07ffffff, 0x0fffffff, 0x1fffffff, 0x3fffffff, -0x80000000];\nfunction createOrderedHuffmanTable(lengths) {\n  var z = [];\n  for (var i = 0; i < lengths.length; i += 1) {\n    z.push([i, lengths[i]]);\n  }\n  z.push([lengths.length, -1]);\n  var table = [];\n  var start = z[0][0];\n  var bits = z[0][1];\n  for (var _i = 0; _i < z.length; _i += 1) {\n    var finish = z[_i][0];\n    var endbits = z[_i][1];\n    if (bits) {\n      for (var code = start; code < finish; code += 1) {\n        table.push({\n          code: code,\n          bits: bits,\n          symbol: undefined\n        });\n      }\n    }\n    start = finish;\n    bits = endbits;\n    if (endbits === -1) {\n      break;\n    }\n  }\n  table.sort(function (a, b) {\n    return a.bits - b.bits || a.code - b.code;\n  });\n  var tempBits = 0;\n  var symbol = -1;\n  var fastAccess = [];\n  var current;\n  for (var _i2 = 0; _i2 < table.length; _i2 += 1) {\n    var t = table[_i2];\n    symbol += 1;\n    if (t.bits !== tempBits) {\n      symbol <<= t.bits - tempBits;\n      tempBits = t.bits;\n      current = fastAccess[tempBits] = {};\n    }\n    t.symbol = symbol;\n    current[symbol] = t;\n  }\n  return {\n    table: table,\n    fastAccess: fastAccess\n  };\n}\nfunction bwtReverse(src, primary) {\n  if (primary < 0 || primary >= src.length) {\n    throw RangeError('Out of bound');\n  }\n  var unsorted = src.slice();\n  src.sort(function (a, b) {\n    return a - b;\n  });\n  var start = {};\n  for (var _i3 = src.length - 1; _i3 >= 0; _i3 -= 1) {\n    start[src[_i3]] = _i3;\n  }\n  var links = [];\n  for (var _i4 = 0; _i4 < src.length; _i4 += 1) {\n    links.push(start[unsorted[_i4]]++); // eslint-disable-line no-plusplus\n  }\n  var i;\n  var first = src[i = primary];\n  var ret = [];\n  for (var j = 1; j < src.length; j += 1) {\n    var x = src[i = links[i]];\n    if (x === undefined) {\n      ret.push(255);\n    } else {\n      ret.push(x);\n    }\n  }\n  ret.push(first);\n  ret.reverse();\n  return ret;\n}\nfunction decompress(bytes) {\n  var checkCRC = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  var index = 0;\n  var bitfield = 0;\n  var bits = 0;\n  var _read = function read(n) {\n    if (n >= 32) {\n      var nd = n >> 1;\n      return _read(nd) * (1 << nd) + _read(n - nd);\n    }\n    while (bits < n) {\n      bitfield = (bitfield << 8) + bytes[index];\n      index += 1;\n      bits += 8;\n    }\n    var m = masks[n];\n    var r = bitfield >> bits - n & m;\n    bits -= n;\n    bitfield &= ~(m << bits);\n    return r;\n  };\n  var magic = _read(16);\n  if (magic !== 0x425A) {\n    // 'BZ'\n    throw new Error('Invalid magic');\n  }\n  var method = _read(8);\n  if (method !== 0x68) {\n    // h for huffman\n    throw new Error('Invalid method');\n  }\n  var blocksize = _read(8);\n  if (blocksize >= 49 && blocksize <= 57) {\n    // 1..9\n    blocksize -= 48;\n  } else {\n    throw new Error('Invalid blocksize');\n  }\n  var out = new Uint8Array(bytes.length * 1.5);\n  var outIndex = 0;\n  var newCRC = -1;\n  while (true) {\n    var blocktype = _read(48);\n    var crc = _read(32) | 0;\n    if (blocktype === 0x314159265359) {\n      if (_read(1)) {\n        throw new Error('do not support randomised');\n      }\n      var pointer = _read(24);\n      var used = [];\n      var usedGroups = _read(16);\n      for (var _i5 = 1 << 15; _i5 > 0; _i5 >>= 1) {\n        if (!(usedGroups & _i5)) {\n          for (var j = 0; j < 16; j += 1) {\n            used.push(false);\n          }\n          continue; // eslint-disable-line no-continue\n        }\n        var usedChars = _read(16);\n        for (var _j = 1 << 15; _j > 0; _j >>= 1) {\n          used.push(!!(usedChars & _j));\n        }\n      }\n      var groups = _read(3);\n      if (groups < 2 || groups > 6) {\n        throw new Error('Invalid number of huffman groups');\n      }\n      var selectorsUsed = _read(15);\n      var selectors = [];\n      var mtf = Array.from({\n        length: groups\n      }, function (_, i) {\n        return i;\n      });\n      for (var _i6 = 0; _i6 < selectorsUsed; _i6 += 1) {\n        var c = 0;\n        while (_read(1)) {\n          c += 1;\n          if (c >= groups) {\n            throw new Error('MTF table out of range');\n          }\n        }\n        var v = mtf[c];\n        for (var _j2 = c; _j2 > 0; mtf[_j2] = mtf[--_j2]) {// eslint-disable-line no-plusplus\n          // nothing\n        }\n        selectors.push(v);\n        mtf[0] = v;\n      }\n      var symbolsInUse = used.reduce(function (a, b) {\n        return a + b;\n      }, 0) + 2;\n      var tables = [];\n      for (var _i7 = 0; _i7 < groups; _i7 += 1) {\n        var length = _read(5);\n        var lengths = [];\n        for (var _j3 = 0; _j3 < symbolsInUse; _j3 += 1) {\n          if (length < 0 || length > 20) {\n            throw new Error('Huffman group length outside range');\n          }\n          while (_read(1)) {\n            length -= _read(1) * 2 - 1;\n          }\n          lengths.push(length);\n        }\n        tables.push(createOrderedHuffmanTable(lengths));\n      }\n      var favourites = [];\n      for (var _i8 = 0; _i8 < used.length - 1; _i8 += 1) {\n        if (used[_i8]) {\n          favourites.push(_i8);\n        }\n      }\n      var decoded = 0;\n      var selectorPointer = 0;\n      var t = void 0;\n      var r = void 0;\n      var repeat = 0;\n      var repeatPower = 0;\n      var buffer = [];\n      while (true) {\n        decoded -= 1;\n        if (decoded <= 0) {\n          decoded = 50;\n          if (selectorPointer <= selectors.length) {\n            t = tables[selectors[selectorPointer]];\n            selectorPointer += 1;\n          }\n        }\n        for (var b in t.fastAccess) {\n          if (!Object.prototype.hasOwnProperty.call(t.fastAccess, b)) {\n            continue; // eslint-disable-line no-continue\n          }\n          if (bits < b) {\n            bitfield = (bitfield << 8) + bytes[index];\n            index += 1;\n            bits += 8;\n          }\n          r = t.fastAccess[b][bitfield >> bits - b];\n          if (r) {\n            bitfield &= masks[bits -= b];\n            r = r.code;\n            break;\n          }\n        }\n        if (r >= 0 && r <= 1) {\n          if (repeat === 0) {\n            repeatPower = 1;\n          }\n          repeat += repeatPower << r;\n          repeatPower <<= 1;\n          continue; // eslint-disable-line no-continue\n        } else {\n          var _v = favourites[0];\n          for (; repeat > 0; repeat -= 1) {\n            buffer.push(_v);\n          }\n        }\n        if (r === symbolsInUse - 1) {\n          break;\n        } else {\n          var _v2 = favourites[r - 1];\n          // eslint-disable-next-line no-plusplus\n          for (var _j4 = r - 1; _j4 > 0; favourites[_j4] = favourites[--_j4]) {\n            // nothing\n          }\n          favourites[0] = _v2;\n          buffer.push(_v2);\n        }\n      }\n      var nt = bwtReverse(buffer, pointer);\n      var i = 0;\n      while (i < nt.length) {\n        var _c = nt[i];\n        var count = 1;\n        if (i < nt.length - 4 && nt[i + 1] === _c && nt[i + 2] === _c && nt[i + 3] === _c) {\n          count = nt[i + 4] + 4;\n          i += 5;\n        } else {\n          i += 1;\n        }\n        if (outIndex + count >= out.length) {\n          var old = out;\n          out = new Uint8Array(old.length * 2);\n          out.set(old);\n        }\n        for (var _j5 = 0; _j5 < count; _j5 += 1) {\n          if (checkCRC) {\n            newCRC = newCRC << 8 ^ crc32Table[(newCRC >> 24 ^ _c) & 0xff];\n          }\n          out[outIndex] = _c;\n          outIndex += 1;\n        }\n      }\n      if (checkCRC) {\n        var calculatedCRC = newCRC ^ -1;\n        if (calculatedCRC !== crc) {\n          throw new Error(\"CRC mismatch: \".concat(calculatedCRC, \" !== \").concat(crc));\n        }\n        newCRC = -1;\n      }\n    } else if (blocktype === 0x177245385090) {\n      _read(bits & 0x07); // pad align\n      break;\n    } else {\n      throw new Error('Invalid bz2 blocktype');\n    }\n  }\n  return out.subarray(0, outIndex);\n}\n\n\n//# sourceURL=webpack://untar-example/./src/bz2.js?");

/***/ }),

/***/ "./src/helper.js":
/*!***********************!*\
  !*** ./src/helper.js ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_libarchive_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lib/libarchive.js */ \"./lib/libarchive.js\");\n/* harmony import */ var _lib_libarchive_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_lib_libarchive_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _lib_libarchive_wasm__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lib/libarchive.wasm */ \"./lib/libarchive.wasm\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return e; }; var t, e = {}, r = Object.prototype, n = r.hasOwnProperty, o = Object.defineProperty || function (t, e, r) { t[e] = r.value; }, i = \"function\" == typeof Symbol ? Symbol : {}, a = i.iterator || \"@@iterator\", c = i.asyncIterator || \"@@asyncIterator\", u = i.toStringTag || \"@@toStringTag\"; function define(t, e, r) { return Object.defineProperty(t, e, { value: r, enumerable: !0, configurable: !0, writable: !0 }), t[e]; } try { define({}, \"\"); } catch (t) { define = function define(t, e, r) { return t[e] = r; }; } function wrap(t, e, r, n) { var i = e && e.prototype instanceof Generator ? e : Generator, a = Object.create(i.prototype), c = new Context(n || []); return o(a, \"_invoke\", { value: makeInvokeMethod(t, r, c) }), a; } function tryCatch(t, e, r) { try { return { type: \"normal\", arg: t.call(e, r) }; } catch (t) { return { type: \"throw\", arg: t }; } } e.wrap = wrap; var h = \"suspendedStart\", l = \"suspendedYield\", f = \"executing\", s = \"completed\", y = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var p = {}; define(p, a, function () { return this; }); var d = Object.getPrototypeOf, v = d && d(d(values([]))); v && v !== r && n.call(v, a) && (p = v); var g = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(p); function defineIteratorMethods(t) { [\"next\", \"throw\", \"return\"].forEach(function (e) { define(t, e, function (t) { return this._invoke(e, t); }); }); } function AsyncIterator(t, e) { function invoke(r, o, i, a) { var c = tryCatch(t[r], t, o); if (\"throw\" !== c.type) { var u = c.arg, h = u.value; return h && \"object\" == _typeof(h) && n.call(h, \"__await\") ? e.resolve(h.__await).then(function (t) { invoke(\"next\", t, i, a); }, function (t) { invoke(\"throw\", t, i, a); }) : e.resolve(h).then(function (t) { u.value = t, i(u); }, function (t) { return invoke(\"throw\", t, i, a); }); } a(c.arg); } var r; o(this, \"_invoke\", { value: function value(t, n) { function callInvokeWithMethodAndArg() { return new e(function (e, r) { invoke(t, n, e, r); }); } return r = r ? r.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(e, r, n) { var o = h; return function (i, a) { if (o === f) throw Error(\"Generator is already running\"); if (o === s) { if (\"throw\" === i) throw a; return { value: t, done: !0 }; } for (n.method = i, n.arg = a;;) { var c = n.delegate; if (c) { var u = maybeInvokeDelegate(c, n); if (u) { if (u === y) continue; return u; } } if (\"next\" === n.method) n.sent = n._sent = n.arg;else if (\"throw\" === n.method) { if (o === h) throw o = s, n.arg; n.dispatchException(n.arg); } else \"return\" === n.method && n.abrupt(\"return\", n.arg); o = f; var p = tryCatch(e, r, n); if (\"normal\" === p.type) { if (o = n.done ? s : l, p.arg === y) continue; return { value: p.arg, done: n.done }; } \"throw\" === p.type && (o = s, n.method = \"throw\", n.arg = p.arg); } }; } function maybeInvokeDelegate(e, r) { var n = r.method, o = e.iterator[n]; if (o === t) return r.delegate = null, \"throw\" === n && e.iterator[\"return\"] && (r.method = \"return\", r.arg = t, maybeInvokeDelegate(e, r), \"throw\" === r.method) || \"return\" !== n && (r.method = \"throw\", r.arg = new TypeError(\"The iterator does not provide a '\" + n + \"' method\")), y; var i = tryCatch(o, e.iterator, r.arg); if (\"throw\" === i.type) return r.method = \"throw\", r.arg = i.arg, r.delegate = null, y; var a = i.arg; return a ? a.done ? (r[e.resultName] = a.value, r.next = e.nextLoc, \"return\" !== r.method && (r.method = \"next\", r.arg = t), r.delegate = null, y) : a : (r.method = \"throw\", r.arg = new TypeError(\"iterator result is not an object\"), r.delegate = null, y); } function pushTryEntry(t) { var e = { tryLoc: t[0] }; 1 in t && (e.catchLoc = t[1]), 2 in t && (e.finallyLoc = t[2], e.afterLoc = t[3]), this.tryEntries.push(e); } function resetTryEntry(t) { var e = t.completion || {}; e.type = \"normal\", delete e.arg, t.completion = e; } function Context(t) { this.tryEntries = [{ tryLoc: \"root\" }], t.forEach(pushTryEntry, this), this.reset(!0); } function values(e) { if (e || \"\" === e) { var r = e[a]; if (r) return r.call(e); if (\"function\" == typeof e.next) return e; if (!isNaN(e.length)) { var o = -1, i = function next() { for (; ++o < e.length;) if (n.call(e, o)) return next.value = e[o], next.done = !1, next; return next.value = t, next.done = !0, next; }; return i.next = i; } } throw new TypeError(_typeof(e) + \" is not iterable\"); } return GeneratorFunction.prototype = GeneratorFunctionPrototype, o(g, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), o(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, u, \"GeneratorFunction\"), e.isGeneratorFunction = function (t) { var e = \"function\" == typeof t && t.constructor; return !!e && (e === GeneratorFunction || \"GeneratorFunction\" === (e.displayName || e.name)); }, e.mark = function (t) { return Object.setPrototypeOf ? Object.setPrototypeOf(t, GeneratorFunctionPrototype) : (t.__proto__ = GeneratorFunctionPrototype, define(t, u, \"GeneratorFunction\")), t.prototype = Object.create(g), t; }, e.awrap = function (t) { return { __await: t }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, c, function () { return this; }), e.AsyncIterator = AsyncIterator, e.async = function (t, r, n, o, i) { void 0 === i && (i = Promise); var a = new AsyncIterator(wrap(t, r, n, o), i); return e.isGeneratorFunction(r) ? a : a.next().then(function (t) { return t.done ? t.value : a.next(); }); }, defineIteratorMethods(g), define(g, u, \"Generator\"), define(g, a, function () { return this; }), define(g, \"toString\", function () { return \"[object Generator]\"; }), e.keys = function (t) { var e = Object(t), r = []; for (var n in e) r.push(n); return r.reverse(), function next() { for (; r.length;) { var t = r.pop(); if (t in e) return next.value = t, next.done = !1, next; } return next.done = !0, next; }; }, e.values = values, Context.prototype = { constructor: Context, reset: function reset(e) { if (this.prev = 0, this.next = 0, this.sent = this._sent = t, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = t, this.tryEntries.forEach(resetTryEntry), !e) for (var r in this) \"t\" === r.charAt(0) && n.call(this, r) && !isNaN(+r.slice(1)) && (this[r] = t); }, stop: function stop() { this.done = !0; var t = this.tryEntries[0].completion; if (\"throw\" === t.type) throw t.arg; return this.rval; }, dispatchException: function dispatchException(e) { if (this.done) throw e; var r = this; function handle(n, o) { return a.type = \"throw\", a.arg = e, r.next = n, o && (r.method = \"next\", r.arg = t), !!o; } for (var o = this.tryEntries.length - 1; o >= 0; --o) { var i = this.tryEntries[o], a = i.completion; if (\"root\" === i.tryLoc) return handle(\"end\"); if (i.tryLoc <= this.prev) { var c = n.call(i, \"catchLoc\"), u = n.call(i, \"finallyLoc\"); if (c && u) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } else if (c) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); } else { if (!u) throw Error(\"try statement without catch or finally\"); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } } } }, abrupt: function abrupt(t, e) { for (var r = this.tryEntries.length - 1; r >= 0; --r) { var o = this.tryEntries[r]; if (o.tryLoc <= this.prev && n.call(o, \"finallyLoc\") && this.prev < o.finallyLoc) { var i = o; break; } } i && (\"break\" === t || \"continue\" === t) && i.tryLoc <= e && e <= i.finallyLoc && (i = null); var a = i ? i.completion : {}; return a.type = t, a.arg = e, i ? (this.method = \"next\", this.next = i.finallyLoc, y) : this.complete(a); }, complete: function complete(t, e) { if (\"throw\" === t.type) throw t.arg; return \"break\" === t.type || \"continue\" === t.type ? this.next = t.arg : \"return\" === t.type ? (this.rval = this.arg = t.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === t.type && e && (this.next = e), y; }, finish: function finish(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.finallyLoc === t) return this.complete(r.completion, r.afterLoc), resetTryEntry(r), y; } }, \"catch\": function _catch(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.tryLoc === t) { var n = r.completion; if (\"throw\" === n.type) { var o = n.arg; resetTryEntry(r); } return o; } } throw Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(e, r, n) { return this.delegate = { iterator: values(e), resultName: r, nextLoc: n }, \"next\" === this.method && (this.arg = t), y; } }, e; }\nfunction asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }\nfunction _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"next\", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"throw\", n); } _next(void 0); }); }; }\n\n\nvar initializeWasm = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n    var wasmModule;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          _context.prev = 0;\n          _context.next = 3;\n          return _lib_libarchive_js__WEBPACK_IMPORTED_MODULE_0___default()({\n            locateFile: function locateFile(path) {\n              if (path.endsWith('.wasm')) {\n                return _lib_libarchive_wasm__WEBPACK_IMPORTED_MODULE_1__;\n              }\n              return path;\n            }\n          });\n        case 3:\n          wasmModule = _context.sent;\n          console.log(\"WASM module initialized:\", wasmModule);\n\n          // Use the module, for example, wasmModule._archive_read_open_memory\n          return _context.abrupt(\"return\", wasmModule);\n        case 8:\n          _context.prev = 8;\n          _context.t0 = _context[\"catch\"](0);\n          console.error('Error initializing the WASM module:', _context.t0);\n        case 11:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee, null, [[0, 8]]);\n  }));\n  return function initializeWasm() {\n    return _ref.apply(this, arguments);\n  };\n}();\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (initializeWasm);\n/*return new Promise(async (resolve, reject) => {\n    try {\n        console.log('loadLibarchive!!!!')\n        const Module = await import('./libarchive.js');\n        console.log('Module loaded:', Module);\n        console.log('Module');\n        console.dir(Module);\n        const condaPackageUrl = \"http://localhost:8888/_r-mutex-1.0.0-mro_2.conda\";\n        console.log('???')\n        // Fetch the .conda file as a Uint8Array\n        const response = await fetch(condaPackageUrl);\n        const buffer = await response.arrayBuffer();\n        const data = new Uint8Array(buffer);\n         console.log('data');\n        console.dir(data);\n         Module.onRuntimeInitialized = ()=> {\n            console.log('onRuntimeInitialized inside');\n           \n            const archive = Module._archive_read_open_memory(data, data.length);\n            console.log('archive');\n            console.dir(archive);\n            if (archive === 0) {\n                console.error(\"Failed to open .conda file\");\n                return;\n            }\n             let entry;\n            const bufferSize = 1024 * 1024;\n            const dataBuffer = Module._malloc(bufferSize);\n             console.log('dataBuffer');\n            console.dir(dataBuffer);\n             while (Module._archive_read_next_header(archive) === 0) {\n                const entryPathPtr = Module._archive_entry_pathname(archive);\n                console.log('entryPathPtr');\n                console.dir(entryPathPtr);\n                const entryName = Module.UTF8ToString(entryPathPtr);\n                console.log('entryPathPtr');\n                console.dir(entryPathPtr);\n                console.log(\"Extracting:\", entryName);\n                 let size = Module._archive_entry_size(archive);\n                let bytesRead = 0;\n                console.log('size');\n                console.dir(size);\n                Module.FS.createDataFile('/test/', entryName, null, true, false);\n                 while (size > 0) {\n                    console.log('size>0');\n                    console.dir(size);\n                    let chunkSize = Math.min(size, bufferSize);\n                    console.log('chunkSize');\n                    console.dir(chunkSize);\n                    bytesRead = Module._archive_read_data(archive, dataBuffer, chunkSize);\n                    console.log('bytesRead');\n                    console.dir(bytesRead);\n                    if (bytesRead < 0) {\n                        console.error(\"Error reading data for entry:\", entryName);\n                        break;\n                    }\n                      let extractedData = new Uint8Array(Module.HEAPU8.buffer, dataBuffer, bytesRead);\n                    console.log('extractedData');\n                    console.dir(extractedData);\n                     Module.FS.writeFile('/output/' + entryName, extractedData, { encoding: 'binary', flags: 'a' });\n                     size -= bytesRead;  // Decrease remaining size\n                }\n            }\n              Module._archive_read_free(archive);\n            Module._free(dataBuffer);\n             console.log(\"Extraction complete. Files saved in virtual file system.\");\n            resolve();\n        };\n    } catch (error) {\n        console.error('Error loading libarchive:', error);\n        reject(error);\n    }\n});\n*/\n\n//# sourceURL=webpack://untar-example/./src/helper.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fetchAndUntarBz2Package: () => (/* binding */ fetchAndUntarBz2Package)\n/* harmony export */ });\n/* harmony import */ var tar_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tar-stream */ \"./node_modules/tar-stream/index.js\");\n/* harmony import */ var _bz2__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./bz2 */ \"./src/bz2.js\");\n/* harmony import */ var _helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./helper */ \"./src/helper.js\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return e; }; var t, e = {}, r = Object.prototype, n = r.hasOwnProperty, o = Object.defineProperty || function (t, e, r) { t[e] = r.value; }, i = \"function\" == typeof Symbol ? Symbol : {}, a = i.iterator || \"@@iterator\", c = i.asyncIterator || \"@@asyncIterator\", u = i.toStringTag || \"@@toStringTag\"; function define(t, e, r) { return Object.defineProperty(t, e, { value: r, enumerable: !0, configurable: !0, writable: !0 }), t[e]; } try { define({}, \"\"); } catch (t) { define = function define(t, e, r) { return t[e] = r; }; } function wrap(t, e, r, n) { var i = e && e.prototype instanceof Generator ? e : Generator, a = Object.create(i.prototype), c = new Context(n || []); return o(a, \"_invoke\", { value: makeInvokeMethod(t, r, c) }), a; } function tryCatch(t, e, r) { try { return { type: \"normal\", arg: t.call(e, r) }; } catch (t) { return { type: \"throw\", arg: t }; } } e.wrap = wrap; var h = \"suspendedStart\", l = \"suspendedYield\", f = \"executing\", s = \"completed\", y = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var p = {}; define(p, a, function () { return this; }); var d = Object.getPrototypeOf, v = d && d(d(values([]))); v && v !== r && n.call(v, a) && (p = v); var g = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(p); function defineIteratorMethods(t) { [\"next\", \"throw\", \"return\"].forEach(function (e) { define(t, e, function (t) { return this._invoke(e, t); }); }); } function AsyncIterator(t, e) { function invoke(r, o, i, a) { var c = tryCatch(t[r], t, o); if (\"throw\" !== c.type) { var u = c.arg, h = u.value; return h && \"object\" == _typeof(h) && n.call(h, \"__await\") ? e.resolve(h.__await).then(function (t) { invoke(\"next\", t, i, a); }, function (t) { invoke(\"throw\", t, i, a); }) : e.resolve(h).then(function (t) { u.value = t, i(u); }, function (t) { return invoke(\"throw\", t, i, a); }); } a(c.arg); } var r; o(this, \"_invoke\", { value: function value(t, n) { function callInvokeWithMethodAndArg() { return new e(function (e, r) { invoke(t, n, e, r); }); } return r = r ? r.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(e, r, n) { var o = h; return function (i, a) { if (o === f) throw Error(\"Generator is already running\"); if (o === s) { if (\"throw\" === i) throw a; return { value: t, done: !0 }; } for (n.method = i, n.arg = a;;) { var c = n.delegate; if (c) { var u = maybeInvokeDelegate(c, n); if (u) { if (u === y) continue; return u; } } if (\"next\" === n.method) n.sent = n._sent = n.arg;else if (\"throw\" === n.method) { if (o === h) throw o = s, n.arg; n.dispatchException(n.arg); } else \"return\" === n.method && n.abrupt(\"return\", n.arg); o = f; var p = tryCatch(e, r, n); if (\"normal\" === p.type) { if (o = n.done ? s : l, p.arg === y) continue; return { value: p.arg, done: n.done }; } \"throw\" === p.type && (o = s, n.method = \"throw\", n.arg = p.arg); } }; } function maybeInvokeDelegate(e, r) { var n = r.method, o = e.iterator[n]; if (o === t) return r.delegate = null, \"throw\" === n && e.iterator[\"return\"] && (r.method = \"return\", r.arg = t, maybeInvokeDelegate(e, r), \"throw\" === r.method) || \"return\" !== n && (r.method = \"throw\", r.arg = new TypeError(\"The iterator does not provide a '\" + n + \"' method\")), y; var i = tryCatch(o, e.iterator, r.arg); if (\"throw\" === i.type) return r.method = \"throw\", r.arg = i.arg, r.delegate = null, y; var a = i.arg; return a ? a.done ? (r[e.resultName] = a.value, r.next = e.nextLoc, \"return\" !== r.method && (r.method = \"next\", r.arg = t), r.delegate = null, y) : a : (r.method = \"throw\", r.arg = new TypeError(\"iterator result is not an object\"), r.delegate = null, y); } function pushTryEntry(t) { var e = { tryLoc: t[0] }; 1 in t && (e.catchLoc = t[1]), 2 in t && (e.finallyLoc = t[2], e.afterLoc = t[3]), this.tryEntries.push(e); } function resetTryEntry(t) { var e = t.completion || {}; e.type = \"normal\", delete e.arg, t.completion = e; } function Context(t) { this.tryEntries = [{ tryLoc: \"root\" }], t.forEach(pushTryEntry, this), this.reset(!0); } function values(e) { if (e || \"\" === e) { var r = e[a]; if (r) return r.call(e); if (\"function\" == typeof e.next) return e; if (!isNaN(e.length)) { var o = -1, i = function next() { for (; ++o < e.length;) if (n.call(e, o)) return next.value = e[o], next.done = !1, next; return next.value = t, next.done = !0, next; }; return i.next = i; } } throw new TypeError(_typeof(e) + \" is not iterable\"); } return GeneratorFunction.prototype = GeneratorFunctionPrototype, o(g, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), o(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, u, \"GeneratorFunction\"), e.isGeneratorFunction = function (t) { var e = \"function\" == typeof t && t.constructor; return !!e && (e === GeneratorFunction || \"GeneratorFunction\" === (e.displayName || e.name)); }, e.mark = function (t) { return Object.setPrototypeOf ? Object.setPrototypeOf(t, GeneratorFunctionPrototype) : (t.__proto__ = GeneratorFunctionPrototype, define(t, u, \"GeneratorFunction\")), t.prototype = Object.create(g), t; }, e.awrap = function (t) { return { __await: t }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, c, function () { return this; }), e.AsyncIterator = AsyncIterator, e.async = function (t, r, n, o, i) { void 0 === i && (i = Promise); var a = new AsyncIterator(wrap(t, r, n, o), i); return e.isGeneratorFunction(r) ? a : a.next().then(function (t) { return t.done ? t.value : a.next(); }); }, defineIteratorMethods(g), define(g, u, \"Generator\"), define(g, a, function () { return this; }), define(g, \"toString\", function () { return \"[object Generator]\"; }), e.keys = function (t) { var e = Object(t), r = []; for (var n in e) r.push(n); return r.reverse(), function next() { for (; r.length;) { var t = r.pop(); if (t in e) return next.value = t, next.done = !1, next; } return next.done = !0, next; }; }, e.values = values, Context.prototype = { constructor: Context, reset: function reset(e) { if (this.prev = 0, this.next = 0, this.sent = this._sent = t, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = t, this.tryEntries.forEach(resetTryEntry), !e) for (var r in this) \"t\" === r.charAt(0) && n.call(this, r) && !isNaN(+r.slice(1)) && (this[r] = t); }, stop: function stop() { this.done = !0; var t = this.tryEntries[0].completion; if (\"throw\" === t.type) throw t.arg; return this.rval; }, dispatchException: function dispatchException(e) { if (this.done) throw e; var r = this; function handle(n, o) { return a.type = \"throw\", a.arg = e, r.next = n, o && (r.method = \"next\", r.arg = t), !!o; } for (var o = this.tryEntries.length - 1; o >= 0; --o) { var i = this.tryEntries[o], a = i.completion; if (\"root\" === i.tryLoc) return handle(\"end\"); if (i.tryLoc <= this.prev) { var c = n.call(i, \"catchLoc\"), u = n.call(i, \"finallyLoc\"); if (c && u) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } else if (c) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); } else { if (!u) throw Error(\"try statement without catch or finally\"); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } } } }, abrupt: function abrupt(t, e) { for (var r = this.tryEntries.length - 1; r >= 0; --r) { var o = this.tryEntries[r]; if (o.tryLoc <= this.prev && n.call(o, \"finallyLoc\") && this.prev < o.finallyLoc) { var i = o; break; } } i && (\"break\" === t || \"continue\" === t) && i.tryLoc <= e && e <= i.finallyLoc && (i = null); var a = i ? i.completion : {}; return a.type = t, a.arg = e, i ? (this.method = \"next\", this.next = i.finallyLoc, y) : this.complete(a); }, complete: function complete(t, e) { if (\"throw\" === t.type) throw t.arg; return \"break\" === t.type || \"continue\" === t.type ? this.next = t.arg : \"return\" === t.type ? (this.rval = this.arg = t.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === t.type && e && (this.next = e), y; }, finish: function finish(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.finallyLoc === t) return this.complete(r.completion, r.afterLoc), resetTryEntry(r), y; } }, \"catch\": function _catch(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.tryLoc === t) { var n = r.completion; if (\"throw\" === n.type) { var o = n.arg; resetTryEntry(r); } return o; } } throw Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(e, r, n) { return this.delegate = { iterator: values(e), resultName: r, nextLoc: n }, \"next\" === this.method && (this.arg = t), y; } }, e; }\nfunction asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }\nfunction _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"next\", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"throw\", n); } _next(void 0); }); }; }\n\n\n\n\n//const condaPackageUrl = 'https://conda.anaconda.org/conda-forge/linux-64/_libgcc_mutex-0.1-conda_forge.tar.bz2';\nvar condaPackageUrl = \"http://localhost:8888/_r-mutex-1.0.0-mro_2.conda\";\nfunction decompressBzip2(data) {\n  return (0,_bz2__WEBPACK_IMPORTED_MODULE_1__.decompress)(data);\n}\nfunction fetchByteArray(_x) {\n  return _fetchByteArray.apply(this, arguments);\n}\nfunction _fetchByteArray() {\n  _fetchByteArray = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee2(url) {\n    var response, arrayBuffer, byte_array;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          _context2.next = 2;\n          return fetch(url);\n        case 2:\n          response = _context2.sent;\n          if (response.ok) {\n            _context2.next = 5;\n            break;\n          }\n          throw new Error(\"HTTP error! status: \".concat(response.status));\n        case 5:\n          _context2.next = 7;\n          return response.arrayBuffer();\n        case 7:\n          arrayBuffer = _context2.sent;\n          byte_array = new Uint8Array(arrayBuffer);\n          return _context2.abrupt(\"return\", byte_array);\n        case 10:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee2);\n  }));\n  return _fetchByteArray.apply(this, arguments);\n}\nfunction fetchAndUntarBz2Package(_x2) {\n  return _fetchAndUntarBz2Package.apply(this, arguments);\n}\nfunction _fetchAndUntarBz2Package() {\n  _fetchAndUntarBz2Package = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee3(url) {\n    var compressedData, decompressedData, extract, files;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          _context3.prev = 0;\n          console.log('>??');\n          _context3.next = 4;\n          return fetchByteArray(url);\n        case 4:\n          compressedData = _context3.sent;\n          console.log(compressedData);\n          decompressedData = decompressBzip2(compressedData);\n          extract = tar_stream__WEBPACK_IMPORTED_MODULE_0__.extract();\n          files = {};\n          extract.on('entry', function (header, stream, next) {\n            var fileName = header.name;\n            var fileContent = '';\n            console.log('fileName');\n            console.log(fileName);\n            stream.on('data', function (chunk) {\n              fileContent += new TextDecoder().decode(chunk);\n            });\n            stream.on('end', function () {\n              files[fileName] = fileContent;\n              next();\n            });\n            stream.on('error', function (err) {\n              console.error(\"Error reading stream for \".concat(fileName, \":\"), err);\n              next(err);\n            });\n          });\n          extract.on('finish', function () {\n            console.log('All files extracted:', files);\n          });\n          extract.write(decompressedData);\n          extract.end();\n          return _context3.abrupt(\"return\", files);\n        case 16:\n          _context3.prev = 16;\n          _context3.t0 = _context3[\"catch\"](0);\n          console.error('Error fetching or untarring the package:', _context3.t0);\n          throw _context3.t0;\n        case 20:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3, null, [[0, 16]]);\n  }));\n  return _fetchAndUntarBz2Package.apply(this, arguments);\n}\nvar getCondaData = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n    var condaPackageUrl, response, buffer, data;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          condaPackageUrl = \"http://localhost:8888/_r-mutex-1.0.0-mro_2.conda\";\n          console.log('???');\n          // Fetch the .conda file as a Uint8Array\n          _context.next = 4;\n          return fetch(condaPackageUrl);\n        case 4:\n          response = _context.sent;\n          _context.next = 7;\n          return response.arrayBuffer();\n        case 7:\n          buffer = _context.sent;\n          data = new Uint8Array(buffer);\n          console.log('data');\n          console.dir(data);\n          return _context.abrupt(\"return\", data);\n        case 12:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee);\n  }));\n  return function getCondaData() {\n    return _ref.apply(this, arguments);\n  };\n}();\n\n/*fetchAndUntarBz2Package(condaPackageUrl)\n    .then((files) => {\n        console.log('Successfully fetched and extracted the BZIP2 tar package!', files);\n    })\n    .catch((err) => {\n        console.error('Failed to fetch and extract BZIP2 tar package:', err);\n    });\ntry{\n    const wasmModule = await initializeWasm();\n    console.dir(wasmModule);\n  if (wasmModule) {\n        let data = await getCondaData();\n        const archivePtr = wasmModule._malloc(data.length);\n        wasmModule.HEAPU8.set(data, archivePtr);\n\n        console.log('data', data);\n\n        const archive = wasmModule._archive_read_open_memory(archivePtr, data.length, 0);\n        console.log('archive');\n        console.dir(archive);\n  }\n       if (archive === 0) {\n            console.error(\"Failed to open .conda file\");\n        }\n\n        let entry;\n      //  const bufferSize = 1024 * 1024;\n        const dataBuffer = wasmModule._malloc(bufferSize);\n\n        console.log('dataBuffer');\n        console.dir(dataBuffer);\n\n\n                while (wasmModule._archive_read_next_header(archive) === 0) {\n                    const entryPathPtr = wasmModule._archive_entry_pathname(archive);\n                    console.log('entryPathPtr');\n                    console.dir(entryPathPtr);\n                    const entryName = wasmModule.UTF8ToString(entryPathPtr);\n                    console.log('entryPathPtr');\n                    console.dir(entryPathPtr);\n                    console.log(\"Extracting:\", entryName);\n\n                    let size = wasmModule._archive_entry_size(archive);\n                    let bytesRead = 0;\n                    console.log('size');\n                    console.dir(size);\n                    wasmModule.FS.createDataFile('/test/', entryName, null, true, false);\n\n                    while (size > 0) {\n                        console.log('size>0');\n                        console.dir(size);\n                        let chunkSize = Math.min(size, bufferSize);\n                        console.log('chunkSize');\n                        console.dir(chunkSize);\n                        bytesRead = wasmModule._archive_read_data(archive, dataBuffer, chunkSize);\n                        console.log('bytesRead');\n                        console.dir(bytesRead);\n                        if (bytesRead < 0) {\n                            console.error(\"Error reading data for entry:\", entryName);\n                            break;\n                        }\n\n\n                        let extractedData = new Uint8Array(wasmModule.HEAPU8.buffer, dataBuffer, bytesRead);\n                        console.log('extractedData');\n                        console.dir(extractedData);\n\n                        wasmModule.FS.writeFile('/output/' + entryName, extractedData, { encoding: 'binary', flags: 'a' });\n\n                        size -= bytesRead;  // Decrease remaining size\n                    }\n                }\n                wasmModule._archive_read_free(archive);\n                wasmModule._free(dataBuffer);\n\n                console.log(\"Extraction complete. Files saved in virtual file system.\");\n                resolve();\n            };\n            \n}catch(error) {\n    console.dir(error);\n}\n*/\nfunction unpackCondaFile() {\n  return _unpackCondaFile.apply(this, arguments);\n} // Call the function to unpack the .conda file\nfunction _unpackCondaFile() {\n  _unpackCondaFile = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee4() {\n    var wasmModule, data, archivePtr, newArchive, archiveHandle, header, size, pathname, buffer, bytesRead;\n    return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n      while (1) switch (_context4.prev = _context4.next) {\n        case 0:\n          _context4.prev = 0;\n          _context4.next = 3;\n          return (0,_helper__WEBPACK_IMPORTED_MODULE_2__[\"default\"])();\n        case 3:\n          wasmModule = _context4.sent;\n          console.dir(wasmModule);\n          if (!wasmModule) {\n            _context4.next = 27;\n            break;\n          }\n          _context4.next = 8;\n          return getCondaData();\n        case 8:\n          data = _context4.sent;\n          console.log('Data downloaded:', data);\n\n          // Allocate memory for the data in the WASM module\n          archivePtr = wasmModule._malloc(data.length);\n          console.log('archivePtr');\n          console.dir(archivePtr);\n          wasmModule.HEAPU8.set(data, archivePtr);\n          newArchive = wasmModule._archive_read_new(); // Create archive pointer\n          if (!(newArchive === 0)) {\n            _context4.next = 19;\n            break;\n          }\n          console.error('Failed to create archive object');\n          wasmModule._free(archivePtr);\n          return _context4.abrupt(\"return\");\n        case 19:\n          // Open the archive\n          archiveHandle = wasmModule._archive_read_open_memory(newArchive, archivePtr, data.length);\n          console.log('Archive handle:', archiveHandle);\n\n          // Check if archive opened successfully\n          if (!(archiveHandle === 0)) {\n            _context4.next = 24;\n            break;\n          }\n          console.error('Failed to open archive');\n          return _context4.abrupt(\"return\");\n        case 24:\n          while ((header = wasmModule._archive_read_next_header(archiveHandle)) !== 0) {\n            size = wasmModule._archive_entry_size(header);\n            pathname = wasmModule._archive_entry_pathname(header);\n            buffer = new Uint8Array(size);\n            bytesRead = wasmModule._archive_read_data(archiveHandle, buffer.byteOffset, size);\n            if (bytesRead > 0) {\n              console.log(\"Extracted: \".concat(pathname, \", Size: \").concat(bytesRead));\n            }\n          }\n\n          // Close the archive\n          wasmModule._archive_read_close(archiveHandle);\n          wasmModule._free(archivePtr);\n        case 27:\n          _context4.next = 32;\n          break;\n        case 29:\n          _context4.prev = 29;\n          _context4.t0 = _context4[\"catch\"](0);\n          console.error('Error during unpacking:', _context4.t0);\n        case 32:\n        case \"end\":\n          return _context4.stop();\n      }\n    }, _callee4, null, [[0, 29]]);\n  }));\n  return _unpackCondaFile.apply(this, arguments);\n}\nunpackCondaFile();\n\n//# sourceURL=webpack://untar-example/./src/index.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/fast-fifo/fixed-size.js":
/*!**********************************************!*\
  !*** ./node_modules/fast-fifo/fixed-size.js ***!
  \**********************************************/
/***/ ((module) => {

eval("module.exports = class FixedFIFO {\n  constructor (hwm) {\n    if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) throw new Error('Max size for a FixedFIFO should be a power of two')\n    this.buffer = new Array(hwm)\n    this.mask = hwm - 1\n    this.top = 0\n    this.btm = 0\n    this.next = null\n  }\n\n  clear () {\n    this.top = this.btm = 0\n    this.next = null\n    this.buffer.fill(undefined)\n  }\n\n  push (data) {\n    if (this.buffer[this.top] !== undefined) return false\n    this.buffer[this.top] = data\n    this.top = (this.top + 1) & this.mask\n    return true\n  }\n\n  shift () {\n    const last = this.buffer[this.btm]\n    if (last === undefined) return undefined\n    this.buffer[this.btm] = undefined\n    this.btm = (this.btm + 1) & this.mask\n    return last\n  }\n\n  peek () {\n    return this.buffer[this.btm]\n  }\n\n  isEmpty () {\n    return this.buffer[this.btm] === undefined\n  }\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/fast-fifo/fixed-size.js?");

/***/ }),

/***/ "./node_modules/fast-fifo/index.js":
/*!*****************************************!*\
  !*** ./node_modules/fast-fifo/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const FixedFIFO = __webpack_require__(/*! ./fixed-size */ \"./node_modules/fast-fifo/fixed-size.js\")\n\nmodule.exports = class FastFIFO {\n  constructor (hwm) {\n    this.hwm = hwm || 16\n    this.head = new FixedFIFO(this.hwm)\n    this.tail = this.head\n    this.length = 0\n  }\n\n  clear () {\n    this.head = this.tail\n    this.head.clear()\n    this.length = 0\n  }\n\n  push (val) {\n    this.length++\n    if (!this.head.push(val)) {\n      const prev = this.head\n      this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length)\n      this.head.push(val)\n    }\n  }\n\n  shift () {\n    if (this.length !== 0) this.length--\n    const val = this.tail.shift()\n    if (val === undefined && this.tail.next) {\n      const next = this.tail.next\n      this.tail.next = null\n      this.tail = next\n      return this.tail.shift()\n    }\n\n    return val\n  }\n\n  peek () {\n    const val = this.tail.peek()\n    if (val === undefined && this.tail.next) return this.tail.next.peek()\n    return val\n  }\n\n  isEmpty () {\n    return this.length === 0\n  }\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/fast-fifo/index.js?");

/***/ }),

/***/ "./node_modules/queue-tick/queue-microtask.js":
/*!****************************************************!*\
  !*** ./node_modules/queue-tick/queue-microtask.js ***!
  \****************************************************/
/***/ ((module) => {

eval("module.exports = typeof queueMicrotask === 'function' ? queueMicrotask : (fn) => Promise.resolve().then(fn)\n\n\n//# sourceURL=webpack://untar-example/./node_modules/queue-tick/queue-microtask.js?");

/***/ }),

/***/ "./node_modules/streamx/index.js":
/*!***************************************!*\
  !*** ./node_modules/streamx/index.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { EventEmitter } = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst STREAM_DESTROYED = new Error('Stream was destroyed')\nconst PREMATURE_CLOSE = new Error('Premature close')\n\nconst queueTick = __webpack_require__(/*! queue-tick */ \"./node_modules/queue-tick/queue-microtask.js\")\nconst FIFO = __webpack_require__(/*! fast-fifo */ \"./node_modules/fast-fifo/index.js\")\nconst TextDecoder = __webpack_require__(/*! text-decoder */ \"./node_modules/text-decoder/index.js\")\n\n/* eslint-disable no-multi-spaces */\n\n// 29 bits used total (4 from shared, 14 from read, and 11 from write)\nconst MAX = ((1 << 29) - 1)\n\n// Shared state\nconst OPENING       = 0b0001\nconst PREDESTROYING = 0b0010\nconst DESTROYING    = 0b0100\nconst DESTROYED     = 0b1000\n\nconst NOT_OPENING = MAX ^ OPENING\nconst NOT_PREDESTROYING = MAX ^ PREDESTROYING\n\n// Read state (4 bit offset from shared state)\nconst READ_ACTIVE           = 0b00000000000001 << 4\nconst READ_UPDATING         = 0b00000000000010 << 4\nconst READ_PRIMARY          = 0b00000000000100 << 4\nconst READ_QUEUED           = 0b00000000001000 << 4\nconst READ_RESUMED          = 0b00000000010000 << 4\nconst READ_PIPE_DRAINED     = 0b00000000100000 << 4\nconst READ_ENDING           = 0b00000001000000 << 4\nconst READ_EMIT_DATA        = 0b00000010000000 << 4\nconst READ_EMIT_READABLE    = 0b00000100000000 << 4\nconst READ_EMITTED_READABLE = 0b00001000000000 << 4\nconst READ_DONE             = 0b00010000000000 << 4\nconst READ_NEXT_TICK        = 0b00100000000000 << 4\nconst READ_NEEDS_PUSH       = 0b01000000000000 << 4\nconst READ_READ_AHEAD       = 0b10000000000000 << 4\n\n// Combined read state\nconst READ_FLOWING = READ_RESUMED | READ_PIPE_DRAINED\nconst READ_ACTIVE_AND_NEEDS_PUSH = READ_ACTIVE | READ_NEEDS_PUSH\nconst READ_PRIMARY_AND_ACTIVE = READ_PRIMARY | READ_ACTIVE\nconst READ_EMIT_READABLE_AND_QUEUED = READ_EMIT_READABLE | READ_QUEUED\nconst READ_RESUMED_READ_AHEAD = READ_RESUMED | READ_READ_AHEAD\n\nconst READ_NOT_ACTIVE             = MAX ^ READ_ACTIVE\nconst READ_NON_PRIMARY            = MAX ^ READ_PRIMARY\nconst READ_NON_PRIMARY_AND_PUSHED = MAX ^ (READ_PRIMARY | READ_NEEDS_PUSH)\nconst READ_PUSHED                 = MAX ^ READ_NEEDS_PUSH\nconst READ_PAUSED                 = MAX ^ READ_RESUMED\nconst READ_NOT_QUEUED             = MAX ^ (READ_QUEUED | READ_EMITTED_READABLE)\nconst READ_NOT_ENDING             = MAX ^ READ_ENDING\nconst READ_PIPE_NOT_DRAINED       = MAX ^ READ_FLOWING\nconst READ_NOT_NEXT_TICK          = MAX ^ READ_NEXT_TICK\nconst READ_NOT_UPDATING           = MAX ^ READ_UPDATING\nconst READ_NO_READ_AHEAD          = MAX ^ READ_READ_AHEAD\nconst READ_PAUSED_NO_READ_AHEAD   = MAX ^ READ_RESUMED_READ_AHEAD\n\n// Write state (18 bit offset, 4 bit offset from shared state and 14 from read state)\nconst WRITE_ACTIVE     = 0b00000000001 << 18\nconst WRITE_UPDATING   = 0b00000000010 << 18\nconst WRITE_PRIMARY    = 0b00000000100 << 18\nconst WRITE_QUEUED     = 0b00000001000 << 18\nconst WRITE_UNDRAINED  = 0b00000010000 << 18\nconst WRITE_DONE       = 0b00000100000 << 18\nconst WRITE_EMIT_DRAIN = 0b00001000000 << 18\nconst WRITE_NEXT_TICK  = 0b00010000000 << 18\nconst WRITE_WRITING    = 0b00100000000 << 18\nconst WRITE_FINISHING  = 0b01000000000 << 18\nconst WRITE_CORKED     = 0b10000000000 << 18\n\nconst WRITE_NOT_ACTIVE    = MAX ^ (WRITE_ACTIVE | WRITE_WRITING)\nconst WRITE_NON_PRIMARY   = MAX ^ WRITE_PRIMARY\nconst WRITE_NOT_FINISHING = MAX ^ WRITE_FINISHING\nconst WRITE_DRAINED       = MAX ^ WRITE_UNDRAINED\nconst WRITE_NOT_QUEUED    = MAX ^ WRITE_QUEUED\nconst WRITE_NOT_NEXT_TICK = MAX ^ WRITE_NEXT_TICK\nconst WRITE_NOT_UPDATING  = MAX ^ WRITE_UPDATING\nconst WRITE_NOT_CORKED    = MAX ^ WRITE_CORKED\n\n// Combined shared state\nconst ACTIVE = READ_ACTIVE | WRITE_ACTIVE\nconst NOT_ACTIVE = MAX ^ ACTIVE\nconst DONE = READ_DONE | WRITE_DONE\nconst DESTROY_STATUS = DESTROYING | DESTROYED | PREDESTROYING\nconst OPEN_STATUS = DESTROY_STATUS | OPENING\nconst AUTO_DESTROY = DESTROY_STATUS | DONE\nconst NON_PRIMARY = WRITE_NON_PRIMARY & READ_NON_PRIMARY\nconst ACTIVE_OR_TICKING = WRITE_NEXT_TICK | READ_NEXT_TICK\nconst TICKING = ACTIVE_OR_TICKING & NOT_ACTIVE\nconst IS_OPENING = OPEN_STATUS | TICKING\n\n// Combined shared state and read state\nconst READ_PRIMARY_STATUS = OPEN_STATUS | READ_ENDING | READ_DONE\nconst READ_STATUS = OPEN_STATUS | READ_DONE | READ_QUEUED\nconst READ_ENDING_STATUS = OPEN_STATUS | READ_ENDING | READ_QUEUED\nconst READ_READABLE_STATUS = OPEN_STATUS | READ_EMIT_READABLE | READ_QUEUED | READ_EMITTED_READABLE\nconst SHOULD_NOT_READ = OPEN_STATUS | READ_ACTIVE | READ_ENDING | READ_DONE | READ_NEEDS_PUSH | READ_READ_AHEAD\nconst READ_BACKPRESSURE_STATUS = DESTROY_STATUS | READ_ENDING | READ_DONE\nconst READ_UPDATE_SYNC_STATUS = READ_UPDATING | OPEN_STATUS | READ_NEXT_TICK | READ_PRIMARY\n\n// Combined write state\nconst WRITE_PRIMARY_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_QUEUED_AND_UNDRAINED = WRITE_QUEUED | WRITE_UNDRAINED\nconst WRITE_QUEUED_AND_ACTIVE = WRITE_QUEUED | WRITE_ACTIVE\nconst WRITE_DRAIN_STATUS = WRITE_QUEUED | WRITE_UNDRAINED | OPEN_STATUS | WRITE_ACTIVE\nconst WRITE_STATUS = OPEN_STATUS | WRITE_ACTIVE | WRITE_QUEUED | WRITE_CORKED\nconst WRITE_PRIMARY_AND_ACTIVE = WRITE_PRIMARY | WRITE_ACTIVE\nconst WRITE_ACTIVE_AND_WRITING = WRITE_ACTIVE | WRITE_WRITING\nconst WRITE_FINISHING_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_QUEUED_AND_ACTIVE | WRITE_DONE\nconst WRITE_BACKPRESSURE_STATUS = WRITE_UNDRAINED | DESTROY_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_UPDATE_SYNC_STATUS = WRITE_UPDATING | OPEN_STATUS | WRITE_NEXT_TICK | WRITE_PRIMARY\n\nconst asyncIterator = Symbol.asyncIterator || Symbol('asyncIterator')\n\nclass WritableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapWritable, byteLength, byteLengthWritable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark\n    this.buffered = 0\n    this.error = null\n    this.pipeline = null\n    this.drains = null // if we add more seldomly used helpers we might them into a subobject so its a single ptr\n    this.byteLength = byteLengthWritable || byteLength || defaultByteLength\n    this.map = mapWritable || map\n    this.afterWrite = afterWrite.bind(this)\n    this.afterUpdateNextTick = updateWriteNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & WRITE_DONE) !== 0\n  }\n\n  push (data) {\n    if (this.map !== null) data = this.map(data)\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    if (this.buffered < this.highWaterMark) {\n      this.stream._duplexState |= WRITE_QUEUED\n      return true\n    }\n\n    this.stream._duplexState |= WRITE_QUEUED_AND_UNDRAINED\n    return false\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= WRITE_NOT_QUEUED\n\n    return data\n  }\n\n  end (data) {\n    if (typeof data === 'function') this.stream.once('finish', data)\n    else if (data !== undefined && data !== null) this.push(data)\n    this.stream._duplexState = (this.stream._duplexState | WRITE_FINISHING) & WRITE_NON_PRIMARY\n  }\n\n  autoBatch (data, cb) {\n    const buffer = []\n    const stream = this.stream\n\n    buffer.push(data)\n    while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED_AND_ACTIVE) {\n      buffer.push(stream._writableState.shift())\n    }\n\n    if ((stream._duplexState & OPEN_STATUS) !== 0) return cb(null)\n    stream._writev(buffer, cb)\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= WRITE_UPDATING\n\n    do {\n      while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED) {\n        const data = this.shift()\n        stream._duplexState |= WRITE_ACTIVE_AND_WRITING\n        stream._write(data, this.afterWrite)\n      }\n\n      if ((stream._duplexState & WRITE_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= WRITE_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & WRITE_FINISHING_STATUS) === WRITE_FINISHING) {\n      stream._duplexState = (stream._duplexState | WRITE_ACTIVE) & WRITE_NOT_FINISHING\n      stream._final(afterFinal.bind(this))\n      return\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & WRITE_UPDATE_SYNC_STATUS) === WRITE_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= WRITE_NEXT_TICK\n    if ((this.stream._duplexState & WRITE_UPDATING) === 0) queueTick(this.afterUpdateNextTick)\n  }\n}\n\nclass ReadableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapReadable, byteLength, byteLengthReadable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark === 0 ? 1 : highWaterMark\n    this.buffered = 0\n    this.readAhead = highWaterMark > 0\n    this.error = null\n    this.pipeline = null\n    this.byteLength = byteLengthReadable || byteLength || defaultByteLength\n    this.map = mapReadable || map\n    this.pipeTo = null\n    this.afterRead = afterRead.bind(this)\n    this.afterUpdateNextTick = updateReadNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & READ_DONE) !== 0\n  }\n\n  pipe (pipeTo, cb) {\n    if (this.pipeTo !== null) throw new Error('Can only pipe to one destination')\n    if (typeof cb !== 'function') cb = null\n\n    this.stream._duplexState |= READ_PIPE_DRAINED\n    this.pipeTo = pipeTo\n    this.pipeline = new Pipeline(this.stream, pipeTo, cb)\n\n    if (cb) this.stream.on('error', noop) // We already error handle this so supress crashes\n\n    if (isStreamx(pipeTo)) {\n      pipeTo._writableState.pipeline = this.pipeline\n      if (cb) pipeTo.on('error', noop) // We already error handle this so supress crashes\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline)) // TODO: just call finished from pipeTo itself\n    } else {\n      const onerror = this.pipeline.done.bind(this.pipeline, pipeTo)\n      const onclose = this.pipeline.done.bind(this.pipeline, pipeTo, null) // onclose has a weird bool arg\n      pipeTo.on('error', onerror)\n      pipeTo.on('close', onclose)\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline))\n    }\n\n    pipeTo.on('drain', afterDrain.bind(this))\n    this.stream.emit('piping', pipeTo)\n    pipeTo.emit('pipe', this.stream)\n  }\n\n  push (data) {\n    const stream = this.stream\n\n    if (data === null) {\n      this.highWaterMark = 0\n      stream._duplexState = (stream._duplexState | READ_ENDING) & READ_NON_PRIMARY_AND_PUSHED\n      return false\n    }\n\n    if (this.map !== null) {\n      data = this.map(data)\n      if (data === null) {\n        stream._duplexState &= READ_PUSHED\n        return this.buffered < this.highWaterMark\n      }\n    }\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    stream._duplexState = (stream._duplexState | READ_QUEUED) & READ_PUSHED\n\n    return this.buffered < this.highWaterMark\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= READ_NOT_QUEUED\n    return data\n  }\n\n  unshift (data) {\n    const pending = [this.map !== null ? this.map(data) : data]\n    while (this.buffered > 0) pending.push(this.shift())\n\n    for (let i = 0; i < pending.length - 1; i++) {\n      const data = pending[i]\n      this.buffered += this.byteLength(data)\n      this.queue.push(data)\n    }\n\n    this.push(pending[pending.length - 1])\n  }\n\n  read () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_STATUS) === READ_QUEUED) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n      return data\n    }\n\n    if (this.readAhead === false) {\n      stream._duplexState |= READ_READ_AHEAD\n      this.updateNextTick()\n    }\n\n    return null\n  }\n\n  drain () {\n    const stream = this.stream\n\n    while ((stream._duplexState & READ_STATUS) === READ_QUEUED && (stream._duplexState & READ_FLOWING) !== 0) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n    }\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= READ_UPDATING\n\n    do {\n      this.drain()\n\n      while (this.buffered < this.highWaterMark && (stream._duplexState & SHOULD_NOT_READ) === READ_READ_AHEAD) {\n        stream._duplexState |= READ_ACTIVE_AND_NEEDS_PUSH\n        stream._read(this.afterRead)\n        this.drain()\n      }\n\n      if ((stream._duplexState & READ_READABLE_STATUS) === READ_EMIT_READABLE_AND_QUEUED) {\n        stream._duplexState |= READ_EMITTED_READABLE\n        stream.emit('readable')\n      }\n\n      if ((stream._duplexState & READ_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= READ_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_ENDING_STATUS) === READ_ENDING) {\n      stream._duplexState = (stream._duplexState | READ_DONE) & READ_NOT_ENDING\n      stream.emit('end')\n      if ((stream._duplexState & AUTO_DESTROY) === DONE) stream._duplexState |= DESTROYING\n      if (this.pipeTo !== null) this.pipeTo.end()\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & READ_UPDATE_SYNC_STATUS) === READ_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= READ_NEXT_TICK\n    if ((this.stream._duplexState & READ_UPDATING) === 0) queueTick(this.afterUpdateNextTick)\n  }\n}\n\nclass TransformState {\n  constructor (stream) {\n    this.data = null\n    this.afterTransform = afterTransform.bind(stream)\n    this.afterFinal = null\n  }\n}\n\nclass Pipeline {\n  constructor (src, dst, cb) {\n    this.from = src\n    this.to = dst\n    this.afterPipe = cb\n    this.error = null\n    this.pipeToFinished = false\n  }\n\n  finished () {\n    this.pipeToFinished = true\n  }\n\n  done (stream, err) {\n    if (err) this.error = err\n\n    if (stream === this.to) {\n      this.to = null\n\n      if (this.from !== null) {\n        if ((this.from._duplexState & READ_DONE) === 0 || !this.pipeToFinished) {\n          this.from.destroy(this.error || new Error('Writable stream closed prematurely'))\n        }\n        return\n      }\n    }\n\n    if (stream === this.from) {\n      this.from = null\n\n      if (this.to !== null) {\n        if ((stream._duplexState & READ_DONE) === 0) {\n          this.to.destroy(this.error || new Error('Readable stream closed before ending'))\n        }\n        return\n      }\n    }\n\n    if (this.afterPipe !== null) this.afterPipe(this.error)\n    this.to = this.from = this.afterPipe = null\n  }\n}\n\nfunction afterDrain () {\n  this.stream._duplexState |= READ_PIPE_DRAINED\n  this.updateCallback()\n}\n\nfunction afterFinal (err) {\n  const stream = this.stream\n  if (err) stream.destroy(err)\n  if ((stream._duplexState & DESTROY_STATUS) === 0) {\n    stream._duplexState |= WRITE_DONE\n    stream.emit('finish')\n  }\n  if ((stream._duplexState & AUTO_DESTROY) === DONE) {\n    stream._duplexState |= DESTROYING\n  }\n\n  stream._duplexState &= WRITE_NOT_ACTIVE\n\n  // no need to wait the extra tick here, so we short circuit that\n  if ((stream._duplexState & WRITE_UPDATING) === 0) this.update()\n  else this.updateNextTick()\n}\n\nfunction afterDestroy (err) {\n  const stream = this.stream\n\n  if (!err && this.error !== STREAM_DESTROYED) err = this.error\n  if (err) stream.emit('error', err)\n  stream._duplexState |= DESTROYED\n  stream.emit('close')\n\n  const rs = stream._readableState\n  const ws = stream._writableState\n\n  if (rs !== null && rs.pipeline !== null) rs.pipeline.done(stream, err)\n\n  if (ws !== null) {\n    while (ws.drains !== null && ws.drains.length > 0) ws.drains.shift().resolve(false)\n    if (ws.pipeline !== null) ws.pipeline.done(stream, err)\n  }\n}\n\nfunction afterWrite (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n  stream._duplexState &= WRITE_NOT_ACTIVE\n\n  if (this.drains !== null) tickDrains(this.drains)\n\n  if ((stream._duplexState & WRITE_DRAIN_STATUS) === WRITE_UNDRAINED) {\n    stream._duplexState &= WRITE_DRAINED\n    if ((stream._duplexState & WRITE_EMIT_DRAIN) === WRITE_EMIT_DRAIN) {\n      stream.emit('drain')\n    }\n  }\n\n  this.updateCallback()\n}\n\nfunction afterRead (err) {\n  if (err) this.stream.destroy(err)\n  this.stream._duplexState &= READ_NOT_ACTIVE\n  if (this.readAhead === false && (this.stream._duplexState & READ_RESUMED) === 0) this.stream._duplexState &= READ_NO_READ_AHEAD\n  this.updateCallback()\n}\n\nfunction updateReadNT () {\n  if ((this.stream._duplexState & READ_UPDATING) === 0) {\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction updateWriteNT () {\n  if ((this.stream._duplexState & WRITE_UPDATING) === 0) {\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction tickDrains (drains) {\n  for (let i = 0; i < drains.length; i++) {\n    // drains.writes are monotonic, so if one is 0 its always the first one\n    if (--drains[i].writes === 0) {\n      drains.shift().resolve(true)\n      i--\n    }\n  }\n}\n\nfunction afterOpen (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n\n  if ((stream._duplexState & DESTROYING) === 0) {\n    if ((stream._duplexState & READ_PRIMARY_STATUS) === 0) stream._duplexState |= READ_PRIMARY\n    if ((stream._duplexState & WRITE_PRIMARY_STATUS) === 0) stream._duplexState |= WRITE_PRIMARY\n    stream.emit('open')\n  }\n\n  stream._duplexState &= NOT_ACTIVE\n\n  if (stream._writableState !== null) {\n    stream._writableState.updateCallback()\n  }\n\n  if (stream._readableState !== null) {\n    stream._readableState.updateCallback()\n  }\n}\n\nfunction afterTransform (err, data) {\n  if (data !== undefined && data !== null) this.push(data)\n  this._writableState.afterWrite(err)\n}\n\nfunction newListener (name) {\n  if (this._readableState !== null) {\n    if (name === 'data') {\n      this._duplexState |= (READ_EMIT_DATA | READ_RESUMED_READ_AHEAD)\n      this._readableState.updateNextTick()\n    }\n    if (name === 'readable') {\n      this._duplexState |= READ_EMIT_READABLE\n      this._readableState.updateNextTick()\n    }\n  }\n\n  if (this._writableState !== null) {\n    if (name === 'drain') {\n      this._duplexState |= WRITE_EMIT_DRAIN\n      this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Stream extends EventEmitter {\n  constructor (opts) {\n    super()\n\n    this._duplexState = 0\n    this._readableState = null\n    this._writableState = null\n\n    if (opts) {\n      if (opts.open) this._open = opts.open\n      if (opts.destroy) this._destroy = opts.destroy\n      if (opts.predestroy) this._predestroy = opts.predestroy\n      if (opts.signal) {\n        opts.signal.addEventListener('abort', abort.bind(this))\n      }\n    }\n\n    this.on('newListener', newListener)\n  }\n\n  _open (cb) {\n    cb(null)\n  }\n\n  _destroy (cb) {\n    cb(null)\n  }\n\n  _predestroy () {\n    // does nothing\n  }\n\n  get readable () {\n    return this._readableState !== null ? true : undefined\n  }\n\n  get writable () {\n    return this._writableState !== null ? true : undefined\n  }\n\n  get destroyed () {\n    return (this._duplexState & DESTROYED) !== 0\n  }\n\n  get destroying () {\n    return (this._duplexState & DESTROY_STATUS) !== 0\n  }\n\n  destroy (err) {\n    if ((this._duplexState & DESTROY_STATUS) === 0) {\n      if (!err) err = STREAM_DESTROYED\n      this._duplexState = (this._duplexState | DESTROYING) & NON_PRIMARY\n\n      if (this._readableState !== null) {\n        this._readableState.highWaterMark = 0\n        this._readableState.error = err\n      }\n      if (this._writableState !== null) {\n        this._writableState.highWaterMark = 0\n        this._writableState.error = err\n      }\n\n      this._duplexState |= PREDESTROYING\n      this._predestroy()\n      this._duplexState &= NOT_PREDESTROYING\n\n      if (this._readableState !== null) this._readableState.updateNextTick()\n      if (this._writableState !== null) this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Readable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | WRITE_DONE | READ_READ_AHEAD\n    this._readableState = new ReadableState(this, opts)\n\n    if (opts) {\n      if (this._readableState.readAhead === false) this._duplexState &= READ_NO_READ_AHEAD\n      if (opts.read) this._read = opts.read\n      if (opts.eagerOpen) this._readableState.updateNextTick()\n      if (opts.encoding) this.setEncoding(opts.encoding)\n    }\n  }\n\n  setEncoding (encoding) {\n    const dec = new TextDecoder(encoding)\n    const map = this._readableState.map || echo\n    this._readableState.map = mapOrSkip\n    return this\n\n    function mapOrSkip (data) {\n      const next = dec.push(data)\n      return next === '' && (data.byteLength !== 0 || dec.remaining > 0) ? null : map(next)\n    }\n  }\n\n  _read (cb) {\n    cb(null)\n  }\n\n  pipe (dest, cb) {\n    this._readableState.updateNextTick()\n    this._readableState.pipe(dest, cb)\n    return dest\n  }\n\n  read () {\n    this._readableState.updateNextTick()\n    return this._readableState.read()\n  }\n\n  push (data) {\n    this._readableState.updateNextTick()\n    return this._readableState.push(data)\n  }\n\n  unshift (data) {\n    this._readableState.updateNextTick()\n    return this._readableState.unshift(data)\n  }\n\n  resume () {\n    this._duplexState |= READ_RESUMED_READ_AHEAD\n    this._readableState.updateNextTick()\n    return this\n  }\n\n  pause () {\n    this._duplexState &= (this._readableState.readAhead === false ? READ_PAUSED_NO_READ_AHEAD : READ_PAUSED)\n    return this\n  }\n\n  static _fromAsyncIterator (ite, opts) {\n    let destroy\n\n    const rs = new Readable({\n      ...opts,\n      read (cb) {\n        ite.next().then(push).then(cb.bind(null, null)).catch(cb)\n      },\n      predestroy () {\n        destroy = ite.return()\n      },\n      destroy (cb) {\n        if (!destroy) return cb(null)\n        destroy.then(cb.bind(null, null)).catch(cb)\n      }\n    })\n\n    return rs\n\n    function push (data) {\n      if (data.done) rs.push(null)\n      else rs.push(data.value)\n    }\n  }\n\n  static from (data, opts) {\n    if (isReadStreamx(data)) return data\n    if (data[asyncIterator]) return this._fromAsyncIterator(data[asyncIterator](), opts)\n    if (!Array.isArray(data)) data = data === undefined ? [] : [data]\n\n    let i = 0\n    return new Readable({\n      ...opts,\n      read (cb) {\n        this.push(i === data.length ? null : data[i++])\n        cb(null)\n      }\n    })\n  }\n\n  static isBackpressured (rs) {\n    return (rs._duplexState & READ_BACKPRESSURE_STATUS) !== 0 || rs._readableState.buffered >= rs._readableState.highWaterMark\n  }\n\n  static isPaused (rs) {\n    return (rs._duplexState & READ_RESUMED) === 0\n  }\n\n  [asyncIterator] () {\n    const stream = this\n\n    let error = null\n    let promiseResolve = null\n    let promiseReject = null\n\n    this.on('error', (err) => { error = err })\n    this.on('readable', onreadable)\n    this.on('close', onclose)\n\n    return {\n      [asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(function (resolve, reject) {\n          promiseResolve = resolve\n          promiseReject = reject\n          const data = stream.read()\n          if (data !== null) ondata(data)\n          else if ((stream._duplexState & DESTROYED) !== 0) ondata(null)\n        })\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function onreadable () {\n      if (promiseResolve !== null) ondata(stream.read())\n    }\n\n    function onclose () {\n      if (promiseResolve !== null) ondata(null)\n    }\n\n    function ondata (data) {\n      if (promiseReject === null) return\n      if (error) promiseReject(error)\n      else if (data === null && (stream._duplexState & READ_DONE) === 0) promiseReject(STREAM_DESTROYED)\n      else promiseResolve({ value: data, done: data === null })\n      promiseReject = promiseResolve = null\n    }\n\n    function destroy (err) {\n      stream.destroy(err)\n      return new Promise((resolve, reject) => {\n        if (stream._duplexState & DESTROYED) return resolve({ value: undefined, done: true })\n        stream.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nclass Writable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | READ_DONE\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n      if (opts.eagerOpen) this._writableState.updateNextTick()\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  static isBackpressured (ws) {\n    return (ws._duplexState & WRITE_BACKPRESSURE_STATUS) !== 0\n  }\n\n  static drained (ws) {\n    if (ws.destroyed) return Promise.resolve(false)\n    const state = ws._writableState\n    const pending = (isWritev(ws) ? Math.min(1, state.queue.length) : state.queue.length)\n    const writes = pending + ((ws._duplexState & WRITE_WRITING) ? 1 : 0)\n    if (writes === 0) return Promise.resolve(true)\n    if (state.drains === null) state.drains = []\n    return new Promise((resolve) => {\n      state.drains.push({ writes, resolve })\n    })\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Duplex extends Readable { // and Writable\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState = OPENING | (this._duplexState & READ_READ_AHEAD)\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Transform extends Duplex {\n  constructor (opts) {\n    super(opts)\n    this._transformState = new TransformState(this)\n\n    if (opts) {\n      if (opts.transform) this._transform = opts.transform\n      if (opts.flush) this._flush = opts.flush\n    }\n  }\n\n  _write (data, cb) {\n    if (this._readableState.buffered >= this._readableState.highWaterMark) {\n      this._transformState.data = data\n    } else {\n      this._transform(data, this._transformState.afterTransform)\n    }\n  }\n\n  _read (cb) {\n    if (this._transformState.data !== null) {\n      const data = this._transformState.data\n      this._transformState.data = null\n      cb(null)\n      this._transform(data, this._transformState.afterTransform)\n    } else {\n      cb(null)\n    }\n  }\n\n  destroy (err) {\n    super.destroy(err)\n    if (this._transformState.data !== null) {\n      this._transformState.data = null\n      this._transformState.afterTransform()\n    }\n  }\n\n  _transform (data, cb) {\n    cb(null, data)\n  }\n\n  _flush (cb) {\n    cb(null)\n  }\n\n  _final (cb) {\n    this._transformState.afterFinal = cb\n    this._flush(transformAfterFlush.bind(this))\n  }\n}\n\nclass PassThrough extends Transform {}\n\nfunction transformAfterFlush (err, data) {\n  const cb = this._transformState.afterFinal\n  if (err) return cb(err)\n  if (data !== null && data !== undefined) this.push(data)\n  this.push(null)\n  cb(null)\n}\n\nfunction pipelinePromise (...streams) {\n  return new Promise((resolve, reject) => {\n    return pipeline(...streams, (err) => {\n      if (err) return reject(err)\n      resolve()\n    })\n  })\n}\n\nfunction pipeline (stream, ...streams) {\n  const all = Array.isArray(stream) ? [...stream, ...streams] : [stream, ...streams]\n  const done = (all.length && typeof all[all.length - 1] === 'function') ? all.pop() : null\n\n  if (all.length < 2) throw new Error('Pipeline requires at least 2 streams')\n\n  let src = all[0]\n  let dest = null\n  let error = null\n\n  for (let i = 1; i < all.length; i++) {\n    dest = all[i]\n\n    if (isStreamx(src)) {\n      src.pipe(dest, onerror)\n    } else {\n      errorHandle(src, true, i > 1, onerror)\n      src.pipe(dest)\n    }\n\n    src = dest\n  }\n\n  if (done) {\n    let fin = false\n\n    const autoDestroy = isStreamx(dest) || !!(dest._writableState && dest._writableState.autoDestroy)\n\n    dest.on('error', (err) => {\n      if (error === null) error = err\n    })\n\n    dest.on('finish', () => {\n      fin = true\n      if (!autoDestroy) done(error)\n    })\n\n    if (autoDestroy) {\n      dest.on('close', () => done(error || (fin ? null : PREMATURE_CLOSE)))\n    }\n  }\n\n  return dest\n\n  function errorHandle (s, rd, wr, onerror) {\n    s.on('error', onerror)\n    s.on('close', onclose)\n\n    function onclose () {\n      if (rd && s._readableState && !s._readableState.ended) return onerror(PREMATURE_CLOSE)\n      if (wr && s._writableState && !s._writableState.ended) return onerror(PREMATURE_CLOSE)\n    }\n  }\n\n  function onerror (err) {\n    if (!err || error) return\n    error = err\n\n    for (const s of all) {\n      s.destroy(err)\n    }\n  }\n}\n\nfunction echo (s) {\n  return s\n}\n\nfunction isStream (stream) {\n  return !!stream._readableState || !!stream._writableState\n}\n\nfunction isStreamx (stream) {\n  return typeof stream._duplexState === 'number' && isStream(stream)\n}\n\nfunction isEnded (stream) {\n  return !!stream._readableState && stream._readableState.ended\n}\n\nfunction isFinished (stream) {\n  return !!stream._writableState && stream._writableState.ended\n}\n\nfunction getStreamError (stream, opts = {}) {\n  const err = (stream._readableState && stream._readableState.error) || (stream._writableState && stream._writableState.error)\n\n  // avoid implicit errors by default\n  return (!opts.all && err === STREAM_DESTROYED) ? null : err\n}\n\nfunction isReadStreamx (stream) {\n  return isStreamx(stream) && stream.readable\n}\n\nfunction isTypedArray (data) {\n  return typeof data === 'object' && data !== null && typeof data.byteLength === 'number'\n}\n\nfunction defaultByteLength (data) {\n  return isTypedArray(data) ? data.byteLength : 1024\n}\n\nfunction noop () {}\n\nfunction abort () {\n  this.destroy(new Error('Stream aborted.'))\n}\n\nfunction isWritev (s) {\n  return s._writev !== Writable.prototype._writev && s._writev !== Duplex.prototype._writev\n}\n\nmodule.exports = {\n  pipeline,\n  pipelinePromise,\n  isStream,\n  isStreamx,\n  isEnded,\n  isFinished,\n  getStreamError,\n  Stream,\n  Writable,\n  Readable,\n  Duplex,\n  Transform,\n  // Export PassThrough for compatibility with Node.js core's stream module\n  PassThrough\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/streamx/index.js?");

/***/ }),

/***/ "./node_modules/tar-stream/constants.js":
/*!**********************************************!*\
  !*** ./node_modules/tar-stream/constants.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const constants = { // just for envs without fs\n  S_IFMT: 61440,\n  S_IFDIR: 16384,\n  S_IFCHR: 8192,\n  S_IFBLK: 24576,\n  S_IFIFO: 4096,\n  S_IFLNK: 40960\n}\n\ntry {\n  module.exports = (__webpack_require__(/*! fs */ \"?08ee\").constants) || constants\n} catch {\n  module.exports = constants\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/tar-stream/constants.js?");

/***/ }),

/***/ "./node_modules/tar-stream/extract.js":
/*!********************************************!*\
  !*** ./node_modules/tar-stream/extract.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { Writable, Readable, getStreamError } = __webpack_require__(/*! streamx */ \"./node_modules/streamx/index.js\")\nconst FIFO = __webpack_require__(/*! fast-fifo */ \"./node_modules/fast-fifo/index.js\")\nconst b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\nconst headers = __webpack_require__(/*! ./headers */ \"./node_modules/tar-stream/headers.js\")\n\nconst EMPTY = b4a.alloc(0)\n\nclass BufferList {\n  constructor () {\n    this.buffered = 0\n    this.shifted = 0\n    this.queue = new FIFO()\n\n    this._offset = 0\n  }\n\n  push (buffer) {\n    this.buffered += buffer.byteLength\n    this.queue.push(buffer)\n  }\n\n  shiftFirst (size) {\n    return this._buffered === 0 ? null : this._next(size)\n  }\n\n  shift (size) {\n    if (size > this.buffered) return null\n    if (size === 0) return EMPTY\n\n    let chunk = this._next(size)\n\n    if (size === chunk.byteLength) return chunk // likely case\n\n    const chunks = [chunk]\n\n    while ((size -= chunk.byteLength) > 0) {\n      chunk = this._next(size)\n      chunks.push(chunk)\n    }\n\n    return b4a.concat(chunks)\n  }\n\n  _next (size) {\n    const buf = this.queue.peek()\n    const rem = buf.byteLength - this._offset\n\n    if (size >= rem) {\n      const sub = this._offset ? buf.subarray(this._offset, buf.byteLength) : buf\n      this.queue.shift()\n      this._offset = 0\n      this.buffered -= rem\n      this.shifted += rem\n      return sub\n    }\n\n    this.buffered -= size\n    this.shifted += size\n\n    return buf.subarray(this._offset, (this._offset += size))\n  }\n}\n\nclass Source extends Readable {\n  constructor (self, header, offset) {\n    super()\n\n    this.header = header\n    this.offset = offset\n\n    this._parent = self\n  }\n\n  _read (cb) {\n    if (this.header.size === 0) {\n      this.push(null)\n    }\n    if (this._parent._stream === this) {\n      this._parent._update()\n    }\n    cb(null)\n  }\n\n  _predestroy () {\n    this._parent.destroy(getStreamError(this))\n  }\n\n  _detach () {\n    if (this._parent._stream === this) {\n      this._parent._stream = null\n      this._parent._missing = overflow(this.header.size)\n      this._parent._update()\n    }\n  }\n\n  _destroy (cb) {\n    this._detach()\n    cb(null)\n  }\n}\n\nclass Extract extends Writable {\n  constructor (opts) {\n    super(opts)\n\n    if (!opts) opts = {}\n\n    this._buffer = new BufferList()\n    this._offset = 0\n    this._header = null\n    this._stream = null\n    this._missing = 0\n    this._longHeader = false\n    this._callback = noop\n    this._locked = false\n    this._finished = false\n    this._pax = null\n    this._paxGlobal = null\n    this._gnuLongPath = null\n    this._gnuLongLinkPath = null\n    this._filenameEncoding = opts.filenameEncoding || 'utf-8'\n    this._allowUnknownFormat = !!opts.allowUnknownFormat\n    this._unlockBound = this._unlock.bind(this)\n  }\n\n  _unlock (err) {\n    this._locked = false\n\n    if (err) {\n      this.destroy(err)\n      this._continueWrite(err)\n      return\n    }\n\n    this._update()\n  }\n\n  _consumeHeader () {\n    if (this._locked) return false\n\n    this._offset = this._buffer.shifted\n\n    try {\n      this._header = headers.decode(this._buffer.shift(512), this._filenameEncoding, this._allowUnknownFormat)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    if (!this._header) return true\n\n    switch (this._header.type) {\n      case 'gnu-long-path':\n      case 'gnu-long-link-path':\n      case 'pax-global-header':\n      case 'pax-header':\n        this._longHeader = true\n        this._missing = this._header.size\n        return true\n    }\n\n    this._locked = true\n    this._applyLongHeaders()\n\n    if (this._header.size === 0 || this._header.type === 'directory') {\n      this.emit('entry', this._header, this._createStream(), this._unlockBound)\n      return true\n    }\n\n    this._stream = this._createStream()\n    this._missing = this._header.size\n\n    this.emit('entry', this._header, this._stream, this._unlockBound)\n    return true\n  }\n\n  _applyLongHeaders () {\n    if (this._gnuLongPath) {\n      this._header.name = this._gnuLongPath\n      this._gnuLongPath = null\n    }\n\n    if (this._gnuLongLinkPath) {\n      this._header.linkname = this._gnuLongLinkPath\n      this._gnuLongLinkPath = null\n    }\n\n    if (this._pax) {\n      if (this._pax.path) this._header.name = this._pax.path\n      if (this._pax.linkpath) this._header.linkname = this._pax.linkpath\n      if (this._pax.size) this._header.size = parseInt(this._pax.size, 10)\n      this._header.pax = this._pax\n      this._pax = null\n    }\n  }\n\n  _decodeLongHeader (buf) {\n    switch (this._header.type) {\n      case 'gnu-long-path':\n        this._gnuLongPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'gnu-long-link-path':\n        this._gnuLongLinkPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'pax-global-header':\n        this._paxGlobal = headers.decodePax(buf)\n        break\n      case 'pax-header':\n        this._pax = this._paxGlobal === null\n          ? headers.decodePax(buf)\n          : Object.assign({}, this._paxGlobal, headers.decodePax(buf))\n        break\n    }\n  }\n\n  _consumeLongHeader () {\n    this._longHeader = false\n    this._missing = overflow(this._header.size)\n\n    const buf = this._buffer.shift(this._header.size)\n\n    try {\n      this._decodeLongHeader(buf)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    return true\n  }\n\n  _consumeStream () {\n    const buf = this._buffer.shiftFirst(this._missing)\n    if (buf === null) return false\n\n    this._missing -= buf.byteLength\n    const drained = this._stream.push(buf)\n\n    if (this._missing === 0) {\n      this._stream.push(null)\n      if (drained) this._stream._detach()\n      return drained && this._locked === false\n    }\n\n    return drained\n  }\n\n  _createStream () {\n    return new Source(this, this._header, this._offset)\n  }\n\n  _update () {\n    while (this._buffer.buffered > 0 && !this.destroying) {\n      if (this._missing > 0) {\n        if (this._stream !== null) {\n          if (this._consumeStream() === false) return\n          continue\n        }\n\n        if (this._longHeader === true) {\n          if (this._missing > this._buffer.buffered) break\n          if (this._consumeLongHeader() === false) return false\n          continue\n        }\n\n        const ignore = this._buffer.shiftFirst(this._missing)\n        if (ignore !== null) this._missing -= ignore.byteLength\n        continue\n      }\n\n      if (this._buffer.buffered < 512) break\n      if (this._stream !== null || this._consumeHeader() === false) return\n    }\n\n    this._continueWrite(null)\n  }\n\n  _continueWrite (err) {\n    const cb = this._callback\n    this._callback = noop\n    cb(err)\n  }\n\n  _write (data, cb) {\n    this._callback = cb\n    this._buffer.push(data)\n    this._update()\n  }\n\n  _final (cb) {\n    this._finished = this._missing === 0 && this._buffer.buffered === 0\n    cb(this._finished ? null : new Error('Unexpected end of data'))\n  }\n\n  _predestroy () {\n    this._continueWrite(null)\n  }\n\n  _destroy (cb) {\n    if (this._stream) this._stream.destroy(getStreamError(this))\n    cb(null)\n  }\n\n  [Symbol.asyncIterator] () {\n    let error = null\n\n    let promiseResolve = null\n    let promiseReject = null\n\n    let entryStream = null\n    let entryCallback = null\n\n    const extract = this\n\n    this.on('entry', onentry)\n    this.on('error', (err) => { error = err })\n    this.on('close', onclose)\n\n    return {\n      [Symbol.asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(onnext)\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function consumeCallback (err) {\n      if (!entryCallback) return\n      const cb = entryCallback\n      entryCallback = null\n      cb(err)\n    }\n\n    function onnext (resolve, reject) {\n      if (error) {\n        return reject(error)\n      }\n\n      if (entryStream) {\n        resolve({ value: entryStream, done: false })\n        entryStream = null\n        return\n      }\n\n      promiseResolve = resolve\n      promiseReject = reject\n\n      consumeCallback(null)\n\n      if (extract._finished && promiseResolve) {\n        promiseResolve({ value: undefined, done: true })\n        promiseResolve = promiseReject = null\n      }\n    }\n\n    function onentry (header, stream, callback) {\n      entryCallback = callback\n      stream.on('error', noop) // no way around this due to tick sillyness\n\n      if (promiseResolve) {\n        promiseResolve({ value: stream, done: false })\n        promiseResolve = promiseReject = null\n      } else {\n        entryStream = stream\n      }\n    }\n\n    function onclose () {\n      consumeCallback(error)\n      if (!promiseResolve) return\n      if (error) promiseReject(error)\n      else promiseResolve({ value: undefined, done: true })\n      promiseResolve = promiseReject = null\n    }\n\n    function destroy (err) {\n      extract.destroy(err)\n      consumeCallback(err)\n      return new Promise((resolve, reject) => {\n        if (extract.destroyed) return resolve({ value: undefined, done: true })\n        extract.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nmodule.exports = function extract (opts) {\n  return new Extract(opts)\n}\n\nfunction noop () {}\n\nfunction overflow (size) {\n  size &= 511\n  return size && 512 - size\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/tar-stream/extract.js?");

/***/ }),

/***/ "./node_modules/tar-stream/headers.js":
/*!********************************************!*\
  !*** ./node_modules/tar-stream/headers.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\n\nconst ZEROS = '0000000000000000000'\nconst SEVENS = '7777777777777777777'\nconst ZERO_OFFSET = '0'.charCodeAt(0)\nconst USTAR_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x00]) // ustar\\x00\nconst USTAR_VER = b4a.from([ZERO_OFFSET, ZERO_OFFSET])\nconst GNU_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x20]) // ustar\\x20\nconst GNU_VER = b4a.from([0x20, 0x00])\nconst MASK = 0o7777\nconst MAGIC_OFFSET = 257\nconst VERSION_OFFSET = 263\n\nexports.decodeLongPath = function decodeLongPath (buf, encoding) {\n  return decodeStr(buf, 0, buf.length, encoding)\n}\n\nexports.encodePax = function encodePax (opts) { // TODO: encode more stuff in pax\n  let result = ''\n  if (opts.name) result += addLength(' path=' + opts.name + '\\n')\n  if (opts.linkname) result += addLength(' linkpath=' + opts.linkname + '\\n')\n  const pax = opts.pax\n  if (pax) {\n    for (const key in pax) {\n      result += addLength(' ' + key + '=' + pax[key] + '\\n')\n    }\n  }\n  return b4a.from(result)\n}\n\nexports.decodePax = function decodePax (buf) {\n  const result = {}\n\n  while (buf.length) {\n    let i = 0\n    while (i < buf.length && buf[i] !== 32) i++\n    const len = parseInt(b4a.toString(buf.subarray(0, i)), 10)\n    if (!len) return result\n\n    const b = b4a.toString(buf.subarray(i + 1, len - 1))\n    const keyIndex = b.indexOf('=')\n    if (keyIndex === -1) return result\n    result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1)\n\n    buf = buf.subarray(len)\n  }\n\n  return result\n}\n\nexports.encode = function encode (opts) {\n  const buf = b4a.alloc(512)\n  let name = opts.name\n  let prefix = ''\n\n  if (opts.typeflag === 5 && name[name.length - 1] !== '/') name += '/'\n  if (b4a.byteLength(name) !== name.length) return null // utf-8\n\n  while (b4a.byteLength(name) > 100) {\n    const i = name.indexOf('/')\n    if (i === -1) return null\n    prefix += prefix ? '/' + name.slice(0, i) : name.slice(0, i)\n    name = name.slice(i + 1)\n  }\n\n  if (b4a.byteLength(name) > 100 || b4a.byteLength(prefix) > 155) return null\n  if (opts.linkname && b4a.byteLength(opts.linkname) > 100) return null\n\n  b4a.write(buf, name)\n  b4a.write(buf, encodeOct(opts.mode & MASK, 6), 100)\n  b4a.write(buf, encodeOct(opts.uid, 6), 108)\n  b4a.write(buf, encodeOct(opts.gid, 6), 116)\n  encodeSize(opts.size, buf, 124)\n  b4a.write(buf, encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136)\n\n  buf[156] = ZERO_OFFSET + toTypeflag(opts.type)\n\n  if (opts.linkname) b4a.write(buf, opts.linkname, 157)\n\n  b4a.copy(USTAR_MAGIC, buf, MAGIC_OFFSET)\n  b4a.copy(USTAR_VER, buf, VERSION_OFFSET)\n  if (opts.uname) b4a.write(buf, opts.uname, 265)\n  if (opts.gname) b4a.write(buf, opts.gname, 297)\n  b4a.write(buf, encodeOct(opts.devmajor || 0, 6), 329)\n  b4a.write(buf, encodeOct(opts.devminor || 0, 6), 337)\n\n  if (prefix) b4a.write(buf, prefix, 345)\n\n  b4a.write(buf, encodeOct(cksum(buf), 6), 148)\n\n  return buf\n}\n\nexports.decode = function decode (buf, filenameEncoding, allowUnknownFormat) {\n  let typeflag = buf[156] === 0 ? 0 : buf[156] - ZERO_OFFSET\n\n  let name = decodeStr(buf, 0, 100, filenameEncoding)\n  const mode = decodeOct(buf, 100, 8)\n  const uid = decodeOct(buf, 108, 8)\n  const gid = decodeOct(buf, 116, 8)\n  const size = decodeOct(buf, 124, 12)\n  const mtime = decodeOct(buf, 136, 12)\n  const type = toType(typeflag)\n  const linkname = buf[157] === 0 ? null : decodeStr(buf, 157, 100, filenameEncoding)\n  const uname = decodeStr(buf, 265, 32)\n  const gname = decodeStr(buf, 297, 32)\n  const devmajor = decodeOct(buf, 329, 8)\n  const devminor = decodeOct(buf, 337, 8)\n\n  const c = cksum(buf)\n\n  // checksum is still initial value if header was null.\n  if (c === 8 * 32) return null\n\n  // valid checksum\n  if (c !== decodeOct(buf, 148, 8)) throw new Error('Invalid tar header. Maybe the tar is corrupted or it needs to be gunzipped?')\n\n  if (isUSTAR(buf)) {\n    // ustar (posix) format.\n    // prepend prefix, if present.\n    if (buf[345]) name = decodeStr(buf, 345, 155, filenameEncoding) + '/' + name\n  } else if (isGNU(buf)) {\n    // 'gnu'/'oldgnu' format. Similar to ustar, but has support for incremental and\n    // multi-volume tarballs.\n  } else {\n    if (!allowUnknownFormat) {\n      throw new Error('Invalid tar header: unknown format.')\n    }\n  }\n\n  // to support old tar versions that use trailing / to indicate dirs\n  if (typeflag === 0 && name && name[name.length - 1] === '/') typeflag = 5\n\n  return {\n    name,\n    mode,\n    uid,\n    gid,\n    size,\n    mtime: new Date(1000 * mtime),\n    type,\n    linkname,\n    uname,\n    gname,\n    devmajor,\n    devminor,\n    pax: null\n  }\n}\n\nfunction isUSTAR (buf) {\n  return b4a.equals(USTAR_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6))\n}\n\nfunction isGNU (buf) {\n  return b4a.equals(GNU_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) &&\n    b4a.equals(GNU_VER, buf.subarray(VERSION_OFFSET, VERSION_OFFSET + 2))\n}\n\nfunction clamp (index, len, defaultValue) {\n  if (typeof index !== 'number') return defaultValue\n  index = ~~index // Coerce to integer.\n  if (index >= len) return len\n  if (index >= 0) return index\n  index += len\n  if (index >= 0) return index\n  return 0\n}\n\nfunction toType (flag) {\n  switch (flag) {\n    case 0:\n      return 'file'\n    case 1:\n      return 'link'\n    case 2:\n      return 'symlink'\n    case 3:\n      return 'character-device'\n    case 4:\n      return 'block-device'\n    case 5:\n      return 'directory'\n    case 6:\n      return 'fifo'\n    case 7:\n      return 'contiguous-file'\n    case 72:\n      return 'pax-header'\n    case 55:\n      return 'pax-global-header'\n    case 27:\n      return 'gnu-long-link-path'\n    case 28:\n    case 30:\n      return 'gnu-long-path'\n  }\n\n  return null\n}\n\nfunction toTypeflag (flag) {\n  switch (flag) {\n    case 'file':\n      return 0\n    case 'link':\n      return 1\n    case 'symlink':\n      return 2\n    case 'character-device':\n      return 3\n    case 'block-device':\n      return 4\n    case 'directory':\n      return 5\n    case 'fifo':\n      return 6\n    case 'contiguous-file':\n      return 7\n    case 'pax-header':\n      return 72\n  }\n\n  return 0\n}\n\nfunction indexOf (block, num, offset, end) {\n  for (; offset < end; offset++) {\n    if (block[offset] === num) return offset\n  }\n  return end\n}\n\nfunction cksum (block) {\n  let sum = 8 * 32\n  for (let i = 0; i < 148; i++) sum += block[i]\n  for (let j = 156; j < 512; j++) sum += block[j]\n  return sum\n}\n\nfunction encodeOct (val, n) {\n  val = val.toString(8)\n  if (val.length > n) return SEVENS.slice(0, n) + ' '\n  return ZEROS.slice(0, n - val.length) + val + ' '\n}\n\nfunction encodeSizeBin (num, buf, off) {\n  buf[off] = 0x80\n  for (let i = 11; i > 0; i--) {\n    buf[off + i] = num & 0xff\n    num = Math.floor(num / 0x100)\n  }\n}\n\nfunction encodeSize (num, buf, off) {\n  if (num.toString(8).length > 11) {\n    encodeSizeBin(num, buf, off)\n  } else {\n    b4a.write(buf, encodeOct(num, 11), off)\n  }\n}\n\n/* Copied from the node-tar repo and modified to meet\n * tar-stream coding standard.\n *\n * Source: https://github.com/npm/node-tar/blob/51b6627a1f357d2eb433e7378e5f05e83b7aa6cd/lib/header.js#L349\n */\nfunction parse256 (buf) {\n  // first byte MUST be either 80 or FF\n  // 80 for positive, FF for 2's comp\n  let positive\n  if (buf[0] === 0x80) positive = true\n  else if (buf[0] === 0xFF) positive = false\n  else return null\n\n  // build up a base-256 tuple from the least sig to the highest\n  const tuple = []\n  let i\n  for (i = buf.length - 1; i > 0; i--) {\n    const byte = buf[i]\n    if (positive) tuple.push(byte)\n    else tuple.push(0xFF - byte)\n  }\n\n  let sum = 0\n  const l = tuple.length\n  for (i = 0; i < l; i++) {\n    sum += tuple[i] * Math.pow(256, i)\n  }\n\n  return positive ? sum : -1 * sum\n}\n\nfunction decodeOct (val, offset, length) {\n  val = val.subarray(offset, offset + length)\n  offset = 0\n\n  // If prefixed with 0x80 then parse as a base-256 integer\n  if (val[offset] & 0x80) {\n    return parse256(val)\n  } else {\n    // Older versions of tar can prefix with spaces\n    while (offset < val.length && val[offset] === 32) offset++\n    const end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length)\n    while (offset < end && val[offset] === 0) offset++\n    if (end === offset) return 0\n    return parseInt(b4a.toString(val.subarray(offset, end)), 8)\n  }\n}\n\nfunction decodeStr (val, offset, length, encoding) {\n  return b4a.toString(val.subarray(offset, indexOf(val, 0, offset, offset + length)), encoding)\n}\n\nfunction addLength (str) {\n  const len = b4a.byteLength(str)\n  let digits = Math.floor(Math.log(len) / Math.log(10)) + 1\n  if (len + digits >= Math.pow(10, digits)) digits++\n\n  return (len + digits) + str\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/tar-stream/headers.js?");

/***/ }),

/***/ "./node_modules/tar-stream/index.js":
/*!******************************************!*\
  !*** ./node_modules/tar-stream/index.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("exports.extract = __webpack_require__(/*! ./extract */ \"./node_modules/tar-stream/extract.js\")\nexports.pack = __webpack_require__(/*! ./pack */ \"./node_modules/tar-stream/pack.js\")\n\n\n//# sourceURL=webpack://untar-example/./node_modules/tar-stream/index.js?");

/***/ }),

/***/ "./node_modules/tar-stream/pack.js":
/*!*****************************************!*\
  !*** ./node_modules/tar-stream/pack.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { Readable, Writable, getStreamError } = __webpack_require__(/*! streamx */ \"./node_modules/streamx/index.js\")\nconst b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\n\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/tar-stream/constants.js\")\nconst headers = __webpack_require__(/*! ./headers */ \"./node_modules/tar-stream/headers.js\")\n\nconst DMODE = 0o755\nconst FMODE = 0o644\n\nconst END_OF_TAR = b4a.alloc(1024)\n\nclass Sink extends Writable {\n  constructor (pack, header, callback) {\n    super({ mapWritable, eagerOpen: true })\n\n    this.written = 0\n    this.header = header\n\n    this._callback = callback\n    this._linkname = null\n    this._isLinkname = header.type === 'symlink' && !header.linkname\n    this._isVoid = header.type !== 'file' && header.type !== 'contiguous-file'\n    this._finished = false\n    this._pack = pack\n    this._openCallback = null\n\n    if (this._pack._stream === null) this._pack._stream = this\n    else this._pack._pending.push(this)\n  }\n\n  _open (cb) {\n    this._openCallback = cb\n    if (this._pack._stream === this) this._continueOpen()\n  }\n\n  _continuePack (err) {\n    if (this._callback === null) return\n\n    const callback = this._callback\n    this._callback = null\n\n    callback(err)\n  }\n\n  _continueOpen () {\n    if (this._pack._stream === null) this._pack._stream = this\n\n    const cb = this._openCallback\n    this._openCallback = null\n    if (cb === null) return\n\n    if (this._pack.destroying) return cb(new Error('pack stream destroyed'))\n    if (this._pack._finalized) return cb(new Error('pack stream is already finalized'))\n\n    this._pack._stream = this\n\n    if (!this._isLinkname) {\n      this._pack._encode(this.header)\n    }\n\n    if (this._isVoid) {\n      this._finish()\n      this._continuePack(null)\n    }\n\n    cb(null)\n  }\n\n  _write (data, cb) {\n    if (this._isLinkname) {\n      this._linkname = this._linkname ? b4a.concat([this._linkname, data]) : data\n      return cb(null)\n    }\n\n    if (this._isVoid) {\n      if (data.byteLength > 0) {\n        return cb(new Error('No body allowed for this entry'))\n      }\n      return cb()\n    }\n\n    this.written += data.byteLength\n    if (this._pack.push(data)) return cb()\n    this._pack._drain = cb\n  }\n\n  _finish () {\n    if (this._finished) return\n    this._finished = true\n\n    if (this._isLinkname) {\n      this.header.linkname = this._linkname ? b4a.toString(this._linkname, 'utf-8') : ''\n      this._pack._encode(this.header)\n    }\n\n    overflow(this._pack, this.header.size)\n\n    this._pack._done(this)\n  }\n\n  _final (cb) {\n    if (this.written !== this.header.size) { // corrupting tar\n      return cb(new Error('Size mismatch'))\n    }\n\n    this._finish()\n    cb(null)\n  }\n\n  _getError () {\n    return getStreamError(this) || new Error('tar entry destroyed')\n  }\n\n  _predestroy () {\n    this._pack.destroy(this._getError())\n  }\n\n  _destroy (cb) {\n    this._pack._done(this)\n\n    this._continuePack(this._finished ? null : this._getError())\n\n    cb()\n  }\n}\n\nclass Pack extends Readable {\n  constructor (opts) {\n    super(opts)\n    this._drain = noop\n    this._finalized = false\n    this._finalizing = false\n    this._pending = []\n    this._stream = null\n  }\n\n  entry (header, buffer, callback) {\n    if (this._finalized || this.destroying) throw new Error('already finalized or destroyed')\n\n    if (typeof buffer === 'function') {\n      callback = buffer\n      buffer = null\n    }\n\n    if (!callback) callback = noop\n\n    if (!header.size || header.type === 'symlink') header.size = 0\n    if (!header.type) header.type = modeToType(header.mode)\n    if (!header.mode) header.mode = header.type === 'directory' ? DMODE : FMODE\n    if (!header.uid) header.uid = 0\n    if (!header.gid) header.gid = 0\n    if (!header.mtime) header.mtime = new Date()\n\n    if (typeof buffer === 'string') buffer = b4a.from(buffer)\n\n    const sink = new Sink(this, header, callback)\n\n    if (b4a.isBuffer(buffer)) {\n      header.size = buffer.byteLength\n      sink.write(buffer)\n      sink.end()\n      return sink\n    }\n\n    if (sink._isVoid) {\n      return sink\n    }\n\n    return sink\n  }\n\n  finalize () {\n    if (this._stream || this._pending.length > 0) {\n      this._finalizing = true\n      return\n    }\n\n    if (this._finalized) return\n    this._finalized = true\n\n    this.push(END_OF_TAR)\n    this.push(null)\n  }\n\n  _done (stream) {\n    if (stream !== this._stream) return\n\n    this._stream = null\n\n    if (this._finalizing) this.finalize()\n    if (this._pending.length) this._pending.shift()._continueOpen()\n  }\n\n  _encode (header) {\n    if (!header.pax) {\n      const buf = headers.encode(header)\n      if (buf) {\n        this.push(buf)\n        return\n      }\n    }\n    this._encodePax(header)\n  }\n\n  _encodePax (header) {\n    const paxHeader = headers.encodePax({\n      name: header.name,\n      linkname: header.linkname,\n      pax: header.pax\n    })\n\n    const newHeader = {\n      name: 'PaxHeader',\n      mode: header.mode,\n      uid: header.uid,\n      gid: header.gid,\n      size: paxHeader.byteLength,\n      mtime: header.mtime,\n      type: 'pax-header',\n      linkname: header.linkname && 'PaxHeader',\n      uname: header.uname,\n      gname: header.gname,\n      devmajor: header.devmajor,\n      devminor: header.devminor\n    }\n\n    this.push(headers.encode(newHeader))\n    this.push(paxHeader)\n    overflow(this, paxHeader.byteLength)\n\n    newHeader.size = header.size\n    newHeader.type = header.type\n    this.push(headers.encode(newHeader))\n  }\n\n  _doDrain () {\n    const drain = this._drain\n    this._drain = noop\n    drain()\n  }\n\n  _predestroy () {\n    const err = getStreamError(this)\n\n    if (this._stream) this._stream.destroy(err)\n\n    while (this._pending.length) {\n      const stream = this._pending.shift()\n      stream.destroy(err)\n      stream._continueOpen()\n    }\n\n    this._doDrain()\n  }\n\n  _read (cb) {\n    this._doDrain()\n    cb()\n  }\n}\n\nmodule.exports = function pack (opts) {\n  return new Pack(opts)\n}\n\nfunction modeToType (mode) {\n  switch (mode & constants.S_IFMT) {\n    case constants.S_IFBLK: return 'block-device'\n    case constants.S_IFCHR: return 'character-device'\n    case constants.S_IFDIR: return 'directory'\n    case constants.S_IFIFO: return 'fifo'\n    case constants.S_IFLNK: return 'symlink'\n  }\n\n  return 'file'\n}\n\nfunction noop () {}\n\nfunction overflow (self, size) {\n  size &= 511\n  if (size) self.push(END_OF_TAR.subarray(0, 512 - size))\n}\n\nfunction mapWritable (buf) {\n  return b4a.isBuffer(buf) ? buf : b4a.from(buf)\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/tar-stream/pack.js?");

/***/ }),

/***/ "./node_modules/text-decoder/index.js":
/*!********************************************!*\
  !*** ./node_modules/text-decoder/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const PassThroughDecoder = __webpack_require__(/*! ./lib/pass-through-decoder */ \"./node_modules/text-decoder/lib/browser-decoder.js\")\nconst UTF8Decoder = __webpack_require__(/*! ./lib/utf8-decoder */ \"./node_modules/text-decoder/lib/browser-decoder.js\")\n\nmodule.exports = class TextDecoder {\n  constructor (encoding = 'utf8') {\n    this.encoding = normalizeEncoding(encoding)\n\n    switch (this.encoding) {\n      case 'utf8':\n        this.decoder = new UTF8Decoder()\n        break\n      case 'utf16le':\n      case 'base64':\n        throw new Error('Unsupported encoding: ' + this.encoding)\n      default:\n        this.decoder = new PassThroughDecoder(this.encoding)\n    }\n  }\n\n  get remaining () {\n    return this.decoder.remaining\n  }\n\n  push (data) {\n    if (typeof data === 'string') return data\n    return this.decoder.decode(data)\n  }\n\n  // For Node.js compatibility\n  write (data) {\n    return this.push(data)\n  }\n\n  end (data) {\n    let result = ''\n    if (data) result = this.push(data)\n    result += this.decoder.flush()\n    return result\n  }\n}\n\nfunction normalizeEncoding (encoding) {\n  encoding = encoding.toLowerCase()\n\n  switch (encoding) {\n    case 'utf8':\n    case 'utf-8':\n      return 'utf8'\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return 'utf16le'\n    case 'latin1':\n    case 'binary':\n      return 'latin1'\n    case 'base64':\n    case 'ascii':\n    case 'hex':\n      return encoding\n    default:\n      throw new Error('Unknown encoding: ' + encoding)\n  }\n};\n\n\n//# sourceURL=webpack://untar-example/./node_modules/text-decoder/index.js?");

/***/ }),

/***/ "./node_modules/text-decoder/lib/browser-decoder.js":
/*!**********************************************************!*\
  !*** ./node_modules/text-decoder/lib/browser-decoder.js ***!
  \**********************************************************/
/***/ ((module) => {

eval("module.exports = class BrowserDecoder {\n  constructor (encoding) {\n    this.decoder = new TextDecoder(encoding === 'utf16le' ? 'utf16-le' : encoding)\n  }\n\n  get remaining () {\n    return -1\n  }\n\n  decode (data) {\n    return this.decoder.decode(data, { stream: true })\n  }\n\n  flush () {\n    return this.decoder.decode(new Uint8Array(0))\n  }\n}\n\n\n//# sourceURL=webpack://untar-example/./node_modules/text-decoder/lib/browser-decoder.js?");

/***/ }),

/***/ "./lib/libarchive.wasm":
/*!*****************************!*\
  !*** ./lib/libarchive.wasm ***!
  \*****************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("module.exports = __webpack_require__.p + \"86c4966bb12067867d98.wasm\";\n\n//# sourceURL=webpack://untar-example/./lib/libarchive.wasm?");

/***/ }),

/***/ "?08ee":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://untar-example/fs_(ignored)?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/node module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.nmd = (module) => {
/******/ 			module.paths = [];
/******/ 			if (!module.children) module.children = [];
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/publicPath */
/******/ 	(() => {
/******/ 		var scriptUrl;
/******/ 		if (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + "";
/******/ 		var document = __webpack_require__.g.document;
/******/ 		if (!scriptUrl && document) {
/******/ 			if (document.currentScript && document.currentScript.tagName.toUpperCase() === 'SCRIPT')
/******/ 				scriptUrl = document.currentScript.src;
/******/ 			if (!scriptUrl) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				if(scripts.length) {
/******/ 					var i = scripts.length - 1;
/******/ 					while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;
/******/ 				}
/******/ 			}
/******/ 		}
/******/ 		// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 		// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 		if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 		scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 		__webpack_require__.p = scriptUrl;
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;